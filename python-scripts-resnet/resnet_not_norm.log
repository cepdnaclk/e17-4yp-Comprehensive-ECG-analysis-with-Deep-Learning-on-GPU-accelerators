GPU memory is free enough. Running Python script...
-------------pr---------------
/storage/projects2/e17-4yp-compreh-ecg-analysis/minicondaInst/envs/test/lib/python3.11/site-packages/torch/nn/modules/conv.py:309: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at /opt/conda/conda-bld/pytorch_1682343970094/work/aten/src/ATen/native/Convolution.cpp:1003.)
  return F.conv1d(input, weight, bias, self.stride,
0 tarainning loss : 13724.71389566524 validation loss : 3267.6726735432944 Real validation loss : 96083676.91666667
Validation loss decreased (inf --> 3267.672674).  Saving model ...
1 tarainning loss : 671.4061151157044 validation loss : 88.95704579353333 Real validation loss : 219939657.16666666
Validation loss decreased (3267.672674 --> 88.957046).  Saving model ...
2 tarainning loss : 55.17156625200224 validation loss : 74.80865474541982 Real validation loss : 219061850.33333334
Validation loss decreased (88.957046 --> 74.808655).  Saving model ...
3 tarainning loss : 51.809299319006044 validation loss : 76.75867033004761 Real validation loss : 244686395.5
EarlyStopping counter: 1 out of 100
4 tarainning loss : 50.22329293447272 validation loss : 84.05155646800995 Real validation loss : 215220882.0
EarlyStopping counter: 2 out of 100
5 tarainning loss : 49.415657648409024 validation loss : 51.03387971719106 Real validation loss : 229128293.83333334
Validation loss decreased (74.808655 --> 51.033880).  Saving model ...
6 tarainning loss : 48.61163936280017 validation loss : 52.76537322998047 Real validation loss : 236053450.5
EarlyStopping counter: 1 out of 100
7 tarainning loss : 47.68549994872407 validation loss : 55.877509117126465 Real validation loss : 224119039.83333334
EarlyStopping counter: 2 out of 100
8 tarainning loss : 46.90482881528522 validation loss : 55.41746779282888 Real validation loss : 224726936.33333334
EarlyStopping counter: 3 out of 100
9 tarainning loss : 46.323433887286704 validation loss : 50.654478907585144 Real validation loss : 224971420.83333334
Validation loss decreased (51.033880 --> 50.654479).  Saving model ...
10 tarainning loss : 45.51629991643863 validation loss : 46.83253425359726 Real validation loss : 228566011.0
Validation loss decreased (50.654479 --> 46.832534).  Saving model ...
11 tarainning loss : 45.26300569036841 validation loss : 48.94963786999384 Real validation loss : 226297999.0
EarlyStopping counter: 1 out of 100
12 tarainning loss : 44.70927285460626 validation loss : 53.11410268147787 Real validation loss : 223782526.33333334
EarlyStopping counter: 2 out of 100
13 tarainning loss : 44.32970690196026 validation loss : 46.139405608177185 Real validation loss : 233278172.0
Validation loss decreased (46.832534 --> 46.139406).  Saving model ...
14 tarainning loss : 43.83722374042396 validation loss : 50.5711966753006 Real validation loss : 224379426.5
EarlyStopping counter: 1 out of 100
15 tarainning loss : 43.38982467351391 validation loss : 50.60744818051656 Real validation loss : 225369005.33333334
EarlyStopping counter: 2 out of 100
16 tarainning loss : 43.09349248043675 validation loss : 62.46946108341217 Real validation loss : 219298593.16666666
EarlyStopping counter: 3 out of 100
17 tarainning loss : 42.86584247424124 validation loss : 45.78803372383118 Real validation loss : 228000439.0
Validation loss decreased (46.139406 --> 45.788034).  Saving model ...
18 tarainning loss : 42.246176898401345 validation loss : 54.162611762682594 Real validation loss : 222433613.5
EarlyStopping counter: 1 out of 100
19 tarainning loss : 42.03859065994523 validation loss : 52.9555057088534 Real validation loss : 223586432.83333334
EarlyStopping counter: 2 out of 100
20 tarainning loss : 41.63284211264994 validation loss : 44.14774298667908 Real validation loss : 231783819.33333334
Validation loss decreased (45.788034 --> 44.147743).  Saving model ...
21 tarainning loss : 41.523906737761294 validation loss : 45.973742147286735 Real validation loss : 229782287.33333334
EarlyStopping counter: 1 out of 100
22 tarainning loss : 40.9435513797625 validation loss : 45.107646465301514 Real validation loss : 233673462.0
EarlyStopping counter: 2 out of 100
23 tarainning loss : 40.54396276361508 validation loss : 45.95532397429148 Real validation loss : 234718536.33333334
EarlyStopping counter: 3 out of 100
24 tarainning loss : 40.22641805146343 validation loss : 45.880783240000405 Real validation loss : 234780527.5
EarlyStopping counter: 4 out of 100
25 tarainning loss : 39.58822547092663 validation loss : 55.84118286768595 Real validation loss : 240233908.33333334
EarlyStopping counter: 5 out of 100
26 tarainning loss : 39.29293094550017 validation loss : 46.358010391394295 Real validation loss : 227525203.66666666
EarlyStopping counter: 6 out of 100
27 tarainning loss : 39.015537131973204 validation loss : 48.25741831461588 Real validation loss : 237109621.16666666
EarlyStopping counter: 7 out of 100
28 tarainning loss : 38.70259063490722 validation loss : 44.528879483540855 Real validation loss : 228964815.66666666
EarlyStopping counter: 8 out of 100
29 tarainning loss : 38.172046163916434 validation loss : 51.77891743183136 Real validation loss : 223810819.66666666
EarlyStopping counter: 9 out of 100
30 tarainning loss : 37.71469002719944 validation loss : 45.05951976776123 Real validation loss : 231403861.33333334
EarlyStopping counter: 10 out of 100
31 tarainning loss : 37.18688445759945 validation loss : 50.86940014362335 Real validation loss : 225423901.0
EarlyStopping counter: 11 out of 100
32 tarainning loss : 36.888765297585984 validation loss : 45.20161944627762 Real validation loss : 231177939.83333334
EarlyStopping counter: 12 out of 100
33 tarainning loss : 36.350302042529904 validation loss : 47.20314703385035 Real validation loss : 227322115.83333334
EarlyStopping counter: 13 out of 100
34 tarainning loss : 35.77752226833279 validation loss : 47.871845841407776 Real validation loss : 235902026.66666666
EarlyStopping counter: 14 out of 100
35 tarainning loss : 35.30674004710986 validation loss : 45.93091873327891 Real validation loss : 232184905.33333334
EarlyStopping counter: 15 out of 100
36 tarainning loss : 34.71504258422052 validation loss : 50.22673084338506 Real validation loss : 224785680.0
EarlyStopping counter: 16 out of 100
37 tarainning loss : 34.266284217684486 validation loss : 49.805045088132225 Real validation loss : 236350277.66666666
EarlyStopping counter: 17 out of 100
38 tarainning loss : 33.691143918318645 validation loss : 47.197341084480286 Real validation loss : 228678393.0
EarlyStopping counter: 18 out of 100
39 tarainning loss : 33.04302023841388 validation loss : 47.1848051349322 Real validation loss : 229788537.0
EarlyStopping counter: 19 out of 100
40 tarainning loss : 32.57425131491565 validation loss : 48.887126326560974 Real validation loss : 226934013.83333334
EarlyStopping counter: 20 out of 100
41 tarainning loss : 31.99813286567578 validation loss : 48.142165998617806 Real validation loss : 233097686.0
EarlyStopping counter: 21 out of 100
42 tarainning loss : 31.463027864108703 validation loss : 46.962692300478615 Real validation loss : 231883759.0
EarlyStopping counter: 22 out of 100
43 tarainning loss : 30.947621366768335 validation loss : 46.68350009123484 Real validation loss : 229654124.66666666
EarlyStopping counter: 23 out of 100
44 tarainning loss : 30.357430944280264 validation loss : 48.45191647609075 Real validation loss : 231405072.16666666
EarlyStopping counter: 24 out of 100
45 tarainning loss : 29.792944719407068 validation loss : 47.72457160552343 Real validation loss : 230664149.5
EarlyStopping counter: 25 out of 100
46 tarainning loss : 29.25088447480808 validation loss : 47.74850034713745 Real validation loss : 229628989.0
EarlyStopping counter: 26 out of 100
47 tarainning loss : 28.57582471005101 validation loss : 49.17122274637222 Real validation loss : 230402551.33333334
EarlyStopping counter: 27 out of 100
48 tarainning loss : 28.111709604725768 validation loss : 48.989354173342385 Real validation loss : 230050747.66666666
EarlyStopping counter: 28 out of 100
49 tarainning loss : 27.232095773379424 validation loss : 50.99659017721812 Real validation loss : 234311639.5
EarlyStopping counter: 29 out of 100
50 tarainning loss : 26.938855069961647 validation loss : 52.13921409845352 Real validation loss : 227877303.5
EarlyStopping counter: 30 out of 100
51 tarainning loss : 26.42187079533368 validation loss : 50.72388275464376 Real validation loss : 233383395.0
EarlyStopping counter: 31 out of 100
52 tarainning loss : 25.805740858905438 validation loss : 51.96012131373087 Real validation loss : 230118046.5
EarlyStopping counter: 32 out of 100
53 tarainning loss : 24.90777283039818 validation loss : 53.17152841885885 Real validation loss : 228873165.16666666
EarlyStopping counter: 33 out of 100
54 tarainning loss : 24.518814585624487 validation loss : 52.516882260640465 Real validation loss : 234159128.83333334
EarlyStopping counter: 34 out of 100
55 tarainning loss : 23.95488732889158 validation loss : 51.11824552218119 Real validation loss : 230388823.33333334
EarlyStopping counter: 35 out of 100
56 tarainning loss : 23.20971753931608 validation loss : 55.12598558266958 Real validation loss : 232158835.5
EarlyStopping counter: 36 out of 100
57 tarainning loss : 22.773975078587764 validation loss : 57.232115944226585 Real validation loss : 236679304.5
EarlyStopping counter: 37 out of 100
58 tarainning loss : 22.2498746799454 validation loss : 59.165844440460205 Real validation loss : 238605342.33333334
EarlyStopping counter: 38 out of 100
59 tarainning loss : 21.552760879146632 validation loss : 59.8101282119751 Real validation loss : 224355218.83333334
EarlyStopping counter: 39 out of 100
60 tarainning loss : 20.99825844695965 validation loss : 55.170352260271706 Real validation loss : 229104354.66666666
EarlyStopping counter: 40 out of 100
61 tarainning loss : 20.434643190466403 validation loss : 56.89095954100291 Real validation loss : 226060152.66666666
EarlyStopping counter: 41 out of 100
62 tarainning loss : 19.924170010367977 validation loss : 55.921138644218445 Real validation loss : 230584092.83333334
EarlyStopping counter: 42 out of 100
63 tarainning loss : 19.31338014390178 validation loss : 56.32816855112711 Real validation loss : 232948112.83333334
EarlyStopping counter: 43 out of 100
64 tarainning loss : 18.854663760133995 validation loss : 55.12482460339864 Real validation loss : 229307427.5
EarlyStopping counter: 44 out of 100
65 tarainning loss : 18.230372217660808 validation loss : 61.861285169919334 Real validation loss : 235573610.0
EarlyStopping counter: 45 out of 100
66 tarainning loss : 17.872351206458255 validation loss : 59.61470937728882 Real validation loss : 234474475.0
EarlyStopping counter: 46 out of 100
67 tarainning loss : 17.236824380617154 validation loss : 59.84803783893585 Real validation loss : 225779408.66666666
EarlyStopping counter: 47 out of 100
68 tarainning loss : 16.888028898526613 validation loss : 67.0793110926946 Real validation loss : 240529198.5
EarlyStopping counter: 48 out of 100
69 tarainning loss : 16.271936999079752 validation loss : 60.65415875116984 Real validation loss : 231795409.16666666
EarlyStopping counter: 49 out of 100
70 tarainning loss : 15.790849203207234 validation loss : 60.16559441884359 Real validation loss : 225817113.5
EarlyStopping counter: 50 out of 100
71 tarainning loss : 15.381652498307734 validation loss : 58.94376162687937 Real validation loss : 226715926.83333334
EarlyStopping counter: 51 out of 100
72 tarainning loss : 14.936624109510669 validation loss : 57.02098333835602 Real validation loss : 230521632.33333334
EarlyStopping counter: 52 out of 100
73 tarainning loss : 14.493222607853841 validation loss : 61.2480274438858 Real validation loss : 225957244.33333334
EarlyStopping counter: 53 out of 100
74 tarainning loss : 14.073792871297734 validation loss : 63.463047663370766 Real validation loss : 235236042.5
EarlyStopping counter: 54 out of 100
75 tarainning loss : 13.674777097189567 validation loss : 56.815083265304565 Real validation loss : 229495409.33333334
EarlyStopping counter: 55 out of 100
76 tarainning loss : 13.278585907672367 validation loss : 60.71741875012716 Real validation loss : 226053155.0
EarlyStopping counter: 56 out of 100
77 tarainning loss : 12.88875404472901 validation loss : 63.979965011278786 Real validation loss : 224025741.16666666
EarlyStopping counter: 57 out of 100
78 tarainning loss : 12.532042976444389 validation loss : 61.996082743008934 Real validation loss : 234473016.16666666
EarlyStopping counter: 58 out of 100
79 tarainning loss : 12.113738575581642 validation loss : 60.7909726301829 Real validation loss : 227560092.16666666
EarlyStopping counter: 59 out of 100
80 tarainning loss : 11.817323037243764 validation loss : 64.51527444521587 Real validation loss : 234388097.16666666
EarlyStopping counter: 60 out of 100
81 tarainning loss : 11.556969771378943 validation loss : 58.67186280091604 Real validation loss : 230286078.66666666
EarlyStopping counter: 61 out of 100
82 tarainning loss : 11.07712805974218 validation loss : 62.2663277387619 Real validation loss : 235444410.83333334
EarlyStopping counter: 62 out of 100
83 tarainning loss : 10.830471351918511 validation loss : 63.66492962837219 Real validation loss : 226624783.0
EarlyStopping counter: 63 out of 100
84 tarainning loss : 10.6131460282312 validation loss : 66.20994738737743 Real validation loss : 237676535.33333334
EarlyStopping counter: 64 out of 100
85 tarainning loss : 10.294937063169668 validation loss : 63.24732538064321 Real validation loss : 231786741.66666666
EarlyStopping counter: 65 out of 100
86 tarainning loss : 10.007972360438476 validation loss : 62.71758504708608 Real validation loss : 229654847.66666666
EarlyStopping counter: 66 out of 100
87 tarainning loss : 9.760701379488523 validation loss : 59.96350344022115 Real validation loss : 230189825.66666666
EarlyStopping counter: 67 out of 100
88 tarainning loss : 9.544637984404558 validation loss : 61.308043003082275 Real validation loss : 230596103.16666666
EarlyStopping counter: 68 out of 100
89 tarainning loss : 9.25910656855272 validation loss : 62.79961276054382 Real validation loss : 226522933.5
EarlyStopping counter: 69 out of 100
90 tarainning loss : 9.014401492097587 validation loss : 64.44327227274577 Real validation loss : 224135735.66666666
EarlyStopping counter: 70 out of 100
91 tarainning loss : 8.737659085624966 validation loss : 84.03755176067352 Real validation loss : 244571245.33333334
EarlyStopping counter: 71 out of 100
92 tarainning loss : 8.588976700059083 validation loss : 60.598163763682045 Real validation loss : 231124318.33333334
EarlyStopping counter: 72 out of 100
93 tarainning loss : 8.32124093006979 validation loss : 90.54404028256734 Real validation loss : 245339276.66666666
EarlyStopping counter: 73 out of 100
94 tarainning loss : 8.26562408507261 validation loss : 65.97738587856293 Real validation loss : 223945737.0
EarlyStopping counter: 74 out of 100
95 tarainning loss : 7.9686036591136125 validation loss : 62.40575214227041 Real validation loss : 226454492.0
EarlyStopping counter: 75 out of 100
96 tarainning loss : 7.877795571268464 validation loss : 61.663843194643654 Real validation loss : 229023862.33333334
EarlyStopping counter: 76 out of 100
97 tarainning loss : 7.683492672396518 validation loss : 63.47915240128835 Real validation loss : 224090702.0
EarlyStopping counter: 77 out of 100
98 tarainning loss : 7.45716374885989 validation loss : 64.70758124192555 Real validation loss : 233155405.16666666
EarlyStopping counter: 78 out of 100
99 tarainning loss : 7.3244867912282485 validation loss : 61.74348258972168 Real validation loss : 230060965.16666666
EarlyStopping counter: 79 out of 100
100 tarainning loss : 7.163944743720139 validation loss : 63.406062602996826 Real validation loss : 227403316.0
EarlyStopping counter: 80 out of 100
101 tarainning loss : 7.020082063162468 validation loss : 70.04841009775798 Real validation loss : 238599340.16666666
EarlyStopping counter: 81 out of 100
102 tarainning loss : 6.888280051095145 validation loss : 77.67253084977467 Real validation loss : 239864581.0
EarlyStopping counter: 82 out of 100
103 tarainning loss : 6.828819667683673 validation loss : 61.403552651405334 Real validation loss : 232424450.16666666
EarlyStopping counter: 83 out of 100
104 tarainning loss : 6.507424030203963 validation loss : 61.82008679707845 Real validation loss : 231591232.16666666
EarlyStopping counter: 84 out of 100
105 tarainning loss : 6.583711455408899 validation loss : 67.86078242460887 Real validation loss : 238367953.66666666
EarlyStopping counter: 85 out of 100
106 tarainning loss : 6.3269739694707825 validation loss : 65.90524025758107 Real validation loss : 227253410.0
EarlyStopping counter: 86 out of 100
107 tarainning loss : 6.248823661479225 validation loss : 72.32630336284637 Real validation loss : 221452922.66666666
EarlyStopping counter: 87 out of 100
108 tarainning loss : 6.151315126944025 validation loss : 66.15777619679768 Real validation loss : 238512784.83333334
EarlyStopping counter: 88 out of 100
109 tarainning loss : 6.043820431160583 validation loss : 63.283462127049766 Real validation loss : 229977112.83333334
EarlyStopping counter: 89 out of 100
110 tarainning loss : 5.920117160127172 validation loss : 67.75587924321492 Real validation loss : 223981513.16666666
EarlyStopping counter: 90 out of 100
111 tarainning loss : 5.856706304287692 validation loss : 64.14196674029033 Real validation loss : 234460704.0
EarlyStopping counter: 91 out of 100
112 tarainning loss : 5.848603702935135 validation loss : 62.45494794845581 Real validation loss : 232784886.5
EarlyStopping counter: 92 out of 100
113 tarainning loss : 5.690344989846606 validation loss : 63.557104428609215 Real validation loss : 225561232.66666666
EarlyStopping counter: 93 out of 100
114 tarainning loss : 5.533048922550006 validation loss : 65.36847480138142 Real validation loss : 235215529.66666666
EarlyStopping counter: 94 out of 100
115 tarainning loss : 5.49408232837642 validation loss : 69.01114002863567 Real validation loss : 237827855.33333334
EarlyStopping counter: 95 out of 100
116 tarainning loss : 5.34391635773535 validation loss : 74.25438352425893 Real validation loss : 241399125.83333334
EarlyStopping counter: 96 out of 100
117 tarainning loss : 5.347121763666835 validation loss : 65.41959698994954 Real validation loss : 225651671.5
EarlyStopping counter: 97 out of 100
118 tarainning loss : 5.302365532708825 validation loss : 73.86283365885417 Real validation loss : 220758047.16666666
EarlyStopping counter: 98 out of 100
119 tarainning loss : 5.106539630952388 validation loss : 73.39461628595988 Real validation loss : 240686533.0
EarlyStopping counter: 99 out of 100
120 tarainning loss : 5.173578499185305 validation loss : 61.682266434033714 Real validation loss : 228889719.16666666
EarlyStopping counter: 100 out of 100
Early stopping
0
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 13724.71389566524, 'Validation Loss': 3267.6726735432944, 'Real Validation Loss': 96083676.91666667} 0
1
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 671.4061151157044, 'Validation Loss': 88.95704579353333, 'Real Validation Loss': 219939657.16666666} 1
2
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 55.17156625200224, 'Validation Loss': 74.80865474541982, 'Real Validation Loss': 219061850.33333334} 2
3
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 51.809299319006044, 'Validation Loss': 76.75867033004761, 'Real Validation Loss': 244686395.5} 3
4
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 50.22329293447272, 'Validation Loss': 84.05155646800995, 'Real Validation Loss': 215220882.0} 4
5
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 49.415657648409024, 'Validation Loss': 51.03387971719106, 'Real Validation Loss': 229128293.83333334} 5
6
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 48.61163936280017, 'Validation Loss': 52.76537322998047, 'Real Validation Loss': 236053450.5} 6
7
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 47.68549994872407, 'Validation Loss': 55.877509117126465, 'Real Validation Loss': 224119039.83333334} 7
8
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 46.90482881528522, 'Validation Loss': 55.41746779282888, 'Real Validation Loss': 224726936.33333334} 8
9
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 46.323433887286704, 'Validation Loss': 50.654478907585144, 'Real Validation Loss': 224971420.83333334} 9
10
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 45.51629991643863, 'Validation Loss': 46.83253425359726, 'Real Validation Loss': 228566011.0} 10
11
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 45.26300569036841, 'Validation Loss': 48.94963786999384, 'Real Validation Loss': 226297999.0} 11
12
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 44.70927285460626, 'Validation Loss': 53.11410268147787, 'Real Validation Loss': 223782526.33333334} 12
13
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 44.32970690196026, 'Validation Loss': 46.139405608177185, 'Real Validation Loss': 233278172.0} 13
14
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 43.83722374042396, 'Validation Loss': 50.5711966753006, 'Real Validation Loss': 224379426.5} 14
15
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 43.38982467351391, 'Validation Loss': 50.60744818051656, 'Real Validation Loss': 225369005.33333334} 15
16
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 43.09349248043675, 'Validation Loss': 62.46946108341217, 'Real Validation Loss': 219298593.16666666} 16
17
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 42.86584247424124, 'Validation Loss': 45.78803372383118, 'Real Validation Loss': 228000439.0} 17
18
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 42.246176898401345, 'Validation Loss': 54.162611762682594, 'Real Validation Loss': 222433613.5} 18
19
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 42.03859065994523, 'Validation Loss': 52.9555057088534, 'Real Validation Loss': 223586432.83333334} 19
20
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 41.63284211264994, 'Validation Loss': 44.14774298667908, 'Real Validation Loss': 231783819.33333334} 20
21
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 41.523906737761294, 'Validation Loss': 45.973742147286735, 'Real Validation Loss': 229782287.33333334} 21
22
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 40.9435513797625, 'Validation Loss': 45.107646465301514, 'Real Validation Loss': 233673462.0} 22
23
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 40.54396276361508, 'Validation Loss': 45.95532397429148, 'Real Validation Loss': 234718536.33333334} 23
24
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 40.22641805146343, 'Validation Loss': 45.880783240000405, 'Real Validation Loss': 234780527.5} 24
25
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 39.58822547092663, 'Validation Loss': 55.84118286768595, 'Real Validation Loss': 240233908.33333334} 25
26
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 39.29293094550017, 'Validation Loss': 46.358010391394295, 'Real Validation Loss': 227525203.66666666} 26
27
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 39.015537131973204, 'Validation Loss': 48.25741831461588, 'Real Validation Loss': 237109621.16666666} 27
28
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 38.70259063490722, 'Validation Loss': 44.528879483540855, 'Real Validation Loss': 228964815.66666666} 28
29
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 38.172046163916434, 'Validation Loss': 51.77891743183136, 'Real Validation Loss': 223810819.66666666} 29
30
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 37.71469002719944, 'Validation Loss': 45.05951976776123, 'Real Validation Loss': 231403861.33333334} 30
31
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 37.18688445759945, 'Validation Loss': 50.86940014362335, 'Real Validation Loss': 225423901.0} 31
32
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 36.888765297585984, 'Validation Loss': 45.20161944627762, 'Real Validation Loss': 231177939.83333334} 32
33
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 36.350302042529904, 'Validation Loss': 47.20314703385035, 'Real Validation Loss': 227322115.83333334} 33
34
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 35.77752226833279, 'Validation Loss': 47.871845841407776, 'Real Validation Loss': 235902026.66666666} 34
35
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 35.30674004710986, 'Validation Loss': 45.93091873327891, 'Real Validation Loss': 232184905.33333334} 35
36
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 34.71504258422052, 'Validation Loss': 50.22673084338506, 'Real Validation Loss': 224785680.0} 36
37
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 34.266284217684486, 'Validation Loss': 49.805045088132225, 'Real Validation Loss': 236350277.66666666} 37
38
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 33.691143918318645, 'Validation Loss': 47.197341084480286, 'Real Validation Loss': 228678393.0} 38
39
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 33.04302023841388, 'Validation Loss': 47.1848051349322, 'Real Validation Loss': 229788537.0} 39
40
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 32.57425131491565, 'Validation Loss': 48.887126326560974, 'Real Validation Loss': 226934013.83333334} 40
41
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 31.99813286567578, 'Validation Loss': 48.142165998617806, 'Real Validation Loss': 233097686.0} 41
42
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 31.463027864108703, 'Validation Loss': 46.962692300478615, 'Real Validation Loss': 231883759.0} 42
43
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 30.947621366768335, 'Validation Loss': 46.68350009123484, 'Real Validation Loss': 229654124.66666666} 43
44
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 30.357430944280264, 'Validation Loss': 48.45191647609075, 'Real Validation Loss': 231405072.16666666} 44
45
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 29.792944719407068, 'Validation Loss': 47.72457160552343, 'Real Validation Loss': 230664149.5} 45
46
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 29.25088447480808, 'Validation Loss': 47.74850034713745, 'Real Validation Loss': 229628989.0} 46
47
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 28.57582471005101, 'Validation Loss': 49.17122274637222, 'Real Validation Loss': 230402551.33333334} 47
48
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 28.111709604725768, 'Validation Loss': 48.989354173342385, 'Real Validation Loss': 230050747.66666666} 48
49
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 27.232095773379424, 'Validation Loss': 50.99659017721812, 'Real Validation Loss': 234311639.5} 49
50
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 26.938855069961647, 'Validation Loss': 52.13921409845352, 'Real Validation Loss': 227877303.5} 50
51
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 26.42187079533368, 'Validation Loss': 50.72388275464376, 'Real Validation Loss': 233383395.0} 51
52
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 25.805740858905438, 'Validation Loss': 51.96012131373087, 'Real Validation Loss': 230118046.5} 52
53
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 24.90777283039818, 'Validation Loss': 53.17152841885885, 'Real Validation Loss': 228873165.16666666} 53
54
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 24.518814585624487, 'Validation Loss': 52.516882260640465, 'Real Validation Loss': 234159128.83333334} 54
55
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 23.95488732889158, 'Validation Loss': 51.11824552218119, 'Real Validation Loss': 230388823.33333334} 55
56
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 23.20971753931608, 'Validation Loss': 55.12598558266958, 'Real Validation Loss': 232158835.5} 56
57
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 22.773975078587764, 'Validation Loss': 57.232115944226585, 'Real Validation Loss': 236679304.5} 57
58
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 22.2498746799454, 'Validation Loss': 59.165844440460205, 'Real Validation Loss': 238605342.33333334} 58
59
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 21.552760879146632, 'Validation Loss': 59.8101282119751, 'Real Validation Loss': 224355218.83333334} 59
60
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 20.99825844695965, 'Validation Loss': 55.170352260271706, 'Real Validation Loss': 229104354.66666666} 60
61
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 20.434643190466403, 'Validation Loss': 56.89095954100291, 'Real Validation Loss': 226060152.66666666} 61
62
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 19.924170010367977, 'Validation Loss': 55.921138644218445, 'Real Validation Loss': 230584092.83333334} 62
63
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 19.31338014390178, 'Validation Loss': 56.32816855112711, 'Real Validation Loss': 232948112.83333334} 63
64
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 18.854663760133995, 'Validation Loss': 55.12482460339864, 'Real Validation Loss': 229307427.5} 64
65
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 18.230372217660808, 'Validation Loss': 61.861285169919334, 'Real Validation Loss': 235573610.0} 65
66
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 17.872351206458255, 'Validation Loss': 59.61470937728882, 'Real Validation Loss': 234474475.0} 66
67
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 17.236824380617154, 'Validation Loss': 59.84803783893585, 'Real Validation Loss': 225779408.66666666} 67
68
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 16.888028898526613, 'Validation Loss': 67.0793110926946, 'Real Validation Loss': 240529198.5} 68
69
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 16.271936999079752, 'Validation Loss': 60.65415875116984, 'Real Validation Loss': 231795409.16666666} 69
70
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 15.790849203207234, 'Validation Loss': 60.16559441884359, 'Real Validation Loss': 225817113.5} 70
71
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 15.381652498307734, 'Validation Loss': 58.94376162687937, 'Real Validation Loss': 226715926.83333334} 71
72
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 14.936624109510669, 'Validation Loss': 57.02098333835602, 'Real Validation Loss': 230521632.33333334} 72
73
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 14.493222607853841, 'Validation Loss': 61.2480274438858, 'Real Validation Loss': 225957244.33333334} 73
74
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 14.073792871297734, 'Validation Loss': 63.463047663370766, 'Real Validation Loss': 235236042.5} 74
75
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 13.674777097189567, 'Validation Loss': 56.815083265304565, 'Real Validation Loss': 229495409.33333334} 75
76
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 13.278585907672367, 'Validation Loss': 60.71741875012716, 'Real Validation Loss': 226053155.0} 76
77
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 12.88875404472901, 'Validation Loss': 63.979965011278786, 'Real Validation Loss': 224025741.16666666} 77
78
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 12.532042976444389, 'Validation Loss': 61.996082743008934, 'Real Validation Loss': 234473016.16666666} 78
79
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 12.113738575581642, 'Validation Loss': 60.7909726301829, 'Real Validation Loss': 227560092.16666666} 79
80
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 11.817323037243764, 'Validation Loss': 64.51527444521587, 'Real Validation Loss': 234388097.16666666} 80
81
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 11.556969771378943, 'Validation Loss': 58.67186280091604, 'Real Validation Loss': 230286078.66666666} 81
82
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 11.07712805974218, 'Validation Loss': 62.2663277387619, 'Real Validation Loss': 235444410.83333334} 82
83
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 10.830471351918511, 'Validation Loss': 63.66492962837219, 'Real Validation Loss': 226624783.0} 83
84
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 10.6131460282312, 'Validation Loss': 66.20994738737743, 'Real Validation Loss': 237676535.33333334} 84
85
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 10.294937063169668, 'Validation Loss': 63.24732538064321, 'Real Validation Loss': 231786741.66666666} 85
86
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 10.007972360438476, 'Validation Loss': 62.71758504708608, 'Real Validation Loss': 229654847.66666666} 86
87
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 9.760701379488523, 'Validation Loss': 59.96350344022115, 'Real Validation Loss': 230189825.66666666} 87
88
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 9.544637984404558, 'Validation Loss': 61.308043003082275, 'Real Validation Loss': 230596103.16666666} 88
89
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 9.25910656855272, 'Validation Loss': 62.79961276054382, 'Real Validation Loss': 226522933.5} 89
90
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 9.014401492097587, 'Validation Loss': 64.44327227274577, 'Real Validation Loss': 224135735.66666666} 90
91
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 8.737659085624966, 'Validation Loss': 84.03755176067352, 'Real Validation Loss': 244571245.33333334} 91
92
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 8.588976700059083, 'Validation Loss': 60.598163763682045, 'Real Validation Loss': 231124318.33333334} 92
93
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 8.32124093006979, 'Validation Loss': 90.54404028256734, 'Real Validation Loss': 245339276.66666666} 93
94
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 8.26562408507261, 'Validation Loss': 65.97738587856293, 'Real Validation Loss': 223945737.0} 94
95
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 7.9686036591136125, 'Validation Loss': 62.40575214227041, 'Real Validation Loss': 226454492.0} 95
96
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 7.877795571268464, 'Validation Loss': 61.663843194643654, 'Real Validation Loss': 229023862.33333334} 96
97
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 7.683492672396518, 'Validation Loss': 63.47915240128835, 'Real Validation Loss': 224090702.0} 97
98
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 7.45716374885989, 'Validation Loss': 64.70758124192555, 'Real Validation Loss': 233155405.16666666} 98
99
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 7.3244867912282485, 'Validation Loss': 61.74348258972168, 'Real Validation Loss': 230060965.16666666} 99
100
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 7.163944743720139, 'Validation Loss': 63.406062602996826, 'Real Validation Loss': 227403316.0} 100
101
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 7.020082063162468, 'Validation Loss': 70.04841009775798, 'Real Validation Loss': 238599340.16666666} 101
102
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 6.888280051095145, 'Validation Loss': 77.67253084977467, 'Real Validation Loss': 239864581.0} 102
103
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 6.828819667683673, 'Validation Loss': 61.403552651405334, 'Real Validation Loss': 232424450.16666666} 103
104
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 6.507424030203963, 'Validation Loss': 61.82008679707845, 'Real Validation Loss': 231591232.16666666} 104
105
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 6.583711455408899, 'Validation Loss': 67.86078242460887, 'Real Validation Loss': 238367953.66666666} 105
106
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 6.3269739694707825, 'Validation Loss': 65.90524025758107, 'Real Validation Loss': 227253410.0} 106
107
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 6.248823661479225, 'Validation Loss': 72.32630336284637, 'Real Validation Loss': 221452922.66666666} 107
108
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 6.151315126944025, 'Validation Loss': 66.15777619679768, 'Real Validation Loss': 238512784.83333334} 108
109
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 6.043820431160583, 'Validation Loss': 63.283462127049766, 'Real Validation Loss': 229977112.83333334} 109
110
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 5.920117160127172, 'Validation Loss': 67.75587924321492, 'Real Validation Loss': 223981513.16666666} 110
111
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 5.856706304287692, 'Validation Loss': 64.14196674029033, 'Real Validation Loss': 234460704.0} 111
112
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 5.848603702935135, 'Validation Loss': 62.45494794845581, 'Real Validation Loss': 232784886.5} 112
113
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 5.690344989846606, 'Validation Loss': 63.557104428609215, 'Real Validation Loss': 225561232.66666666} 113
114
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 5.533048922550006, 'Validation Loss': 65.36847480138142, 'Real Validation Loss': 235215529.66666666} 114
115
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 5.49408232837642, 'Validation Loss': 69.01114002863567, 'Real Validation Loss': 237827855.33333334} 115
116
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 5.34391635773535, 'Validation Loss': 74.25438352425893, 'Real Validation Loss': 241399125.83333334} 116
117
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 5.347121763666835, 'Validation Loss': 65.41959698994954, 'Real Validation Loss': 225651671.5} 117
118
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 5.302365532708825, 'Validation Loss': 73.86283365885417, 'Real Validation Loss': 220758047.16666666} 118
119
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 5.106539630952388, 'Validation Loss': 73.39461628595988, 'Real Validation Loss': 240686533.0} 119
120
TL Mean Absolute Loss vs Epoch [Y: pr, Learning Rate: 0.0005] {'Training Loss': 5.173578499185305, 'Validation Loss': 61.682266434033714, 'Real Validation Loss': 228889719.16666666} 120


-------------qt---------------
0 tarainning loss : 121990.82656864352 validation loss : 70606.62768554688 Real validation loss : 419180462.3333333
Validation loss decreased (inf --> 70606.627686).  Saving model ...
1 tarainning loss : 31168.211398263433 validation loss : 5174.020182291667 Real validation loss : 2616752184.0
Validation loss decreased (70606.627686 --> 5174.020182).  Saving model ...
2 tarainning loss : 1068.5921190694307 validation loss : 115.61831378936768 Real validation loss : 3731355506.6666665
Validation loss decreased (5174.020182 --> 115.618314).  Saving model ...
3 tarainning loss : 40.28412581927498 validation loss : 58.25264569123586 Real validation loss : 3957840917.3333335
Validation loss decreased (115.618314 --> 58.252646).  Saving model ...
4 tarainning loss : 35.30419176934119 validation loss : 151.2347855567932 Real validation loss : 3688097058.6666665
EarlyStopping counter: 1 out of 100
5 tarainning loss : 33.70818216116369 validation loss : 41.083085556825004 Real validation loss : 3840511061.3333335
Validation loss decreased (58.252646 --> 41.083086).  Saving model ...
6 tarainning loss : 32.98049321305861 validation loss : 37.651959796746574 Real validation loss : 3846477189.3333335
Validation loss decreased (41.083086 --> 37.651960).  Saving model ...
7 tarainning loss : 32.19131205497532 validation loss : 227.02161169052124 Real validation loss : 4178792992.0
EarlyStopping counter: 1 out of 100
8 tarainning loss : 31.890416652784435 validation loss : 50.25620992978414 Real validation loss : 3983168306.6666665
EarlyStopping counter: 2 out of 100
9 tarainning loss : 30.71542125666907 validation loss : 40.21902277072271 Real validation loss : 3832270621.3333335
EarlyStopping counter: 3 out of 100
10 tarainning loss : 30.493185893267512 validation loss : 36.68307503064474 Real validation loss : 3842092213.3333335
Validation loss decreased (37.651960 --> 36.683075).  Saving model ...
11 tarainning loss : 30.167854747797215 validation loss : 124.1422545115153 Real validation loss : 4092820864.0
EarlyStopping counter: 1 out of 100
12 tarainning loss : 29.960229053722298 validation loss : 63.41296148300171 Real validation loss : 3781717050.6666665
EarlyStopping counter: 2 out of 100
13 tarainning loss : 29.44718139793426 validation loss : 60.36939140160879 Real validation loss : 3785454349.3333335
EarlyStopping counter: 3 out of 100
14 tarainning loss : 28.74377352038342 validation loss : 65.83222484588623 Real validation loss : 3776154208.0
EarlyStopping counter: 4 out of 100
15 tarainning loss : 28.424043251677546 validation loss : 34.96844172477722 Real validation loss : 3952939904.0
Validation loss decreased (36.683075 --> 34.968442).  Saving model ...
16 tarainning loss : 28.144209435539196 validation loss : 99.5589165687561 Real validation loss : 4066584848.0
EarlyStopping counter: 1 out of 100
17 tarainning loss : 27.886020980374997 validation loss : 137.62653064727783 Real validation loss : 3694826138.6666665
EarlyStopping counter: 2 out of 100
18 tarainning loss : 27.327399035112574 validation loss : 26.622238874435425 Real validation loss : 3904265733.3333335
Validation loss decreased (34.968442 --> 26.622239).  Saving model ...
19 tarainning loss : 27.185663601986548 validation loss : 133.55601000785828 Real validation loss : 3696872882.6666665
EarlyStopping counter: 1 out of 100
20 tarainning loss : 26.627577225471388 validation loss : 28.140056709448498 Real validation loss : 3866817381.3333335
EarlyStopping counter: 2 out of 100
21 tarainning loss : 26.303468782967382 validation loss : 32.738679667313896 Real validation loss : 3953424384.0
EarlyStopping counter: 3 out of 100
22 tarainning loss : 25.995981105189493 validation loss : 33.410863836606346 Real validation loss : 3950842277.3333335
EarlyStopping counter: 4 out of 100
23 tarainning loss : 25.60127372166745 validation loss : 31.440934081872303 Real validation loss : 3852755693.3333335
EarlyStopping counter: 5 out of 100
24 tarainning loss : 25.447811357940633 validation loss : 28.08665857712428 Real validation loss : 3867481936.0
EarlyStopping counter: 6 out of 100
25 tarainning loss : 25.095797633749786 validation loss : 75.82124451796214 Real validation loss : 3760433416.0
EarlyStopping counter: 7 out of 100
26 tarainning loss : 24.921387323701992 validation loss : 31.57340528567632 Real validation loss : 3849137058.6666665
EarlyStopping counter: 8 out of 100
27 tarainning loss : 24.490558126807056 validation loss : 37.88368364175161 Real validation loss : 3966091408.0
EarlyStopping counter: 9 out of 100
28 tarainning loss : 24.07582614743694 validation loss : 29.27215180794398 Real validation loss : 3857658784.0
EarlyStopping counter: 10 out of 100
29 tarainning loss : 23.83254006087077 validation loss : 31.454302807648975 Real validation loss : 3847702013.3333335
EarlyStopping counter: 11 out of 100
30 tarainning loss : 23.508474687448803 validation loss : 31.719089488188427 Real validation loss : 3848767072.0
EarlyStopping counter: 12 out of 100
31 tarainning loss : 23.431596662238885 validation loss : 25.61335356036822 Real validation loss : 3911025978.6666665
Validation loss decreased (26.622239 --> 25.613354).  Saving model ...
32 tarainning loss : 23.121838215919183 validation loss : 32.189344584941864 Real validation loss : 3950043384.0
EarlyStopping counter: 1 out of 100
33 tarainning loss : 22.992412193418332 validation loss : 28.197611391544342 Real validation loss : 3934446480.0
EarlyStopping counter: 2 out of 100
34 tarainning loss : 22.850885299992594 validation loss : 26.415917833646137 Real validation loss : 3874630893.3333335
EarlyStopping counter: 3 out of 100
35 tarainning loss : 22.767432606548343 validation loss : 26.697349468866985 Real validation loss : 3871060722.6666665
EarlyStopping counter: 4 out of 100
36 tarainning loss : 22.515833782181048 validation loss : 26.25241349140803 Real validation loss : 3882009826.6666665
EarlyStopping counter: 5 out of 100
37 tarainning loss : 22.33225420855601 validation loss : 26.058087070782978 Real validation loss : 3921450080.0
EarlyStopping counter: 6 out of 100
38 tarainning loss : 22.132647319358735 validation loss : 26.58012478550275 Real validation loss : 3919146010.6666665
EarlyStopping counter: 7 out of 100
39 tarainning loss : 21.97791701750549 validation loss : 42.38695917526881 Real validation loss : 3815254242.6666665
EarlyStopping counter: 8 out of 100
40 tarainning loss : 21.746803789901232 validation loss : 27.17983188231786 Real validation loss : 3927003429.3333335
EarlyStopping counter: 9 out of 100
41 tarainning loss : 21.665225967667205 validation loss : 25.13339987397194 Real validation loss : 3885947117.3333335
Validation loss decreased (25.613354 --> 25.133400).  Saving model ...
42 tarainning loss : 21.43669461141564 validation loss : 28.353133857250214 Real validation loss : 3931516800.0
EarlyStopping counter: 1 out of 100
43 tarainning loss : 21.235828769628842 validation loss : 25.292912274599075 Real validation loss : 3896928912.0
EarlyStopping counter: 2 out of 100
44 tarainning loss : 21.204337063810616 validation loss : 25.001441578070324 Real validation loss : 3893208320.0
Validation loss decreased (25.133400 --> 25.001442).  Saving model ...
45 tarainning loss : 20.93177771912021 validation loss : 36.94772690534592 Real validation loss : 3830102826.6666665
EarlyStopping counter: 1 out of 100
46 tarainning loss : 20.691927056168822 validation loss : 31.53337899843852 Real validation loss : 3850978224.0
EarlyStopping counter: 2 out of 100
47 tarainning loss : 20.481796215902307 validation loss : 25.646468589703243 Real validation loss : 3910500768.0
EarlyStopping counter: 3 out of 100
48 tarainning loss : 20.330260665513585 validation loss : 36.77145719528198 Real validation loss : 3965015360.0
EarlyStopping counter: 4 out of 100
49 tarainning loss : 20.05566485118741 validation loss : 24.681484560171764 Real validation loss : 3889420618.6666665
Validation loss decreased (25.001442 --> 24.681485).  Saving model ...
50 tarainning loss : 19.83357418130297 validation loss : 27.340161840120953 Real validation loss : 3868547080.0
EarlyStopping counter: 1 out of 100
51 tarainning loss : 19.65677625073674 validation loss : 25.682156652212143 Real validation loss : 3895145450.6666665
EarlyStopping counter: 2 out of 100
52 tarainning loss : 19.3754465045654 validation loss : 26.07506142059962 Real validation loss : 3875990293.3333335
EarlyStopping counter: 3 out of 100
53 tarainning loss : 19.06571068270022 validation loss : 30.324598054091137 Real validation loss : 3941099632.0
EarlyStopping counter: 4 out of 100
54 tarainning loss : 18.79072440686107 validation loss : 26.710922519365948 Real validation loss : 3917476749.3333335
EarlyStopping counter: 5 out of 100
55 tarainning loss : 18.600400444720705 validation loss : 26.20081216096878 Real validation loss : 3912606778.6666665
EarlyStopping counter: 6 out of 100
56 tarainning loss : 18.347335719187324 validation loss : 25.90769390265147 Real validation loss : 3887503808.0
EarlyStopping counter: 7 out of 100
57 tarainning loss : 18.015206291978668 validation loss : 26.574530204137165 Real validation loss : 3905073621.3333335
EarlyStopping counter: 8 out of 100
58 tarainning loss : 17.787628285069296 validation loss : 29.29939502477646 Real validation loss : 3859669912.0
EarlyStopping counter: 9 out of 100
59 tarainning loss : 17.61899738761732 validation loss : 26.15014676253001 Real validation loss : 3902426085.3333335
EarlyStopping counter: 10 out of 100
60 tarainning loss : 17.239120847119572 validation loss : 35.18172194560369 Real validation loss : 3837805021.3333335
EarlyStopping counter: 11 out of 100
61 tarainning loss : 16.95000545756689 validation loss : 34.51649008194605 Real validation loss : 3950627562.6666665
EarlyStopping counter: 12 out of 100
62 tarainning loss : 16.73944941229464 validation loss : 65.37929447491963 Real validation loss : 4017731066.6666665
EarlyStopping counter: 13 out of 100
63 tarainning loss : 16.441898729666814 validation loss : 32.66037114461263 Real validation loss : 3936279493.3333335
EarlyStopping counter: 14 out of 100
64 tarainning loss : 16.222241991625545 validation loss : 28.26455295085907 Real validation loss : 3869289397.3333335
EarlyStopping counter: 15 out of 100
65 tarainning loss : 15.937849359774809 validation loss : 33.84966387351354 Real validation loss : 3850954205.3333335
EarlyStopping counter: 16 out of 100
66 tarainning loss : 15.519656636299343 validation loss : 35.05185697476069 Real validation loss : 3843145498.6666665
EarlyStopping counter: 17 out of 100
67 tarainning loss : 15.291007119425002 validation loss : 28.740106185277302 Real validation loss : 3923447890.6666665
EarlyStopping counter: 18 out of 100
68 tarainning loss : 15.02519144330706 validation loss : 29.2298504114151 Real validation loss : 3916624226.6666665
EarlyStopping counter: 19 out of 100
69 tarainning loss : 14.698289687480402 validation loss : 28.1136767466863 Real validation loss : 3876153072.0
EarlyStopping counter: 20 out of 100
70 tarainning loss : 14.566599670900118 validation loss : 29.707796196142834 Real validation loss : 3874590741.3333335
EarlyStopping counter: 21 out of 100
71 tarainning loss : 14.257581382091518 validation loss : 39.13530832529068 Real validation loss : 3836399525.3333335
EarlyStopping counter: 22 out of 100
72 tarainning loss : 13.990856524376225 validation loss : 28.56139103571574 Real validation loss : 3897922984.0
EarlyStopping counter: 23 out of 100
73 tarainning loss : 13.72322645349865 validation loss : 27.465085099140804 Real validation loss : 3888694266.6666665
EarlyStopping counter: 24 out of 100
74 tarainning loss : 13.480629487243892 validation loss : 34.29524028301239 Real validation loss : 3846608922.6666665
EarlyStopping counter: 25 out of 100
75 tarainning loss : 13.100761136096239 validation loss : 31.164789140224457 Real validation loss : 3871127797.3333335
EarlyStopping counter: 26 out of 100
76 tarainning loss : 12.963326692893652 validation loss : 27.87096107006073 Real validation loss : 3895387304.0
EarlyStopping counter: 27 out of 100
77 tarainning loss : 12.631368715828712 validation loss : 28.65359769264857 Real validation loss : 3925474562.6666665
EarlyStopping counter: 28 out of 100
78 tarainning loss : 12.3384030405847 validation loss : 28.62678196032842 Real validation loss : 3917128098.6666665
EarlyStopping counter: 29 out of 100
79 tarainning loss : 12.271371840180763 validation loss : 28.093776792287827 Real validation loss : 3908706368.0
EarlyStopping counter: 30 out of 100
80 tarainning loss : 11.940666610572785 validation loss : 29.04139306147893 Real validation loss : 3885780192.0
EarlyStopping counter: 31 out of 100
81 tarainning loss : 11.767241931055352 validation loss : 31.426722864309948 Real validation loss : 3865512389.3333335
EarlyStopping counter: 32 out of 100
82 tarainning loss : 11.559038481581101 validation loss : 30.574711362520855 Real validation loss : 3871998576.0
EarlyStopping counter: 33 out of 100
83 tarainning loss : 11.332952802490594 validation loss : 65.63504016399384 Real validation loss : 4013399354.6666665
EarlyStopping counter: 34 out of 100
84 tarainning loss : 10.942369520429859 validation loss : 29.596181293328602 Real validation loss : 3891243405.3333335
EarlyStopping counter: 35 out of 100
85 tarainning loss : 10.806378074586 validation loss : 37.05503040552139 Real validation loss : 3845768392.0
EarlyStopping counter: 36 out of 100
86 tarainning loss : 10.570183309627549 validation loss : 31.17398927609126 Real validation loss : 3928174357.3333335
EarlyStopping counter: 37 out of 100
87 tarainning loss : 10.411892746566632 validation loss : 31.677943607171375 Real validation loss : 3915106509.3333335
EarlyStopping counter: 38 out of 100
88 tarainning loss : 10.227363863903761 validation loss : 34.33979139725367 Real validation loss : 3857399178.6666665
EarlyStopping counter: 39 out of 100
89 tarainning loss : 9.945294296444635 validation loss : 31.361196796099346 Real validation loss : 3913725402.6666665
EarlyStopping counter: 40 out of 100
90 tarainning loss : 9.806817009752105 validation loss : 30.155455887317657 Real validation loss : 3912338818.6666665
EarlyStopping counter: 41 out of 100
91 tarainning loss : 9.477891177681139 validation loss : 31.782987018426258 Real validation loss : 3910425968.0
EarlyStopping counter: 42 out of 100
92 tarainning loss : 9.45680114388622 validation loss : 31.302985171477 Real validation loss : 3908018186.6666665
EarlyStopping counter: 43 out of 100
93 tarainning loss : 9.194191280854952 validation loss : 30.67587920029958 Real validation loss : 3890271392.0
EarlyStopping counter: 44 out of 100
94 tarainning loss : 9.030391560000798 validation loss : 31.078803102175396 Real validation loss : 3891972029.3333335
EarlyStopping counter: 45 out of 100
95 tarainning loss : 8.826681525179161 validation loss : 34.43496519327164 Real validation loss : 3936432056.0
EarlyStopping counter: 46 out of 100
96 tarainning loss : 8.65395201549305 validation loss : 31.80392263333003 Real validation loss : 3866700610.6666665
EarlyStopping counter: 47 out of 100
97 tarainning loss : 8.490998361870002 validation loss : 30.916597942511242 Real validation loss : 3906572541.3333335
EarlyStopping counter: 48 out of 100
98 tarainning loss : 8.225875235166336 validation loss : 31.5603440006574 Real validation loss : 3877217944.0
EarlyStopping counter: 49 out of 100
99 tarainning loss : 8.116270314037878 validation loss : 42.50951260328293 Real validation loss : 3960205989.3333335
EarlyStopping counter: 50 out of 100
100 tarainning loss : 7.9774060655546375 validation loss : 34.18173533678055 Real validation loss : 3932043325.3333335
EarlyStopping counter: 51 out of 100
101 tarainning loss : 7.794848103354518 validation loss : 32.137134631474815 Real validation loss : 3911513757.3333335
EarlyStopping counter: 52 out of 100
102 tarainning loss : 7.619910417659255 validation loss : 31.774206658204395 Real validation loss : 3901151058.6666665
EarlyStopping counter: 53 out of 100
103 tarainning loss : 7.4595335820399296 validation loss : 34.61835730075836 Real validation loss : 3857695058.6666665
EarlyStopping counter: 54 out of 100
104 tarainning loss : 7.364134790388035 validation loss : 30.80674300591151 Real validation loss : 3903901642.6666665
EarlyStopping counter: 55 out of 100
105 tarainning loss : 7.1439089725089415 validation loss : 33.40014706055323 Real validation loss : 3927992312.0
EarlyStopping counter: 56 out of 100
106 tarainning loss : 7.051515872950323 validation loss : 31.483944714069366 Real validation loss : 3891517632.0
EarlyStopping counter: 57 out of 100
107 tarainning loss : 6.803079029523217 validation loss : 40.418945054213204 Real validation loss : 3839757408.0
EarlyStopping counter: 58 out of 100
108 tarainning loss : 6.653356819915271 validation loss : 33.72474857171377 Real validation loss : 3865092485.3333335
EarlyStopping counter: 59 out of 100
109 tarainning loss : 6.560222694476966 validation loss : 40.946408450603485 Real validation loss : 3838469581.3333335
EarlyStopping counter: 60 out of 100
110 tarainning loss : 6.539018099461127 validation loss : 34.71278619766235 Real validation loss : 3866548624.0
EarlyStopping counter: 61 out of 100
111 tarainning loss : 6.376779452532647 validation loss : 30.69959380229314 Real validation loss : 3897803280.0
EarlyStopping counter: 62 out of 100
112 tarainning loss : 6.252618025670983 validation loss : 39.1821336944898 Real validation loss : 3843604149.3333335
EarlyStopping counter: 63 out of 100
113 tarainning loss : 6.135300074148615 validation loss : 44.019481201966606 Real validation loss : 3830266864.0
EarlyStopping counter: 64 out of 100
114 tarainning loss : 6.0473347557012875 validation loss : 42.71011475721995 Real validation loss : 3830531904.0
EarlyStopping counter: 65 out of 100
115 tarainning loss : 5.894636024810071 validation loss : 32.85415053367615 Real validation loss : 3873975082.6666665
EarlyStopping counter: 66 out of 100
116 tarainning loss : 5.713560559334011 validation loss : 31.569264113903046 Real validation loss : 3905152749.3333335
EarlyStopping counter: 67 out of 100
117 tarainning loss : 5.669955794495649 validation loss : 35.12102780739466 Real validation loss : 3929644890.6666665
EarlyStopping counter: 68 out of 100
118 tarainning loss : 5.548406522208397 validation loss : 31.457873463630676 Real validation loss : 3900817936.0
EarlyStopping counter: 69 out of 100
119 tarainning loss : 5.379923404903587 validation loss : 38.42040238777796 Real validation loss : 3945498589.3333335
EarlyStopping counter: 70 out of 100
120 tarainning loss : 5.314359505867114 validation loss : 32.18323540687561 Real validation loss : 3911382170.6666665
EarlyStopping counter: 71 out of 100
121 tarainning loss : 5.268381647794931 validation loss : 32.10225409269333 Real validation loss : 3916973906.6666665
EarlyStopping counter: 72 out of 100
122 tarainning loss : 5.177273080358343 validation loss : 33.74509543180466 Real validation loss : 3872762954.6666665
EarlyStopping counter: 73 out of 100
123 tarainning loss : 4.954042874032517 validation loss : 31.186759690443676 Real validation loss : 3900902424.0
EarlyStopping counter: 74 out of 100
124 tarainning loss : 4.9504694291836 validation loss : 47.19587071736654 Real validation loss : 3820915682.6666665
EarlyStopping counter: 75 out of 100
125 tarainning loss : 4.939876739819428 validation loss : 34.43169198433558 Real validation loss : 3887138221.3333335
EarlyStopping counter: 76 out of 100
126 tarainning loss : 4.768576477020783 validation loss : 33.82926535606384 Real validation loss : 3917352594.6666665
EarlyStopping counter: 77 out of 100
127 tarainning loss : 4.714482824893016 validation loss : 32.040882090727486 Real validation loss : 3889170237.3333335
EarlyStopping counter: 78 out of 100
128 tarainning loss : 4.63675929272003 validation loss : 31.728960514068604 Real validation loss : 3889368981.3333335
EarlyStopping counter: 79 out of 100
129 tarainning loss : 4.550404204922297 validation loss : 32.95868194103241 Real validation loss : 3877922586.6666665
EarlyStopping counter: 80 out of 100
130 tarainning loss : 4.477961958938939 validation loss : 32.92372876405716 Real validation loss : 3884497184.0
EarlyStopping counter: 81 out of 100
131 tarainning loss : 4.344510162486005 validation loss : 32.57919991016388 Real validation loss : 3887681722.6666665
EarlyStopping counter: 82 out of 100
132 tarainning loss : 4.322061800550508 validation loss : 35.61603391170502 Real validation loss : 3932601464.0
EarlyStopping counter: 83 out of 100
133 tarainning loss : 4.234244526916844 validation loss : 59.54030156135559 Real validation loss : 3998186282.6666665
EarlyStopping counter: 84 out of 100
134 tarainning loss : 4.1891318429969395 validation loss : 35.98221643765768 Real validation loss : 3858873394.6666665
EarlyStopping counter: 85 out of 100
135 tarainning loss : 4.111710840252718 validation loss : 39.48455903927485 Real validation loss : 3950364162.6666665
EarlyStopping counter: 86 out of 100
136 tarainning loss : 4.027033664920852 validation loss : 43.47983447710673 Real validation loss : 3956618168.0
EarlyStopping counter: 87 out of 100
137 tarainning loss : 4.060347080230713 validation loss : 38.25875627994537 Real validation loss : 3942667253.3333335
EarlyStopping counter: 88 out of 100
138 tarainning loss : 3.9476169621178863 validation loss : 33.39826476573944 Real validation loss : 3921333693.3333335
EarlyStopping counter: 89 out of 100
139 tarainning loss : 3.963004190674928 validation loss : 33.452668050924935 Real validation loss : 3898165858.6666665
EarlyStopping counter: 90 out of 100
140 tarainning loss : 3.8699479959270433 validation loss : 32.2659263809522 Real validation loss : 3893894096.0
EarlyStopping counter: 91 out of 100
141 tarainning loss : 3.7593644255891854 validation loss : 70.10256842772166 Real validation loss : 4013796554.6666665
EarlyStopping counter: 92 out of 100
142 tarainning loss : 3.688915642967074 validation loss : 32.28502768278122 Real validation loss : 3895678605.3333335
EarlyStopping counter: 93 out of 100
143 tarainning loss : 3.7132478782108853 validation loss : 34.10457170009613 Real validation loss : 3867559333.3333335
EarlyStopping counter: 94 out of 100
144 tarainning loss : 3.574001333504173 validation loss : 35.25038890043894 Real validation loss : 3875055298.6666665
EarlyStopping counter: 95 out of 100
145 tarainning loss : 3.567973199084421 validation loss : 36.53133338689804 Real validation loss : 3938785354.6666665
EarlyStopping counter: 96 out of 100
146 tarainning loss : 3.5598107587306873 validation loss : 44.46791191895803 Real validation loss : 3966112589.3333335
EarlyStopping counter: 97 out of 100
147 tarainning loss : 3.4597037619719497 validation loss : 33.756090541680656 Real validation loss : 3880171517.3333335
EarlyStopping counter: 98 out of 100
148 tarainning loss : 3.478462347665589 validation loss : 33.896835366884865 Real validation loss : 3869690632.0
EarlyStopping counter: 99 out of 100
149 tarainning loss : 3.318674448901985 validation loss : 34.49686807394028 Real validation loss : 3877607690.6666665
EarlyStopping counter: 100 out of 100
Early stopping
0
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 121990.82656864352, 'Validation Loss': 70606.62768554688, 'Real Validation Loss': 419180462.3333333} 0
1
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 31168.211398263433, 'Validation Loss': 5174.020182291667, 'Real Validation Loss': 2616752184.0} 1
2
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 1068.5921190694307, 'Validation Loss': 115.61831378936768, 'Real Validation Loss': 3731355506.6666665} 2
3
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 40.28412581927498, 'Validation Loss': 58.25264569123586, 'Real Validation Loss': 3957840917.3333335} 3
4
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 35.30419176934119, 'Validation Loss': 151.2347855567932, 'Real Validation Loss': 3688097058.6666665} 4
5
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 33.70818216116369, 'Validation Loss': 41.083085556825004, 'Real Validation Loss': 3840511061.3333335} 5
6
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 32.98049321305861, 'Validation Loss': 37.651959796746574, 'Real Validation Loss': 3846477189.3333335} 6
7
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 32.19131205497532, 'Validation Loss': 227.02161169052124, 'Real Validation Loss': 4178792992.0} 7
8
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 31.890416652784435, 'Validation Loss': 50.25620992978414, 'Real Validation Loss': 3983168306.6666665} 8
9
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 30.71542125666907, 'Validation Loss': 40.21902277072271, 'Real Validation Loss': 3832270621.3333335} 9
10
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 30.493185893267512, 'Validation Loss': 36.68307503064474, 'Real Validation Loss': 3842092213.3333335} 10
11
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 30.167854747797215, 'Validation Loss': 124.1422545115153, 'Real Validation Loss': 4092820864.0} 11
12
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 29.960229053722298, 'Validation Loss': 63.41296148300171, 'Real Validation Loss': 3781717050.6666665} 12
13
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 29.44718139793426, 'Validation Loss': 60.36939140160879, 'Real Validation Loss': 3785454349.3333335} 13
14
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 28.74377352038342, 'Validation Loss': 65.83222484588623, 'Real Validation Loss': 3776154208.0} 14
15
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 28.424043251677546, 'Validation Loss': 34.96844172477722, 'Real Validation Loss': 3952939904.0} 15
16
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 28.144209435539196, 'Validation Loss': 99.5589165687561, 'Real Validation Loss': 4066584848.0} 16
17
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 27.886020980374997, 'Validation Loss': 137.62653064727783, 'Real Validation Loss': 3694826138.6666665} 17
18
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 27.327399035112574, 'Validation Loss': 26.622238874435425, 'Real Validation Loss': 3904265733.3333335} 18
19
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 27.185663601986548, 'Validation Loss': 133.55601000785828, 'Real Validation Loss': 3696872882.6666665} 19
20
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 26.627577225471388, 'Validation Loss': 28.140056709448498, 'Real Validation Loss': 3866817381.3333335} 20
21
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 26.303468782967382, 'Validation Loss': 32.738679667313896, 'Real Validation Loss': 3953424384.0} 21
22
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 25.995981105189493, 'Validation Loss': 33.410863836606346, 'Real Validation Loss': 3950842277.3333335} 22
23
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 25.60127372166745, 'Validation Loss': 31.440934081872303, 'Real Validation Loss': 3852755693.3333335} 23
24
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 25.447811357940633, 'Validation Loss': 28.08665857712428, 'Real Validation Loss': 3867481936.0} 24
25
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 25.095797633749786, 'Validation Loss': 75.82124451796214, 'Real Validation Loss': 3760433416.0} 25
26
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 24.921387323701992, 'Validation Loss': 31.57340528567632, 'Real Validation Loss': 3849137058.6666665} 26
27
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 24.490558126807056, 'Validation Loss': 37.88368364175161, 'Real Validation Loss': 3966091408.0} 27
28
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 24.07582614743694, 'Validation Loss': 29.27215180794398, 'Real Validation Loss': 3857658784.0} 28
29
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 23.83254006087077, 'Validation Loss': 31.454302807648975, 'Real Validation Loss': 3847702013.3333335} 29
30
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 23.508474687448803, 'Validation Loss': 31.719089488188427, 'Real Validation Loss': 3848767072.0} 30
31
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 23.431596662238885, 'Validation Loss': 25.61335356036822, 'Real Validation Loss': 3911025978.6666665} 31
32
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 23.121838215919183, 'Validation Loss': 32.189344584941864, 'Real Validation Loss': 3950043384.0} 32
33
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 22.992412193418332, 'Validation Loss': 28.197611391544342, 'Real Validation Loss': 3934446480.0} 33
34
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 22.850885299992594, 'Validation Loss': 26.415917833646137, 'Real Validation Loss': 3874630893.3333335} 34
35
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 22.767432606548343, 'Validation Loss': 26.697349468866985, 'Real Validation Loss': 3871060722.6666665} 35
36
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 22.515833782181048, 'Validation Loss': 26.25241349140803, 'Real Validation Loss': 3882009826.6666665} 36
37
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 22.33225420855601, 'Validation Loss': 26.058087070782978, 'Real Validation Loss': 3921450080.0} 37
38
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 22.132647319358735, 'Validation Loss': 26.58012478550275, 'Real Validation Loss': 3919146010.6666665} 38
39
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 21.97791701750549, 'Validation Loss': 42.38695917526881, 'Real Validation Loss': 3815254242.6666665} 39
40
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 21.746803789901232, 'Validation Loss': 27.17983188231786, 'Real Validation Loss': 3927003429.3333335} 40
41
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 21.665225967667205, 'Validation Loss': 25.13339987397194, 'Real Validation Loss': 3885947117.3333335} 41
42
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 21.43669461141564, 'Validation Loss': 28.353133857250214, 'Real Validation Loss': 3931516800.0} 42
43
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 21.235828769628842, 'Validation Loss': 25.292912274599075, 'Real Validation Loss': 3896928912.0} 43
44
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 21.204337063810616, 'Validation Loss': 25.001441578070324, 'Real Validation Loss': 3893208320.0} 44
45
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 20.93177771912021, 'Validation Loss': 36.94772690534592, 'Real Validation Loss': 3830102826.6666665} 45
46
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 20.691927056168822, 'Validation Loss': 31.53337899843852, 'Real Validation Loss': 3850978224.0} 46
47
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 20.481796215902307, 'Validation Loss': 25.646468589703243, 'Real Validation Loss': 3910500768.0} 47
48
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 20.330260665513585, 'Validation Loss': 36.77145719528198, 'Real Validation Loss': 3965015360.0} 48
49
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 20.05566485118741, 'Validation Loss': 24.681484560171764, 'Real Validation Loss': 3889420618.6666665} 49
50
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 19.83357418130297, 'Validation Loss': 27.340161840120953, 'Real Validation Loss': 3868547080.0} 50
51
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 19.65677625073674, 'Validation Loss': 25.682156652212143, 'Real Validation Loss': 3895145450.6666665} 51
52
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 19.3754465045654, 'Validation Loss': 26.07506142059962, 'Real Validation Loss': 3875990293.3333335} 52
53
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 19.06571068270022, 'Validation Loss': 30.324598054091137, 'Real Validation Loss': 3941099632.0} 53
54
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 18.79072440686107, 'Validation Loss': 26.710922519365948, 'Real Validation Loss': 3917476749.3333335} 54
55
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 18.600400444720705, 'Validation Loss': 26.20081216096878, 'Real Validation Loss': 3912606778.6666665} 55
56
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 18.347335719187324, 'Validation Loss': 25.90769390265147, 'Real Validation Loss': 3887503808.0} 56
57
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 18.015206291978668, 'Validation Loss': 26.574530204137165, 'Real Validation Loss': 3905073621.3333335} 57
58
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 17.787628285069296, 'Validation Loss': 29.29939502477646, 'Real Validation Loss': 3859669912.0} 58
59
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 17.61899738761732, 'Validation Loss': 26.15014676253001, 'Real Validation Loss': 3902426085.3333335} 59
60
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 17.239120847119572, 'Validation Loss': 35.18172194560369, 'Real Validation Loss': 3837805021.3333335} 60
61
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 16.95000545756689, 'Validation Loss': 34.51649008194605, 'Real Validation Loss': 3950627562.6666665} 61
62
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 16.73944941229464, 'Validation Loss': 65.37929447491963, 'Real Validation Loss': 4017731066.6666665} 62
63
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 16.441898729666814, 'Validation Loss': 32.66037114461263, 'Real Validation Loss': 3936279493.3333335} 63
64
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 16.222241991625545, 'Validation Loss': 28.26455295085907, 'Real Validation Loss': 3869289397.3333335} 64
65
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 15.937849359774809, 'Validation Loss': 33.84966387351354, 'Real Validation Loss': 3850954205.3333335} 65
66
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 15.519656636299343, 'Validation Loss': 35.05185697476069, 'Real Validation Loss': 3843145498.6666665} 66
67
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 15.291007119425002, 'Validation Loss': 28.740106185277302, 'Real Validation Loss': 3923447890.6666665} 67
68
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 15.02519144330706, 'Validation Loss': 29.2298504114151, 'Real Validation Loss': 3916624226.6666665} 68
69
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 14.698289687480402, 'Validation Loss': 28.1136767466863, 'Real Validation Loss': 3876153072.0} 69
70
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 14.566599670900118, 'Validation Loss': 29.707796196142834, 'Real Validation Loss': 3874590741.3333335} 70
71
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 14.257581382091518, 'Validation Loss': 39.13530832529068, 'Real Validation Loss': 3836399525.3333335} 71
72
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 13.990856524376225, 'Validation Loss': 28.56139103571574, 'Real Validation Loss': 3897922984.0} 72
73
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 13.72322645349865, 'Validation Loss': 27.465085099140804, 'Real Validation Loss': 3888694266.6666665} 73
74
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 13.480629487243892, 'Validation Loss': 34.29524028301239, 'Real Validation Loss': 3846608922.6666665} 74
75
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 13.100761136096239, 'Validation Loss': 31.164789140224457, 'Real Validation Loss': 3871127797.3333335} 75
76
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 12.963326692893652, 'Validation Loss': 27.87096107006073, 'Real Validation Loss': 3895387304.0} 76
77
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 12.631368715828712, 'Validation Loss': 28.65359769264857, 'Real Validation Loss': 3925474562.6666665} 77
78
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 12.3384030405847, 'Validation Loss': 28.62678196032842, 'Real Validation Loss': 3917128098.6666665} 78
79
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 12.271371840180763, 'Validation Loss': 28.093776792287827, 'Real Validation Loss': 3908706368.0} 79
80
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 11.940666610572785, 'Validation Loss': 29.04139306147893, 'Real Validation Loss': 3885780192.0} 80
81
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 11.767241931055352, 'Validation Loss': 31.426722864309948, 'Real Validation Loss': 3865512389.3333335} 81
82
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 11.559038481581101, 'Validation Loss': 30.574711362520855, 'Real Validation Loss': 3871998576.0} 82
83
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 11.332952802490594, 'Validation Loss': 65.63504016399384, 'Real Validation Loss': 4013399354.6666665} 83
84
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 10.942369520429859, 'Validation Loss': 29.596181293328602, 'Real Validation Loss': 3891243405.3333335} 84
85
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 10.806378074586, 'Validation Loss': 37.05503040552139, 'Real Validation Loss': 3845768392.0} 85
86
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 10.570183309627549, 'Validation Loss': 31.17398927609126, 'Real Validation Loss': 3928174357.3333335} 86
87
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 10.411892746566632, 'Validation Loss': 31.677943607171375, 'Real Validation Loss': 3915106509.3333335} 87
88
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 10.227363863903761, 'Validation Loss': 34.33979139725367, 'Real Validation Loss': 3857399178.6666665} 88
89
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 9.945294296444635, 'Validation Loss': 31.361196796099346, 'Real Validation Loss': 3913725402.6666665} 89
90
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 9.806817009752105, 'Validation Loss': 30.155455887317657, 'Real Validation Loss': 3912338818.6666665} 90
91
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 9.477891177681139, 'Validation Loss': 31.782987018426258, 'Real Validation Loss': 3910425968.0} 91
92
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 9.45680114388622, 'Validation Loss': 31.302985171477, 'Real Validation Loss': 3908018186.6666665} 92
93
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 9.194191280854952, 'Validation Loss': 30.67587920029958, 'Real Validation Loss': 3890271392.0} 93
94
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 9.030391560000798, 'Validation Loss': 31.078803102175396, 'Real Validation Loss': 3891972029.3333335} 94
95
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 8.826681525179161, 'Validation Loss': 34.43496519327164, 'Real Validation Loss': 3936432056.0} 95
96
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 8.65395201549305, 'Validation Loss': 31.80392263333003, 'Real Validation Loss': 3866700610.6666665} 96
97
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 8.490998361870002, 'Validation Loss': 30.916597942511242, 'Real Validation Loss': 3906572541.3333335} 97
98
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 8.225875235166336, 'Validation Loss': 31.5603440006574, 'Real Validation Loss': 3877217944.0} 98
99
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 8.116270314037878, 'Validation Loss': 42.50951260328293, 'Real Validation Loss': 3960205989.3333335} 99
100
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 7.9774060655546375, 'Validation Loss': 34.18173533678055, 'Real Validation Loss': 3932043325.3333335} 100
101
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 7.794848103354518, 'Validation Loss': 32.137134631474815, 'Real Validation Loss': 3911513757.3333335} 101
102
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 7.619910417659255, 'Validation Loss': 31.774206658204395, 'Real Validation Loss': 3901151058.6666665} 102
103
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 7.4595335820399296, 'Validation Loss': 34.61835730075836, 'Real Validation Loss': 3857695058.6666665} 103
104
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 7.364134790388035, 'Validation Loss': 30.80674300591151, 'Real Validation Loss': 3903901642.6666665} 104
105
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 7.1439089725089415, 'Validation Loss': 33.40014706055323, 'Real Validation Loss': 3927992312.0} 105
106
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 7.051515872950323, 'Validation Loss': 31.483944714069366, 'Real Validation Loss': 3891517632.0} 106
107
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 6.803079029523217, 'Validation Loss': 40.418945054213204, 'Real Validation Loss': 3839757408.0} 107
108
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 6.653356819915271, 'Validation Loss': 33.72474857171377, 'Real Validation Loss': 3865092485.3333335} 108
109
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 6.560222694476966, 'Validation Loss': 40.946408450603485, 'Real Validation Loss': 3838469581.3333335} 109
110
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 6.539018099461127, 'Validation Loss': 34.71278619766235, 'Real Validation Loss': 3866548624.0} 110
111
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 6.376779452532647, 'Validation Loss': 30.69959380229314, 'Real Validation Loss': 3897803280.0} 111
112
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 6.252618025670983, 'Validation Loss': 39.1821336944898, 'Real Validation Loss': 3843604149.3333335} 112
113
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 6.135300074148615, 'Validation Loss': 44.019481201966606, 'Real Validation Loss': 3830266864.0} 113
114
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 6.0473347557012875, 'Validation Loss': 42.71011475721995, 'Real Validation Loss': 3830531904.0} 114
115
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 5.894636024810071, 'Validation Loss': 32.85415053367615, 'Real Validation Loss': 3873975082.6666665} 115
116
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 5.713560559334011, 'Validation Loss': 31.569264113903046, 'Real Validation Loss': 3905152749.3333335} 116
117
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 5.669955794495649, 'Validation Loss': 35.12102780739466, 'Real Validation Loss': 3929644890.6666665} 117
118
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 5.548406522208397, 'Validation Loss': 31.457873463630676, 'Real Validation Loss': 3900817936.0} 118
119
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 5.379923404903587, 'Validation Loss': 38.42040238777796, 'Real Validation Loss': 3945498589.3333335} 119
120
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 5.314359505867114, 'Validation Loss': 32.18323540687561, 'Real Validation Loss': 3911382170.6666665} 120
121
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 5.268381647794931, 'Validation Loss': 32.10225409269333, 'Real Validation Loss': 3916973906.6666665} 121
122
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 5.177273080358343, 'Validation Loss': 33.74509543180466, 'Real Validation Loss': 3872762954.6666665} 122
123
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 4.954042874032517, 'Validation Loss': 31.186759690443676, 'Real Validation Loss': 3900902424.0} 123
124
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 4.9504694291836, 'Validation Loss': 47.19587071736654, 'Real Validation Loss': 3820915682.6666665} 124
125
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 4.939876739819428, 'Validation Loss': 34.43169198433558, 'Real Validation Loss': 3887138221.3333335} 125
126
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 4.768576477020783, 'Validation Loss': 33.82926535606384, 'Real Validation Loss': 3917352594.6666665} 126
127
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 4.714482824893016, 'Validation Loss': 32.040882090727486, 'Real Validation Loss': 3889170237.3333335} 127
128
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 4.63675929272003, 'Validation Loss': 31.728960514068604, 'Real Validation Loss': 3889368981.3333335} 128
129
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 4.550404204922297, 'Validation Loss': 32.95868194103241, 'Real Validation Loss': 3877922586.6666665} 129
130
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 4.477961958938939, 'Validation Loss': 32.92372876405716, 'Real Validation Loss': 3884497184.0} 130
131
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 4.344510162486005, 'Validation Loss': 32.57919991016388, 'Real Validation Loss': 3887681722.6666665} 131
132
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 4.322061800550508, 'Validation Loss': 35.61603391170502, 'Real Validation Loss': 3932601464.0} 132
133
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 4.234244526916844, 'Validation Loss': 59.54030156135559, 'Real Validation Loss': 3998186282.6666665} 133
134
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 4.1891318429969395, 'Validation Loss': 35.98221643765768, 'Real Validation Loss': 3858873394.6666665} 134
135
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 4.111710840252718, 'Validation Loss': 39.48455903927485, 'Real Validation Loss': 3950364162.6666665} 135
136
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 4.027033664920852, 'Validation Loss': 43.47983447710673, 'Real Validation Loss': 3956618168.0} 136
137
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 4.060347080230713, 'Validation Loss': 38.25875627994537, 'Real Validation Loss': 3942667253.3333335} 137
138
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 3.9476169621178863, 'Validation Loss': 33.39826476573944, 'Real Validation Loss': 3921333693.3333335} 138
139
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 3.963004190674928, 'Validation Loss': 33.452668050924935, 'Real Validation Loss': 3898165858.6666665} 139
140
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 3.8699479959270433, 'Validation Loss': 32.2659263809522, 'Real Validation Loss': 3893894096.0} 140
141
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 3.7593644255891854, 'Validation Loss': 70.10256842772166, 'Real Validation Loss': 4013796554.6666665} 141
142
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 3.688915642967074, 'Validation Loss': 32.28502768278122, 'Real Validation Loss': 3895678605.3333335} 142
143
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 3.7132478782108853, 'Validation Loss': 34.10457170009613, 'Real Validation Loss': 3867559333.3333335} 143
144
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 3.574001333504173, 'Validation Loss': 35.25038890043894, 'Real Validation Loss': 3875055298.6666665} 144
145
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 3.567973199084421, 'Validation Loss': 36.53133338689804, 'Real Validation Loss': 3938785354.6666665} 145
146
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 3.5598107587306873, 'Validation Loss': 44.46791191895803, 'Real Validation Loss': 3966112589.3333335} 146
147
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 3.4597037619719497, 'Validation Loss': 33.756090541680656, 'Real Validation Loss': 3880171517.3333335} 147
148
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 3.478462347665589, 'Validation Loss': 33.896835366884865, 'Real Validation Loss': 3869690632.0} 148
149
TL Mean Absolute Loss vs Epoch [Y: qt, Learning Rate: 0.0005] {'Training Loss': 3.318674448901985, 'Validation Loss': 34.49686807394028, 'Real Validation Loss': 3877607690.6666665} 149


-------------qrs---------------
0 tarainning loss : 3695.4864007792344 validation loss : 145.67228730519614 Real validation loss : 20729000.229166668
Validation loss decreased (inf --> 145.672287).  Saving model ...
1 tarainning loss : 53.5191474054619 validation loss : 66.39388660589854 Real validation loss : 23176383.0625
Validation loss decreased (145.672287 --> 66.393887).  Saving model ...
2 tarainning loss : 23.31521356715131 validation loss : 26.753523588180542 Real validation loss : 25867674.5
Validation loss decreased (66.393887 --> 26.753524).  Saving model ...
3 tarainning loss : 21.568557788003943 validation loss : 31.146684726079304 Real validation loss : 24992814.770833332
EarlyStopping counter: 1 out of 100
4 tarainning loss : 20.726675822256745 validation loss : 53.52791408697764 Real validation loss : 23408572.4375
EarlyStopping counter: 2 out of 100
5 tarainning loss : 20.126495455070685 validation loss : 23.054792781670887 Real validation loss : 27070617.0
Validation loss decreased (26.753524 --> 23.054793).  Saving model ...
6 tarainning loss : 19.687584914511184 validation loss : 20.777781456708908 Real validation loss : 26949935.020833332
Validation loss decreased (23.054793 --> 20.777781).  Saving model ...
7 tarainning loss : 19.2920597946347 validation loss : 23.096004406611126 Real validation loss : 25933154.708333332
EarlyStopping counter: 1 out of 100
8 tarainning loss : 18.99967474081257 validation loss : 21.455139487981796 Real validation loss : 26008660.520833332
EarlyStopping counter: 2 out of 100
9 tarainning loss : 18.793549825135877 validation loss : 21.98887984951337 Real validation loss : 25580257.270833332
EarlyStopping counter: 3 out of 100
10 tarainning loss : 18.624192657820675 validation loss : 19.363630145788193 Real validation loss : 26060391.520833332
Validation loss decreased (20.777781 --> 19.363630).  Saving model ...
11 tarainning loss : 18.346052371033835 validation loss : 18.300559361775715 Real validation loss : 26265510.875
Validation loss decreased (19.363630 --> 18.300559).  Saving model ...
12 tarainning loss : 18.21498938094273 validation loss : 18.28499088684718 Real validation loss : 26332555.291666668
Validation loss decreased (18.300559 --> 18.284991).  Saving model ...
13 tarainning loss : 18.041888189503283 validation loss : 20.340778410434723 Real validation loss : 27310656.666666668
EarlyStopping counter: 1 out of 100
14 tarainning loss : 17.88739804609106 validation loss : 19.87689298391342 Real validation loss : 25672692.395833332
EarlyStopping counter: 2 out of 100
15 tarainning loss : 17.758222163739084 validation loss : 19.461034496625263 Real validation loss : 25874163.583333332
EarlyStopping counter: 3 out of 100
16 tarainning loss : 17.5460802268232 validation loss : 19.61978433529536 Real validation loss : 26976703.395833332
EarlyStopping counter: 4 out of 100
17 tarainning loss : 17.39654060178784 validation loss : 18.219698697328568 Real validation loss : 26799622.104166668
Validation loss decreased (18.284991 --> 18.219699).  Saving model ...
18 tarainning loss : 17.24776089769516 validation loss : 21.194121092557907 Real validation loss : 25536332.854166668
EarlyStopping counter: 1 out of 100
19 tarainning loss : 17.126400743836967 validation loss : 19.37627536058426 Real validation loss : 25997446.020833332
EarlyStopping counter: 2 out of 100
20 tarainning loss : 17.04472131841617 validation loss : 18.182288984457653 Real validation loss : 26671381.979166668
Validation loss decreased (18.219699 --> 18.182289).  Saving model ...
21 tarainning loss : 16.870978197920213 validation loss : 18.979985266923904 Real validation loss : 25749053.708333332
EarlyStopping counter: 1 out of 100
22 tarainning loss : 16.690860792037544 validation loss : 17.865220030148823 Real validation loss : 26412761.958333332
Validation loss decreased (18.182289 --> 17.865220).  Saving model ...
23 tarainning loss : 16.62320741975917 validation loss : 19.181940267483395 Real validation loss : 26384510.770833332
EarlyStopping counter: 1 out of 100
24 tarainning loss : 16.439549214874308 validation loss : 17.691895335912704 Real validation loss : 26470955.6875
Validation loss decreased (17.865220 --> 17.691895).  Saving model ...
25 tarainning loss : 16.276069508623795 validation loss : 18.44616575042407 Real validation loss : 26480094.854166668
EarlyStopping counter: 1 out of 100
26 tarainning loss : 16.182770412840036 validation loss : 19.465346107880276 Real validation loss : 27007869.770833332
EarlyStopping counter: 2 out of 100
27 tarainning loss : 15.922148924511351 validation loss : 18.94177247087161 Real validation loss : 27132354.166666668
EarlyStopping counter: 3 out of 100
28 tarainning loss : 15.94465044129098 validation loss : 17.74238595366478 Real validation loss : 26331247.125
EarlyStopping counter: 4 out of 100
29 tarainning loss : 15.723480243357887 validation loss : 17.94756265481313 Real validation loss : 26805175.0625
EarlyStopping counter: 5 out of 100
30 tarainning loss : 15.599497558873727 validation loss : 21.663800259431202 Real validation loss : 27528313.645833332
EarlyStopping counter: 6 out of 100
31 tarainning loss : 15.453512769226634 validation loss : 18.080531855424244 Real validation loss : 26302683.125
EarlyStopping counter: 7 out of 100
32 tarainning loss : 15.43019612713535 validation loss : 17.624433477719624 Real validation loss : 26466731.833333332
Validation loss decreased (17.691895 --> 17.624433).  Saving model ...
33 tarainning loss : 15.184315089004537 validation loss : 20.79694135983785 Real validation loss : 25656654.583333332
EarlyStopping counter: 1 out of 100
34 tarainning loss : 15.07613661529821 validation loss : 18.047590285539627 Real validation loss : 26414563.25
EarlyStopping counter: 2 out of 100
35 tarainning loss : 14.914947674752531 validation loss : 18.422598133484524 Real validation loss : 25925496.3125
EarlyStopping counter: 3 out of 100
36 tarainning loss : 14.79385916558662 validation loss : 18.29012440641721 Real validation loss : 26953895.520833332
EarlyStopping counter: 4 out of 100
37 tarainning loss : 14.51134735572385 validation loss : 17.958224217096966 Real validation loss : 26430015.729166668
EarlyStopping counter: 5 out of 100
38 tarainning loss : 14.379565667043664 validation loss : 18.370473663012188 Real validation loss : 25967032.25
EarlyStopping counter: 6 out of 100
39 tarainning loss : 14.164621198161713 validation loss : 17.383625616629917 Real validation loss : 26434273.083333332
Validation loss decreased (17.624433 --> 17.383626).  Saving model ...
40 tarainning loss : 14.011552481945033 validation loss : 17.42664075891177 Real validation loss : 26442846.541666668
EarlyStopping counter: 1 out of 100
41 tarainning loss : 13.83169736024749 validation loss : 18.448600282271702 Real validation loss : 26866237.0
EarlyStopping counter: 2 out of 100
42 tarainning loss : 13.649801108034067 validation loss : 19.842218577861786 Real validation loss : 26999100.541666668
EarlyStopping counter: 3 out of 100
43 tarainning loss : 13.441740555969478 validation loss : 19.654098560412724 Real validation loss : 26984172.5
EarlyStopping counter: 4 out of 100
44 tarainning loss : 13.266126140229511 validation loss : 20.044543196757633 Real validation loss : 25586988.75
EarlyStopping counter: 5 out of 100
45 tarainning loss : 13.036667920033866 validation loss : 20.28955254952113 Real validation loss : 25656254.541666668
EarlyStopping counter: 6 out of 100
46 tarainning loss : 12.85100778402226 validation loss : 18.244246552387875 Real validation loss : 26331521.5625
EarlyStopping counter: 7 out of 100
47 tarainning loss : 12.659787722996303 validation loss : 18.352569450934727 Real validation loss : 26554101.020833332
EarlyStopping counter: 8 out of 100
48 tarainning loss : 12.364556101952749 validation loss : 18.428029815355938 Real validation loss : 26352563.583333332
EarlyStopping counter: 9 out of 100
49 tarainning loss : 12.252173397519172 validation loss : 20.002674748500187 Real validation loss : 25911883.791666668
EarlyStopping counter: 10 out of 100
50 tarainning loss : 11.923623412495985 validation loss : 18.053309708833694 Real validation loss : 26278269.479166668
EarlyStopping counter: 11 out of 100
51 tarainning loss : 11.745957070846858 validation loss : 20.29857791463534 Real validation loss : 26118210.75
EarlyStopping counter: 12 out of 100
52 tarainning loss : 11.566372767657159 validation loss : 18.651738733053207 Real validation loss : 26547301.791666668
EarlyStopping counter: 13 out of 100
53 tarainning loss : 11.271059870563672 validation loss : 20.336652954419453 Real validation loss : 27061214.166666668
EarlyStopping counter: 14 out of 100
54 tarainning loss : 11.065108115519953 validation loss : 20.034140596787136 Real validation loss : 26015223.229166668
EarlyStopping counter: 15 out of 100
55 tarainning loss : 10.849165223372873 validation loss : 22.022594342629116 Real validation loss : 27192224.5625
EarlyStopping counter: 16 out of 100
56 tarainning loss : 10.589804393123362 validation loss : 19.224283754825592 Real validation loss : 26211740.458333332
EarlyStopping counter: 17 out of 100
57 tarainning loss : 10.38969041354378 validation loss : 20.75827560822169 Real validation loss : 26437727.020833332
EarlyStopping counter: 18 out of 100
58 tarainning loss : 10.111001904013898 validation loss : 20.34120378891627 Real validation loss : 25878220.708333332
EarlyStopping counter: 19 out of 100
59 tarainning loss : 9.905676994223738 validation loss : 19.520103563865025 Real validation loss : 26766078.229166668
EarlyStopping counter: 20 out of 100
60 tarainning loss : 9.66075658923208 validation loss : 20.554455320040386 Real validation loss : 26204379.770833332
EarlyStopping counter: 21 out of 100
61 tarainning loss : 9.502926242773373 validation loss : 20.247465431690216 Real validation loss : 26124425.6875
EarlyStopping counter: 22 out of 100
62 tarainning loss : 9.194153708211717 validation loss : 21.3128264049689 Real validation loss : 26546749.708333332
EarlyStopping counter: 23 out of 100
63 tarainning loss : 9.016996832381382 validation loss : 22.11032925049464 Real validation loss : 26057401.229166668
EarlyStopping counter: 24 out of 100
64 tarainning loss : 8.797143283084054 validation loss : 24.805493354797363 Real validation loss : 27463308.4375
EarlyStopping counter: 25 out of 100
65 tarainning loss : 8.612457817847575 validation loss : 20.599898050228756 Real validation loss : 26449889.020833332
EarlyStopping counter: 26 out of 100
66 tarainning loss : 8.415862760256346 validation loss : 21.087373445431393 Real validation loss : 26686471.729166668
EarlyStopping counter: 27 out of 100
67 tarainning loss : 8.249297637614479 validation loss : 21.87317629655202 Real validation loss : 26396543.6875
EarlyStopping counter: 28 out of 100
68 tarainning loss : 8.025569353941071 validation loss : 20.432504336039226 Real validation loss : 26231817.333333332
EarlyStopping counter: 29 out of 100
69 tarainning loss : 7.808669540860238 validation loss : 20.222818851470947 Real validation loss : 26724145.5
EarlyStopping counter: 30 out of 100
70 tarainning loss : 7.613235729237528 validation loss : 23.066569020350773 Real validation loss : 26840130.416666668
EarlyStopping counter: 31 out of 100
71 tarainning loss : 7.48156824961871 validation loss : 24.66164392232895 Real validation loss : 27044306.395833332
EarlyStopping counter: 32 out of 100
72 tarainning loss : 7.306784252351734 validation loss : 21.86610534787178 Real validation loss : 26552830.833333332
EarlyStopping counter: 33 out of 100
73 tarainning loss : 7.1194185673174974 validation loss : 20.82574772834778 Real validation loss : 26539313.5
EarlyStopping counter: 34 out of 100
74 tarainning loss : 6.924670656886669 validation loss : 23.381321390469868 Real validation loss : 27369558.083333332
EarlyStopping counter: 35 out of 100
75 tarainning loss : 6.758312193781801 validation loss : 21.81565202275912 Real validation loss : 25807193.75
EarlyStopping counter: 36 out of 100
76 tarainning loss : 6.5637578736126505 validation loss : 23.772450526555378 Real validation loss : 25547706.0625
EarlyStopping counter: 37 out of 100
77 tarainning loss : 6.399847234685955 validation loss : 21.621932218472164 Real validation loss : 25888873.4375
EarlyStopping counter: 38 out of 100
78 tarainning loss : 6.252132367337828 validation loss : 28.265990773836773 Real validation loss : 25052680.5625
EarlyStopping counter: 39 out of 100
79 tarainning loss : 6.093133011151735 validation loss : 22.869243264198303 Real validation loss : 27075684.979166668
EarlyStopping counter: 40 out of 100
80 tarainning loss : 5.9432478597873475 validation loss : 27.998594025770824 Real validation loss : 27740456.625
EarlyStopping counter: 41 out of 100
81 tarainning loss : 5.8289313378840255 validation loss : 21.259865244229633 Real validation loss : 26559133.416666668
EarlyStopping counter: 42 out of 100
82 tarainning loss : 5.718357340536455 validation loss : 22.652089794476826 Real validation loss : 26928785.395833332
EarlyStopping counter: 43 out of 100
83 tarainning loss : 5.483323983408677 validation loss : 26.328059176603954 Real validation loss : 25081922.729166668
EarlyStopping counter: 44 out of 100
84 tarainning loss : 5.396650582434778 validation loss : 20.83553757270177 Real validation loss : 26361887.8125
EarlyStopping counter: 45 out of 100
85 tarainning loss : 5.258264780357031 validation loss : 20.3641895254453 Real validation loss : 26425687.354166668
EarlyStopping counter: 46 out of 100
86 tarainning loss : 5.158180899888785 validation loss : 22.224613000949223 Real validation loss : 26613255.208333332
EarlyStopping counter: 47 out of 100
87 tarainning loss : 5.047865792308222 validation loss : 25.46997880935669 Real validation loss : 27348871.229166668
EarlyStopping counter: 48 out of 100
88 tarainning loss : 4.887973403243219 validation loss : 31.216937402884167 Real validation loss : 27724012.5
EarlyStopping counter: 49 out of 100
89 tarainning loss : 4.743980222729524 validation loss : 22.564781924088795 Real validation loss : 25903215.8125
EarlyStopping counter: 50 out of 100
90 tarainning loss : 4.707591735519869 validation loss : 23.73975646495819 Real validation loss : 25652665.104166668
EarlyStopping counter: 51 out of 100
91 tarainning loss : 4.559929699916514 validation loss : 22.915786763032276 Real validation loss : 26746662.979166668
EarlyStopping counter: 52 out of 100
92 tarainning loss : 4.493093351236646 validation loss : 27.81345025698344 Real validation loss : 25052988.895833332
EarlyStopping counter: 53 out of 100
93 tarainning loss : 4.325719202799066 validation loss : 21.55068040887515 Real validation loss : 26177246.270833332
EarlyStopping counter: 54 out of 100
94 tarainning loss : 4.2472576220101175 validation loss : 26.02206540107727 Real validation loss : 26853370.041666668
EarlyStopping counter: 55 out of 100
95 tarainning loss : 4.178285685310514 validation loss : 22.715020149946213 Real validation loss : 26435289.5625
EarlyStopping counter: 56 out of 100
96 tarainning loss : 4.083123349580977 validation loss : 23.59505432844162 Real validation loss : 25995845.041666668
EarlyStopping counter: 57 out of 100
97 tarainning loss : 4.0115807434522 validation loss : 23.3240591386954 Real validation loss : 25816329.0625
EarlyStopping counter: 58 out of 100
98 tarainning loss : 3.9165048958589646 validation loss : 24.7131870786349 Real validation loss : 26450300.395833332
EarlyStopping counter: 59 out of 100
99 tarainning loss : 3.8652372425849286 validation loss : 23.9734765291214 Real validation loss : 27118701.729166668
EarlyStopping counter: 60 out of 100
100 tarainning loss : 3.7563321496681024 validation loss : 23.13549925883611 Real validation loss : 26820278.4375
EarlyStopping counter: 61 out of 100
101 tarainning loss : 3.6849218861616144 validation loss : 22.747137318054836 Real validation loss : 25990841.6875
EarlyStopping counter: 62 out of 100
102 tarainning loss : 3.6280805649013694 validation loss : 22.279545207818348 Real validation loss : 26338654.479166668
EarlyStopping counter: 63 out of 100
103 tarainning loss : 3.5384848483424354 validation loss : 23.827208558718365 Real validation loss : 26592642.729166668
EarlyStopping counter: 64 out of 100
104 tarainning loss : 3.380172549506471 validation loss : 21.68899832169215 Real validation loss : 26166976.770833332
EarlyStopping counter: 65 out of 100
105 tarainning loss : 3.3579649281533017 validation loss : 23.185380458831787 Real validation loss : 26202719.9375
EarlyStopping counter: 66 out of 100
106 tarainning loss : 3.3145059426833887 validation loss : 23.772561341524124 Real validation loss : 26802487.145833332
EarlyStopping counter: 67 out of 100
107 tarainning loss : 3.2726067499908207 validation loss : 23.551488320032757 Real validation loss : 25742991.0
EarlyStopping counter: 68 out of 100
108 tarainning loss : 3.151720091368549 validation loss : 22.456478317578632 Real validation loss : 26139075.208333332
EarlyStopping counter: 69 out of 100
109 tarainning loss : 3.1631504565985145 validation loss : 25.928506791591644 Real validation loss : 26110638.729166668
EarlyStopping counter: 70 out of 100
110 tarainning loss : 3.087628528299994 validation loss : 22.063069810469944 Real validation loss : 26572661.979166668
EarlyStopping counter: 71 out of 100
111 tarainning loss : 3.023993984587383 validation loss : 23.51382604241371 Real validation loss : 26141203.104166668
EarlyStopping counter: 72 out of 100
112 tarainning loss : 2.9229124565736964 validation loss : 24.06481157739957 Real validation loss : 26898005.208333332
EarlyStopping counter: 73 out of 100
113 tarainning loss : 2.891228320245505 validation loss : 22.35518206159274 Real validation loss : 26235834.354166668
EarlyStopping counter: 74 out of 100
114 tarainning loss : 2.8473047033674908 validation loss : 26.323318759600323 Real validation loss : 25337836.3125
EarlyStopping counter: 75 out of 100
115 tarainning loss : 2.819405355116018 validation loss : 23.07751429080963 Real validation loss : 26199947.625
EarlyStopping counter: 76 out of 100
116 tarainning loss : 2.7593622095150527 validation loss : 29.26003247499466 Real validation loss : 27788023.104166668
EarlyStopping counter: 77 out of 100
117 tarainning loss : 2.748197752713845 validation loss : 24.194186290105183 Real validation loss : 26456259.083333332
EarlyStopping counter: 78 out of 100
118 tarainning loss : 2.654241504081736 validation loss : 22.019241611162823 Real validation loss : 26529387.375
EarlyStopping counter: 79 out of 100
119 tarainning loss : 2.6525548649646664 validation loss : 22.782002250353496 Real validation loss : 26089952.958333332
EarlyStopping counter: 80 out of 100
120 tarainning loss : 2.5909476028669864 validation loss : 22.3339706659317 Real validation loss : 26089202.666666668
EarlyStopping counter: 81 out of 100
121 tarainning loss : 2.501302680056811 validation loss : 22.32264272371928 Real validation loss : 26548265.5625
EarlyStopping counter: 82 out of 100
122 tarainning loss : 2.532541159096114 validation loss : 23.71086424589157 Real validation loss : 26975766.5
EarlyStopping counter: 83 out of 100
123 tarainning loss : 2.46541012411505 validation loss : 23.326220909754436 Real validation loss : 26317145.9375
EarlyStopping counter: 84 out of 100
124 tarainning loss : 2.4461203854174633 validation loss : 23.521835525830586 Real validation loss : 25787701.8125
EarlyStopping counter: 85 out of 100
125 tarainning loss : 2.382904223814548 validation loss : 22.74923359354337 Real validation loss : 26318003.375
EarlyStopping counter: 86 out of 100
126 tarainning loss : 2.4047810059543675 validation loss : 27.694559792677563 Real validation loss : 25295881.041666668
EarlyStopping counter: 87 out of 100
127 tarainning loss : 2.344090732334482 validation loss : 22.90266375740369 Real validation loss : 26469715.208333332
EarlyStopping counter: 88 out of 100
128 tarainning loss : 2.269599870804253 validation loss : 27.82386765877406 Real validation loss : 27713480.1875
EarlyStopping counter: 89 out of 100
129 tarainning loss : 2.3059374911132053 validation loss : 34.47479510307312 Real validation loss : 27974845.166666668
EarlyStopping counter: 90 out of 100
130 tarainning loss : 2.2570833455219494 validation loss : 23.16741230090459 Real validation loss : 26917932.125
EarlyStopping counter: 91 out of 100
131 tarainning loss : 2.1643281376689947 validation loss : 22.008457203706104 Real validation loss : 26030193.833333332
EarlyStopping counter: 92 out of 100
132 tarainning loss : 2.21227337336009 validation loss : 23.03805238008499 Real validation loss : 26965724.041666668
EarlyStopping counter: 93 out of 100
133 tarainning loss : 2.1174873971376633 validation loss : 22.83635675907135 Real validation loss : 25993106.604166668
EarlyStopping counter: 94 out of 100
134 tarainning loss : 2.1256640968285256 validation loss : 23.349507212638855 Real validation loss : 26177444.833333332
EarlyStopping counter: 95 out of 100
135 tarainning loss : 2.0593457821937253 validation loss : 25.640060861905415 Real validation loss : 25499277.166666668
EarlyStopping counter: 96 out of 100
136 tarainning loss : 2.0290456440001923 validation loss : 24.013838191827137 Real validation loss : 25631216.1875
EarlyStopping counter: 97 out of 100
137 tarainning loss : 2.053202050541519 validation loss : 22.808093736569088 Real validation loss : 26744963.708333332
EarlyStopping counter: 98 out of 100
138 tarainning loss : 1.9953034702166037 validation loss : 24.828730483849842 Real validation loss : 27026410.979166668
EarlyStopping counter: 99 out of 100
139 tarainning loss : 2.00926202293461 validation loss : 23.198091963926952 Real validation loss : 26470784.0625
EarlyStopping counter: 100 out of 100
Early stopping
0
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 3695.4864007792344, 'Validation Loss': 145.67228730519614, 'Real Validation Loss': 20729000.229166668} 0
1
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 53.5191474054619, 'Validation Loss': 66.39388660589854, 'Real Validation Loss': 23176383.0625} 1
2
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 23.31521356715131, 'Validation Loss': 26.753523588180542, 'Real Validation Loss': 25867674.5} 2
3
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 21.568557788003943, 'Validation Loss': 31.146684726079304, 'Real Validation Loss': 24992814.770833332} 3
4
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 20.726675822256745, 'Validation Loss': 53.52791408697764, 'Real Validation Loss': 23408572.4375} 4
5
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 20.126495455070685, 'Validation Loss': 23.054792781670887, 'Real Validation Loss': 27070617.0} 5
6
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 19.687584914511184, 'Validation Loss': 20.777781456708908, 'Real Validation Loss': 26949935.020833332} 6
7
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 19.2920597946347, 'Validation Loss': 23.096004406611126, 'Real Validation Loss': 25933154.708333332} 7
8
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 18.99967474081257, 'Validation Loss': 21.455139487981796, 'Real Validation Loss': 26008660.520833332} 8
9
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 18.793549825135877, 'Validation Loss': 21.98887984951337, 'Real Validation Loss': 25580257.270833332} 9
10
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 18.624192657820675, 'Validation Loss': 19.363630145788193, 'Real Validation Loss': 26060391.520833332} 10
11
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 18.346052371033835, 'Validation Loss': 18.300559361775715, 'Real Validation Loss': 26265510.875} 11
12
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 18.21498938094273, 'Validation Loss': 18.28499088684718, 'Real Validation Loss': 26332555.291666668} 12
13
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 18.041888189503283, 'Validation Loss': 20.340778410434723, 'Real Validation Loss': 27310656.666666668} 13
14
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 17.88739804609106, 'Validation Loss': 19.87689298391342, 'Real Validation Loss': 25672692.395833332} 14
15
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 17.758222163739084, 'Validation Loss': 19.461034496625263, 'Real Validation Loss': 25874163.583333332} 15
16
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 17.5460802268232, 'Validation Loss': 19.61978433529536, 'Real Validation Loss': 26976703.395833332} 16
17
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 17.39654060178784, 'Validation Loss': 18.219698697328568, 'Real Validation Loss': 26799622.104166668} 17
18
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 17.24776089769516, 'Validation Loss': 21.194121092557907, 'Real Validation Loss': 25536332.854166668} 18
19
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 17.126400743836967, 'Validation Loss': 19.37627536058426, 'Real Validation Loss': 25997446.020833332} 19
20
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 17.04472131841617, 'Validation Loss': 18.182288984457653, 'Real Validation Loss': 26671381.979166668} 20
21
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 16.870978197920213, 'Validation Loss': 18.979985266923904, 'Real Validation Loss': 25749053.708333332} 21
22
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 16.690860792037544, 'Validation Loss': 17.865220030148823, 'Real Validation Loss': 26412761.958333332} 22
23
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 16.62320741975917, 'Validation Loss': 19.181940267483395, 'Real Validation Loss': 26384510.770833332} 23
24
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 16.439549214874308, 'Validation Loss': 17.691895335912704, 'Real Validation Loss': 26470955.6875} 24
25
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 16.276069508623795, 'Validation Loss': 18.44616575042407, 'Real Validation Loss': 26480094.854166668} 25
26
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 16.182770412840036, 'Validation Loss': 19.465346107880276, 'Real Validation Loss': 27007869.770833332} 26
27
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 15.922148924511351, 'Validation Loss': 18.94177247087161, 'Real Validation Loss': 27132354.166666668} 27
28
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 15.94465044129098, 'Validation Loss': 17.74238595366478, 'Real Validation Loss': 26331247.125} 28
29
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 15.723480243357887, 'Validation Loss': 17.94756265481313, 'Real Validation Loss': 26805175.0625} 29
30
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 15.599497558873727, 'Validation Loss': 21.663800259431202, 'Real Validation Loss': 27528313.645833332} 30
31
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 15.453512769226634, 'Validation Loss': 18.080531855424244, 'Real Validation Loss': 26302683.125} 31
32
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 15.43019612713535, 'Validation Loss': 17.624433477719624, 'Real Validation Loss': 26466731.833333332} 32
33
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 15.184315089004537, 'Validation Loss': 20.79694135983785, 'Real Validation Loss': 25656654.583333332} 33
34
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 15.07613661529821, 'Validation Loss': 18.047590285539627, 'Real Validation Loss': 26414563.25} 34
35
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 14.914947674752531, 'Validation Loss': 18.422598133484524, 'Real Validation Loss': 25925496.3125} 35
36
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 14.79385916558662, 'Validation Loss': 18.29012440641721, 'Real Validation Loss': 26953895.520833332} 36
37
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 14.51134735572385, 'Validation Loss': 17.958224217096966, 'Real Validation Loss': 26430015.729166668} 37
38
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 14.379565667043664, 'Validation Loss': 18.370473663012188, 'Real Validation Loss': 25967032.25} 38
39
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 14.164621198161713, 'Validation Loss': 17.383625616629917, 'Real Validation Loss': 26434273.083333332} 39
40
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 14.011552481945033, 'Validation Loss': 17.42664075891177, 'Real Validation Loss': 26442846.541666668} 40
41
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 13.83169736024749, 'Validation Loss': 18.448600282271702, 'Real Validation Loss': 26866237.0} 41
42
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 13.649801108034067, 'Validation Loss': 19.842218577861786, 'Real Validation Loss': 26999100.541666668} 42
43
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 13.441740555969478, 'Validation Loss': 19.654098560412724, 'Real Validation Loss': 26984172.5} 43
44
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 13.266126140229511, 'Validation Loss': 20.044543196757633, 'Real Validation Loss': 25586988.75} 44
45
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 13.036667920033866, 'Validation Loss': 20.28955254952113, 'Real Validation Loss': 25656254.541666668} 45
46
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 12.85100778402226, 'Validation Loss': 18.244246552387875, 'Real Validation Loss': 26331521.5625} 46
47
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 12.659787722996303, 'Validation Loss': 18.352569450934727, 'Real Validation Loss': 26554101.020833332} 47
48
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 12.364556101952749, 'Validation Loss': 18.428029815355938, 'Real Validation Loss': 26352563.583333332} 48
49
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 12.252173397519172, 'Validation Loss': 20.002674748500187, 'Real Validation Loss': 25911883.791666668} 49
50
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 11.923623412495985, 'Validation Loss': 18.053309708833694, 'Real Validation Loss': 26278269.479166668} 50
51
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 11.745957070846858, 'Validation Loss': 20.29857791463534, 'Real Validation Loss': 26118210.75} 51
52
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 11.566372767657159, 'Validation Loss': 18.651738733053207, 'Real Validation Loss': 26547301.791666668} 52
53
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 11.271059870563672, 'Validation Loss': 20.336652954419453, 'Real Validation Loss': 27061214.166666668} 53
54
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 11.065108115519953, 'Validation Loss': 20.034140596787136, 'Real Validation Loss': 26015223.229166668} 54
55
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 10.849165223372873, 'Validation Loss': 22.022594342629116, 'Real Validation Loss': 27192224.5625} 55
56
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 10.589804393123362, 'Validation Loss': 19.224283754825592, 'Real Validation Loss': 26211740.458333332} 56
57
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 10.38969041354378, 'Validation Loss': 20.75827560822169, 'Real Validation Loss': 26437727.020833332} 57
58
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 10.111001904013898, 'Validation Loss': 20.34120378891627, 'Real Validation Loss': 25878220.708333332} 58
59
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 9.905676994223738, 'Validation Loss': 19.520103563865025, 'Real Validation Loss': 26766078.229166668} 59
60
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 9.66075658923208, 'Validation Loss': 20.554455320040386, 'Real Validation Loss': 26204379.770833332} 60
61
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 9.502926242773373, 'Validation Loss': 20.247465431690216, 'Real Validation Loss': 26124425.6875} 61
62
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 9.194153708211717, 'Validation Loss': 21.3128264049689, 'Real Validation Loss': 26546749.708333332} 62
63
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 9.016996832381382, 'Validation Loss': 22.11032925049464, 'Real Validation Loss': 26057401.229166668} 63
64
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 8.797143283084054, 'Validation Loss': 24.805493354797363, 'Real Validation Loss': 27463308.4375} 64
65
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 8.612457817847575, 'Validation Loss': 20.599898050228756, 'Real Validation Loss': 26449889.020833332} 65
66
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 8.415862760256346, 'Validation Loss': 21.087373445431393, 'Real Validation Loss': 26686471.729166668} 66
67
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 8.249297637614479, 'Validation Loss': 21.87317629655202, 'Real Validation Loss': 26396543.6875} 67
68
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 8.025569353941071, 'Validation Loss': 20.432504336039226, 'Real Validation Loss': 26231817.333333332} 68
69
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 7.808669540860238, 'Validation Loss': 20.222818851470947, 'Real Validation Loss': 26724145.5} 69
70
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 7.613235729237528, 'Validation Loss': 23.066569020350773, 'Real Validation Loss': 26840130.416666668} 70
71
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 7.48156824961871, 'Validation Loss': 24.66164392232895, 'Real Validation Loss': 27044306.395833332} 71
72
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 7.306784252351734, 'Validation Loss': 21.86610534787178, 'Real Validation Loss': 26552830.833333332} 72
73
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 7.1194185673174974, 'Validation Loss': 20.82574772834778, 'Real Validation Loss': 26539313.5} 73
74
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 6.924670656886669, 'Validation Loss': 23.381321390469868, 'Real Validation Loss': 27369558.083333332} 74
75
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 6.758312193781801, 'Validation Loss': 21.81565202275912, 'Real Validation Loss': 25807193.75} 75
76
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 6.5637578736126505, 'Validation Loss': 23.772450526555378, 'Real Validation Loss': 25547706.0625} 76
77
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 6.399847234685955, 'Validation Loss': 21.621932218472164, 'Real Validation Loss': 25888873.4375} 77
78
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 6.252132367337828, 'Validation Loss': 28.265990773836773, 'Real Validation Loss': 25052680.5625} 78
79
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 6.093133011151735, 'Validation Loss': 22.869243264198303, 'Real Validation Loss': 27075684.979166668} 79
80
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 5.9432478597873475, 'Validation Loss': 27.998594025770824, 'Real Validation Loss': 27740456.625} 80
81
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 5.8289313378840255, 'Validation Loss': 21.259865244229633, 'Real Validation Loss': 26559133.416666668} 81
82
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 5.718357340536455, 'Validation Loss': 22.652089794476826, 'Real Validation Loss': 26928785.395833332} 82
83
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 5.483323983408677, 'Validation Loss': 26.328059176603954, 'Real Validation Loss': 25081922.729166668} 83
84
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 5.396650582434778, 'Validation Loss': 20.83553757270177, 'Real Validation Loss': 26361887.8125} 84
85
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 5.258264780357031, 'Validation Loss': 20.3641895254453, 'Real Validation Loss': 26425687.354166668} 85
86
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 5.158180899888785, 'Validation Loss': 22.224613000949223, 'Real Validation Loss': 26613255.208333332} 86
87
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 5.047865792308222, 'Validation Loss': 25.46997880935669, 'Real Validation Loss': 27348871.229166668} 87
88
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 4.887973403243219, 'Validation Loss': 31.216937402884167, 'Real Validation Loss': 27724012.5} 88
89
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 4.743980222729524, 'Validation Loss': 22.564781924088795, 'Real Validation Loss': 25903215.8125} 89
90
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 4.707591735519869, 'Validation Loss': 23.73975646495819, 'Real Validation Loss': 25652665.104166668} 90
91
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 4.559929699916514, 'Validation Loss': 22.915786763032276, 'Real Validation Loss': 26746662.979166668} 91
92
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 4.493093351236646, 'Validation Loss': 27.81345025698344, 'Real Validation Loss': 25052988.895833332} 92
93
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 4.325719202799066, 'Validation Loss': 21.55068040887515, 'Real Validation Loss': 26177246.270833332} 93
94
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 4.2472576220101175, 'Validation Loss': 26.02206540107727, 'Real Validation Loss': 26853370.041666668} 94
95
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 4.178285685310514, 'Validation Loss': 22.715020149946213, 'Real Validation Loss': 26435289.5625} 95
96
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 4.083123349580977, 'Validation Loss': 23.59505432844162, 'Real Validation Loss': 25995845.041666668} 96
97
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 4.0115807434522, 'Validation Loss': 23.3240591386954, 'Real Validation Loss': 25816329.0625} 97
98
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 3.9165048958589646, 'Validation Loss': 24.7131870786349, 'Real Validation Loss': 26450300.395833332} 98
99
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 3.8652372425849286, 'Validation Loss': 23.9734765291214, 'Real Validation Loss': 27118701.729166668} 99
100
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 3.7563321496681024, 'Validation Loss': 23.13549925883611, 'Real Validation Loss': 26820278.4375} 100
101
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 3.6849218861616144, 'Validation Loss': 22.747137318054836, 'Real Validation Loss': 25990841.6875} 101
102
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 3.6280805649013694, 'Validation Loss': 22.279545207818348, 'Real Validation Loss': 26338654.479166668} 102
103
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 3.5384848483424354, 'Validation Loss': 23.827208558718365, 'Real Validation Loss': 26592642.729166668} 103
104
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 3.380172549506471, 'Validation Loss': 21.68899832169215, 'Real Validation Loss': 26166976.770833332} 104
105
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 3.3579649281533017, 'Validation Loss': 23.185380458831787, 'Real Validation Loss': 26202719.9375} 105
106
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 3.3145059426833887, 'Validation Loss': 23.772561341524124, 'Real Validation Loss': 26802487.145833332} 106
107
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 3.2726067499908207, 'Validation Loss': 23.551488320032757, 'Real Validation Loss': 25742991.0} 107
108
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 3.151720091368549, 'Validation Loss': 22.456478317578632, 'Real Validation Loss': 26139075.208333332} 108
109
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 3.1631504565985145, 'Validation Loss': 25.928506791591644, 'Real Validation Loss': 26110638.729166668} 109
110
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 3.087628528299994, 'Validation Loss': 22.063069810469944, 'Real Validation Loss': 26572661.979166668} 110
111
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 3.023993984587383, 'Validation Loss': 23.51382604241371, 'Real Validation Loss': 26141203.104166668} 111
112
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 2.9229124565736964, 'Validation Loss': 24.06481157739957, 'Real Validation Loss': 26898005.208333332} 112
113
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 2.891228320245505, 'Validation Loss': 22.35518206159274, 'Real Validation Loss': 26235834.354166668} 113
114
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 2.8473047033674908, 'Validation Loss': 26.323318759600323, 'Real Validation Loss': 25337836.3125} 114
115
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 2.819405355116018, 'Validation Loss': 23.07751429080963, 'Real Validation Loss': 26199947.625} 115
116
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 2.7593622095150527, 'Validation Loss': 29.26003247499466, 'Real Validation Loss': 27788023.104166668} 116
117
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 2.748197752713845, 'Validation Loss': 24.194186290105183, 'Real Validation Loss': 26456259.083333332} 117
118
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 2.654241504081736, 'Validation Loss': 22.019241611162823, 'Real Validation Loss': 26529387.375} 118
119
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 2.6525548649646664, 'Validation Loss': 22.782002250353496, 'Real Validation Loss': 26089952.958333332} 119
120
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 2.5909476028669864, 'Validation Loss': 22.3339706659317, 'Real Validation Loss': 26089202.666666668} 120
121
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 2.501302680056811, 'Validation Loss': 22.32264272371928, 'Real Validation Loss': 26548265.5625} 121
122
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 2.532541159096114, 'Validation Loss': 23.71086424589157, 'Real Validation Loss': 26975766.5} 122
123
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 2.46541012411505, 'Validation Loss': 23.326220909754436, 'Real Validation Loss': 26317145.9375} 123
124
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 2.4461203854174633, 'Validation Loss': 23.521835525830586, 'Real Validation Loss': 25787701.8125} 124
125
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 2.382904223814548, 'Validation Loss': 22.74923359354337, 'Real Validation Loss': 26318003.375} 125
126
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 2.4047810059543675, 'Validation Loss': 27.694559792677563, 'Real Validation Loss': 25295881.041666668} 126
127
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 2.344090732334482, 'Validation Loss': 22.90266375740369, 'Real Validation Loss': 26469715.208333332} 127
128
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 2.269599870804253, 'Validation Loss': 27.82386765877406, 'Real Validation Loss': 27713480.1875} 128
129
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 2.3059374911132053, 'Validation Loss': 34.47479510307312, 'Real Validation Loss': 27974845.166666668} 129
130
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 2.2570833455219494, 'Validation Loss': 23.16741230090459, 'Real Validation Loss': 26917932.125} 130
131
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 2.1643281376689947, 'Validation Loss': 22.008457203706104, 'Real Validation Loss': 26030193.833333332} 131
132
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 2.21227337336009, 'Validation Loss': 23.03805238008499, 'Real Validation Loss': 26965724.041666668} 132
133
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 2.1174873971376633, 'Validation Loss': 22.83635675907135, 'Real Validation Loss': 25993106.604166668} 133
134
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 2.1256640968285256, 'Validation Loss': 23.349507212638855, 'Real Validation Loss': 26177444.833333332} 134
135
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 2.0593457821937253, 'Validation Loss': 25.640060861905415, 'Real Validation Loss': 25499277.166666668} 135
136
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 2.0290456440001923, 'Validation Loss': 24.013838191827137, 'Real Validation Loss': 25631216.1875} 136
137
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 2.053202050541519, 'Validation Loss': 22.808093736569088, 'Real Validation Loss': 26744963.708333332} 137
138
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 1.9953034702166037, 'Validation Loss': 24.828730483849842, 'Real Validation Loss': 27026410.979166668} 138
139
TL Mean Absolute Loss vs Epoch [Y: qrs, Learning Rate: 0.0005] {'Training Loss': 2.00926202293461, 'Validation Loss': 23.198091963926952, 'Real Validation Loss': 26470784.0625} 139


-------------hr---------------
0 tarainning loss : 1628.477272582398 validation loss : 35.76571957270304 Real validation loss : 35.76571957270304
Validation loss decreased (inf --> 35.765720).  Saving model ...
1 tarainning loss : 2.764149271928233 validation loss : 0.11777142148154478 Real validation loss : 0.11777142148154478
Validation loss decreased (35.765720 --> 0.117771).  Saving model ...
2 tarainning loss : 0.5934007049905597 validation loss : 2.9672537073493004 Real validation loss : 2.9672537073493004
EarlyStopping counter: 1 out of 100
3 tarainning loss : 0.5785217130383377 validation loss : 0.49878943897783756 Real validation loss : 0.49878943897783756
EarlyStopping counter: 2 out of 100
4 tarainning loss : 0.531429106914005 validation loss : 2.7224184200167656 Real validation loss : 2.7224184200167656
EarlyStopping counter: 3 out of 100
5 tarainning loss : 0.5057311199195341 validation loss : 3.618893419702848 Real validation loss : 3.618893419702848
EarlyStopping counter: 4 out of 100
6 tarainning loss : 0.4301679224376402 validation loss : 1.0069246751566727 Real validation loss : 1.0069246751566727
EarlyStopping counter: 5 out of 100
7 tarainning loss : 1.468917713584781 validation loss : 0.6249490957707167 Real validation loss : 0.6249490957707167
EarlyStopping counter: 6 out of 100
8 tarainning loss : 0.5855886370607628 validation loss : 0.3111084469904502 Real validation loss : 0.3111084469904502
EarlyStopping counter: 7 out of 100
9 tarainning loss : 0.5358212273641151 validation loss : 1.6669515781104565 Real validation loss : 1.6669515781104565
EarlyStopping counter: 8 out of 100
10 tarainning loss : 0.4802252903219366 validation loss : 0.15956137795001268 Real validation loss : 0.15956137795001268
EarlyStopping counter: 9 out of 100
11 tarainning loss : 0.44785701895076513 validation loss : 0.1395905182386438 Real validation loss : 0.1395905182386438
EarlyStopping counter: 10 out of 100
12 tarainning loss : 0.3570674440260796 validation loss : 1.2602998601893585 Real validation loss : 1.2602998601893585
EarlyStopping counter: 11 out of 100
13 tarainning loss : 0.33465414746209177 validation loss : 3.002189273635546 Real validation loss : 3.002189273635546
EarlyStopping counter: 12 out of 100
14 tarainning loss : 0.2650256919263231 validation loss : 2.1178621475895247 Real validation loss : 2.1178621475895247
EarlyStopping counter: 13 out of 100
15 tarainning loss : 0.21884473896589066 validation loss : 0.5512886010110378 Real validation loss : 0.5512886010110378
EarlyStopping counter: 14 out of 100
16 tarainning loss : 0.14464137952672232 validation loss : 0.35330620718499023 Real validation loss : 0.35330620718499023
EarlyStopping counter: 15 out of 100
17 tarainning loss : 0.08074092019842462 validation loss : 0.20732852288832268 Real validation loss : 0.20732852288832268
EarlyStopping counter: 16 out of 100
18 tarainning loss : 0.0769908927407892 validation loss : 0.12313878450853129 Real validation loss : 0.12313878450853129
EarlyStopping counter: 17 out of 100
19 tarainning loss : 0.050558972769315556 validation loss : 1.562307274589936 Real validation loss : 1.562307274589936
EarlyStopping counter: 18 out of 100
20 tarainning loss : 0.18571638982000896 validation loss : 0.43390077880273265 Real validation loss : 0.43390077880273265
EarlyStopping counter: 19 out of 100
21 tarainning loss : 0.06437929613371703 validation loss : 0.0470614797474506 Real validation loss : 0.0470614797474506
Validation loss decreased (0.117771 --> 0.047061).  Saving model ...
22 tarainning loss : 0.043232141342136134 validation loss : 0.035698918237661324 Real validation loss : 0.035698918237661324
Validation loss decreased (0.047061 --> 0.035699).  Saving model ...
23 tarainning loss : 0.04216675444836893 validation loss : 0.057943784670593836 Real validation loss : 0.057943784670593836
EarlyStopping counter: 1 out of 100
24 tarainning loss : 0.03655075595310131 validation loss : 0.03951491747284308 Real validation loss : 0.03951491747284308
EarlyStopping counter: 2 out of 100
25 tarainning loss : 0.03316589426200441 validation loss : 0.10179404821246862 Real validation loss : 0.10179404821246862
EarlyStopping counter: 3 out of 100
26 tarainning loss : 0.03951463996534032 validation loss : 0.020404895146687824 Real validation loss : 0.020404895146687824
Validation loss decreased (0.035699 --> 0.020405).  Saving model ...
27 tarainning loss : 0.03248746517489067 validation loss : 0.28132608253508806 Real validation loss : 0.28132608253508806
EarlyStopping counter: 1 out of 100
28 tarainning loss : 0.029988584289300412 validation loss : 0.17149607464671135 Real validation loss : 0.17149607464671135
EarlyStopping counter: 2 out of 100
29 tarainning loss : 0.030861280367832977 validation loss : 0.069490156446894 Real validation loss : 0.069490156446894
EarlyStopping counter: 3 out of 100
30 tarainning loss : 0.02678671983945846 validation loss : 0.13465397936912873 Real validation loss : 0.13465397936912873
EarlyStopping counter: 4 out of 100
31 tarainning loss : 0.031170276048572473 validation loss : 0.04447717766743153 Real validation loss : 0.04447717766743153
EarlyStopping counter: 5 out of 100
32 tarainning loss : 0.02362622529985981 validation loss : 0.02117668482242152 Real validation loss : 0.02117668482242152
EarlyStopping counter: 6 out of 100
33 tarainning loss : 0.023291713155337353 validation loss : 0.28486179855341714 Real validation loss : 0.28486179855341714
EarlyStopping counter: 7 out of 100
34 tarainning loss : 0.024156498772776924 validation loss : 0.03242222386567543 Real validation loss : 0.03242222386567543
EarlyStopping counter: 8 out of 100
35 tarainning loss : 0.022338140981703957 validation loss : 0.028728587242464226 Real validation loss : 0.028728587242464226
EarlyStopping counter: 9 out of 100
36 tarainning loss : 0.02280825895512401 validation loss : 0.019691964698722586 Real validation loss : 0.019691964698722586
Validation loss decreased (0.020405 --> 0.019692).  Saving model ...
37 tarainning loss : 0.02111002214150418 validation loss : 0.09638444730080664 Real validation loss : 0.09638444730080664
EarlyStopping counter: 1 out of 100
38 tarainning loss : 0.021381699615603662 validation loss : 0.03346135232519979 Real validation loss : 0.03346135232519979
EarlyStopping counter: 2 out of 100
39 tarainning loss : 0.01906376912076695 validation loss : 0.031993727141525596 Real validation loss : 0.031993727141525596
EarlyStopping counter: 3 out of 100
40 tarainning loss : 0.02068974817999264 validation loss : 0.019984290362723794 Real validation loss : 0.019984290362723794
EarlyStopping counter: 4 out of 100
41 tarainning loss : 0.019994194829912167 validation loss : 0.022496006422443315 Real validation loss : 0.022496006422443315
EarlyStopping counter: 5 out of 100
42 tarainning loss : 0.017931091528981532 validation loss : 0.018822126536785316 Real validation loss : 0.018822126536785316
Validation loss decreased (0.019692 --> 0.018822).  Saving model ...
43 tarainning loss : 0.019480690635315986 validation loss : 0.07379500346723944 Real validation loss : 0.07379500346723944
EarlyStopping counter: 1 out of 100
44 tarainning loss : 0.017261551109632064 validation loss : 0.18339537115146717 Real validation loss : 0.18339537115146717
EarlyStopping counter: 2 out of 100
45 tarainning loss : 0.018255822293992554 validation loss : 0.19459371315315366 Real validation loss : 0.19459371315315366
EarlyStopping counter: 3 out of 100
46 tarainning loss : 0.019206327217146463 validation loss : 0.020678437829095248 Real validation loss : 0.020678437829095248
EarlyStopping counter: 4 out of 100
47 tarainning loss : 0.016680857501094024 validation loss : 0.016940658873257537 Real validation loss : 0.016940658873257537
Validation loss decreased (0.018822 --> 0.016941).  Saving model ...
48 tarainning loss : 0.016478896058661322 validation loss : 0.056592801779819034 Real validation loss : 0.056592801779819034
EarlyStopping counter: 1 out of 100
49 tarainning loss : 0.017494071031484856 validation loss : 0.12707058782689273 Real validation loss : 0.12707058782689273
EarlyStopping counter: 2 out of 100
50 tarainning loss : 0.01633223759859976 validation loss : 0.15379197243601084 Real validation loss : 0.15379197243601084
EarlyStopping counter: 3 out of 100
51 tarainning loss : 0.016057953529601834 validation loss : 0.0983843607828021 Real validation loss : 0.0983843607828021
EarlyStopping counter: 4 out of 100
52 tarainning loss : 0.015739605827977194 validation loss : 0.023773258028086275 Real validation loss : 0.023773258028086275
EarlyStopping counter: 5 out of 100
53 tarainning loss : 0.015500341243016611 validation loss : 0.019836930364059906 Real validation loss : 0.019836930364059906
EarlyStopping counter: 6 out of 100
54 tarainning loss : 0.015484386883544227 validation loss : 0.11612473094525437 Real validation loss : 0.11612473094525437
EarlyStopping counter: 7 out of 100
55 tarainning loss : 0.01597643454789842 validation loss : 0.01936007073769967 Real validation loss : 0.01936007073769967
EarlyStopping counter: 8 out of 100
56 tarainning loss : 0.014843518265338704 validation loss : 0.0425733583397232 Real validation loss : 0.0425733583397232
EarlyStopping counter: 9 out of 100
57 tarainning loss : 0.015276966944244125 validation loss : 0.028908272603681933 Real validation loss : 0.028908272603681933
EarlyStopping counter: 10 out of 100
58 tarainning loss : 0.016545055730715102 validation loss : 0.017338535146942984 Real validation loss : 0.017338535146942984
EarlyStopping counter: 11 out of 100
59 tarainning loss : 0.013704530723261138 validation loss : 0.0159145099799692 Real validation loss : 0.0159145099799692
Validation loss decreased (0.016941 --> 0.015915).  Saving model ...
60 tarainning loss : 0.014483006771160765 validation loss : 0.03238231708140423 Real validation loss : 0.03238231708140423
EarlyStopping counter: 1 out of 100
61 tarainning loss : 0.013516677284142098 validation loss : 0.035355696318826325 Real validation loss : 0.035355696318826325
EarlyStopping counter: 2 out of 100
62 tarainning loss : 0.014720276779303544 validation loss : 0.16660696982095638 Real validation loss : 0.16660696982095638
EarlyStopping counter: 3 out of 100
63 tarainning loss : 0.013590512409083653 validation loss : 0.014044850759091787 Real validation loss : 0.014044850759091787
Validation loss decreased (0.015915 --> 0.014045).  Saving model ...
64 tarainning loss : 0.01373212909884995 validation loss : 0.05399157506568978 Real validation loss : 0.05399157506568978
EarlyStopping counter: 1 out of 100
65 tarainning loss : 0.014199765558387513 validation loss : 0.10697824019007385 Real validation loss : 0.10697824019007385
EarlyStopping counter: 2 out of 100
66 tarainning loss : 0.013045514677437621 validation loss : 0.09891527673850457 Real validation loss : 0.09891527673850457
EarlyStopping counter: 3 out of 100
67 tarainning loss : 0.013014358756416825 validation loss : 0.02107151331923281 Real validation loss : 0.02107151331923281
EarlyStopping counter: 4 out of 100
68 tarainning loss : 0.012740478337025893 validation loss : 0.017447120005575318 Real validation loss : 0.017447120005575318
EarlyStopping counter: 5 out of 100
69 tarainning loss : 0.01325870089984815 validation loss : 0.031093922754128773 Real validation loss : 0.031093922754128773
EarlyStopping counter: 6 out of 100
70 tarainning loss : 0.013142222410426774 validation loss : 0.017349414478909846 Real validation loss : 0.017349414478909846
EarlyStopping counter: 7 out of 100
71 tarainning loss : 0.028281609648606723 validation loss : 0.023058166436385363 Real validation loss : 0.023058166436385363
EarlyStopping counter: 8 out of 100
72 tarainning loss : 0.011098492105136262 validation loss : 0.016228062178318698 Real validation loss : 0.016228062178318698
EarlyStopping counter: 9 out of 100
73 tarainning loss : 0.011308925649270826 validation loss : 0.015881359247335542 Real validation loss : 0.015881359247335542
EarlyStopping counter: 10 out of 100
74 tarainning loss : 0.012375757991681717 validation loss : 0.05710920489703616 Real validation loss : 0.05710920489703616
EarlyStopping counter: 11 out of 100
75 tarainning loss : 0.01249684662122382 validation loss : 0.015436396468430758 Real validation loss : 0.015436396468430758
EarlyStopping counter: 12 out of 100
76 tarainning loss : 0.011865982230445113 validation loss : 0.026280065717097994 Real validation loss : 0.026280065717097994
EarlyStopping counter: 13 out of 100
77 tarainning loss : 0.012341615115322885 validation loss : 0.014961335643117005 Real validation loss : 0.014961335643117005
EarlyStopping counter: 14 out of 100
78 tarainning loss : 0.011474515660513353 validation loss : 0.018346750856532406 Real validation loss : 0.018346750856532406
EarlyStopping counter: 15 out of 100
79 tarainning loss : 0.01211136220838401 validation loss : 0.03876380071354409 Real validation loss : 0.03876380071354409
EarlyStopping counter: 16 out of 100
80 tarainning loss : 0.012277432859583538 validation loss : 0.05099359449620048 Real validation loss : 0.05099359449620048
EarlyStopping counter: 17 out of 100
81 tarainning loss : 0.01142133590685958 validation loss : 0.01941135319066234 Real validation loss : 0.01941135319066234
EarlyStopping counter: 18 out of 100
82 tarainning loss : 0.011403090531692436 validation loss : 0.024500341600893687 Real validation loss : 0.024500341600893687
EarlyStopping counter: 19 out of 100
83 tarainning loss : 0.011622413862276906 validation loss : 0.07672627526335418 Real validation loss : 0.07672627526335418
EarlyStopping counter: 20 out of 100
84 tarainning loss : 0.011033584190432476 validation loss : 0.014015374001852857 Real validation loss : 0.014015374001852857
Validation loss decreased (0.014045 --> 0.014015).  Saving model ...
85 tarainning loss : 0.01181252758283544 validation loss : 0.017428528857029352 Real validation loss : 0.017428528857029352
EarlyStopping counter: 1 out of 100
86 tarainning loss : 0.011069421819991007 validation loss : 0.015343057360344877 Real validation loss : 0.015343057360344877
EarlyStopping counter: 2 out of 100
87 tarainning loss : 0.01115604019009778 validation loss : 0.026824181045716006 Real validation loss : 0.026824181045716006
EarlyStopping counter: 3 out of 100
88 tarainning loss : 0.010896527636210344 validation loss : 0.015597005947104966 Real validation loss : 0.015597005947104966
EarlyStopping counter: 4 out of 100
89 tarainning loss : 0.01097934406499719 validation loss : 0.08409653937754531 Real validation loss : 0.08409653937754531
EarlyStopping counter: 5 out of 100
90 tarainning loss : 0.011023948611117908 validation loss : 0.05118197839086255 Real validation loss : 0.05118197839086255
EarlyStopping counter: 6 out of 100
91 tarainning loss : 0.010751975537918576 validation loss : 0.015575724362861365 Real validation loss : 0.015575724362861365
EarlyStopping counter: 7 out of 100
92 tarainning loss : 0.010886919606589317 validation loss : 0.014266059588408098 Real validation loss : 0.014266059588408098
EarlyStopping counter: 8 out of 100
93 tarainning loss : 0.010232603330614331 validation loss : 0.014869487538817339 Real validation loss : 0.014869487538817339
EarlyStopping counter: 9 out of 100
94 tarainning loss : 0.01107153368425381 validation loss : 0.04019301780499518 Real validation loss : 0.04019301780499518
EarlyStopping counter: 10 out of 100
95 tarainning loss : 0.010195387899021217 validation loss : 0.042482486188722156 Real validation loss : 0.042482486188722156
EarlyStopping counter: 11 out of 100
96 tarainning loss : 0.010471511176307619 validation loss : 0.01591592596863241 Real validation loss : 0.01591592596863241
EarlyStopping counter: 12 out of 100
97 tarainning loss : 0.010639474641770945 validation loss : 0.01464411163275751 Real validation loss : 0.01464411163275751
EarlyStopping counter: 13 out of 100
98 tarainning loss : 0.010213970912188331 validation loss : 0.015580529453776156 Real validation loss : 0.015580529453776156
EarlyStopping counter: 14 out of 100
99 tarainning loss : 0.010224947575870339 validation loss : 0.015191069857489007 Real validation loss : 0.015191069857489007
EarlyStopping counter: 15 out of 100
100 tarainning loss : 0.010480427474325442 validation loss : 0.014620530399649093 Real validation loss : 0.014620530399649093
EarlyStopping counter: 16 out of 100
101 tarainning loss : 0.010095629844751068 validation loss : 0.0577756519196555 Real validation loss : 0.0577756519196555
EarlyStopping counter: 17 out of 100
102 tarainning loss : 0.009929179238353222 validation loss : 0.015091236835966507 Real validation loss : 0.015091236835966507
EarlyStopping counter: 18 out of 100
103 tarainning loss : 0.010016331054895218 validation loss : 0.023278688410452258 Real validation loss : 0.023278688410452258
EarlyStopping counter: 19 out of 100
104 tarainning loss : 0.009585747022918995 validation loss : 0.022159416791206848 Real validation loss : 0.022159416791206848
EarlyStopping counter: 20 out of 100
105 tarainning loss : 0.00943951655257381 validation loss : 0.015364782768301666 Real validation loss : 0.015364782768301666
EarlyStopping counter: 21 out of 100
106 tarainning loss : 0.009621956959357034 validation loss : 0.01958348224676835 Real validation loss : 0.01958348224676835
EarlyStopping counter: 22 out of 100
107 tarainning loss : 0.009621084867311376 validation loss : 0.01694936620575997 Real validation loss : 0.01694936620575997
EarlyStopping counter: 23 out of 100
108 tarainning loss : 0.01018158020451665 validation loss : 0.01374716060430122 Real validation loss : 0.01374716060430122
Validation loss decreased (0.014015 --> 0.013747).  Saving model ...
109 tarainning loss : 0.009266966522999626 validation loss : 0.019560587058852736 Real validation loss : 0.019560587058852736
EarlyStopping counter: 1 out of 100
110 tarainning loss : 0.009531275278902069 validation loss : 0.03940994521447768 Real validation loss : 0.03940994521447768
EarlyStopping counter: 2 out of 100
111 tarainning loss : 0.009641275194938615 validation loss : 0.02092265634564683 Real validation loss : 0.02092265634564683
EarlyStopping counter: 3 out of 100
112 tarainning loss : 0.009159331324694589 validation loss : 0.01406990045021909 Real validation loss : 0.01406990045021909
EarlyStopping counter: 4 out of 100
113 tarainning loss : 0.00910764944472327 validation loss : 0.07619421304358791 Real validation loss : 0.07619421304358791
EarlyStopping counter: 5 out of 100
114 tarainning loss : 0.009436946779094041 validation loss : 0.016258498256017145 Real validation loss : 0.016258498256017145
EarlyStopping counter: 6 out of 100
115 tarainning loss : 0.009262939396303337 validation loss : 0.01477089149314755 Real validation loss : 0.01477089149314755
EarlyStopping counter: 7 out of 100
116 tarainning loss : 0.008879044362945607 validation loss : 0.031457904648656644 Real validation loss : 0.031457904648656644
EarlyStopping counter: 8 out of 100
117 tarainning loss : 0.00916652975672292 validation loss : 0.084283892918999 Real validation loss : 0.084283892918999
EarlyStopping counter: 9 out of 100
118 tarainning loss : 0.009172138434543054 validation loss : 0.06778734732264032 Real validation loss : 0.06778734732264032
EarlyStopping counter: 10 out of 100
119 tarainning loss : 0.008586181856833427 validation loss : 0.0171214724444629 Real validation loss : 0.0171214724444629
EarlyStopping counter: 11 out of 100
120 tarainning loss : 0.008934497737434361 validation loss : 0.021727924739631515 Real validation loss : 0.021727924739631515
EarlyStopping counter: 12 out of 100
121 tarainning loss : 0.008806500010812462 validation loss : 0.013630306959385052 Real validation loss : 0.013630306959385052
Validation loss decreased (0.013747 --> 0.013630).  Saving model ...
122 tarainning loss : 0.008804746703299672 validation loss : 0.019263216556282714 Real validation loss : 0.019263216556282714
EarlyStopping counter: 1 out of 100
123 tarainning loss : 0.008658477488470656 validation loss : 0.016350860397020977 Real validation loss : 0.016350860397020977
EarlyStopping counter: 2 out of 100
124 tarainning loss : 0.0088652920180524 validation loss : 0.020087375276489183 Real validation loss : 0.020087375276489183
EarlyStopping counter: 3 out of 100
125 tarainning loss : 0.008586076422085495 validation loss : 0.03411635533363248 Real validation loss : 0.03411635533363248
EarlyStopping counter: 4 out of 100
126 tarainning loss : 0.008508540053399058 validation loss : 0.014561256311329393 Real validation loss : 0.014561256311329393
EarlyStopping counter: 5 out of 100
127 tarainning loss : 0.008630565843065202 validation loss : 0.020339778071502224 Real validation loss : 0.020339778071502224
EarlyStopping counter: 6 out of 100
128 tarainning loss : 0.00828847074685899 validation loss : 0.015993134496966377 Real validation loss : 0.015993134496966377
EarlyStopping counter: 7 out of 100
129 tarainning loss : 0.008427377201270111 validation loss : 0.013511096161285726 Real validation loss : 0.013511096161285726
Validation loss decreased (0.013630 --> 0.013511).  Saving model ...
130 tarainning loss : 0.008135812518188087 validation loss : 0.013877266324319256 Real validation loss : 0.013877266324319256
EarlyStopping counter: 1 out of 100
131 tarainning loss : 0.008500449230032698 validation loss : 0.043611485802102834 Real validation loss : 0.043611485802102834
EarlyStopping counter: 2 out of 100
132 tarainning loss : 0.00837615640988991 validation loss : 0.013436769382678904 Real validation loss : 0.013436769382678904
Validation loss decreased (0.013511 --> 0.013437).  Saving model ...
133 tarainning loss : 0.008215191742639651 validation loss : 0.016463713051052764 Real validation loss : 0.016463713051052764
EarlyStopping counter: 1 out of 100
134 tarainning loss : 0.008420480859220555 validation loss : 0.02530712242393444 Real validation loss : 0.02530712242393444
EarlyStopping counter: 2 out of 100
135 tarainning loss : 0.00824996365568702 validation loss : 0.024508694468143705 Real validation loss : 0.024508694468143705
EarlyStopping counter: 3 out of 100
136 tarainning loss : 0.00789229225899492 validation loss : 0.04537061433074996 Real validation loss : 0.04537061433074996
EarlyStopping counter: 4 out of 100
137 tarainning loss : 0.008097778469919768 validation loss : 0.061012911571500204 Real validation loss : 0.061012911571500204
EarlyStopping counter: 5 out of 100
138 tarainning loss : 0.008080113173229314 validation loss : 0.013565502100391313 Real validation loss : 0.013565502100391313
EarlyStopping counter: 6 out of 100
139 tarainning loss : 0.008325180765680803 validation loss : 0.026880265038926154 Real validation loss : 0.026880265038926154
EarlyStopping counter: 7 out of 100
140 tarainning loss : 0.007848844459453698 validation loss : 0.013228660997507783 Real validation loss : 0.013228660997507783
Validation loss decreased (0.013437 --> 0.013229).  Saving model ...
141 tarainning loss : 0.008070714995423686 validation loss : 0.03210870630573481 Real validation loss : 0.03210870630573481
EarlyStopping counter: 1 out of 100
142 tarainning loss : 0.007686898158069793 validation loss : 0.08026662084739655 Real validation loss : 0.08026662084739655
EarlyStopping counter: 2 out of 100
143 tarainning loss : 0.00798756584188221 validation loss : 0.0161019790393766 Real validation loss : 0.0161019790393766
EarlyStopping counter: 3 out of 100
144 tarainning loss : 0.007635877388352492 validation loss : 0.013580099616471367 Real validation loss : 0.013580099616471367
EarlyStopping counter: 4 out of 100
145 tarainning loss : 0.007686328672624509 validation loss : 0.014934966568641054 Real validation loss : 0.014934966568641054
EarlyStopping counter: 5 out of 100
146 tarainning loss : 0.007656056637757337 validation loss : 0.014026252528613744 Real validation loss : 0.014026252528613744
EarlyStopping counter: 6 out of 100
147 tarainning loss : 0.0078204693107928 validation loss : 0.026070538345569123 Real validation loss : 0.026070538345569123
EarlyStopping counter: 7 out of 100
148 tarainning loss : 0.007586053747752118 validation loss : 0.04044052244474491 Real validation loss : 0.04044052244474491
EarlyStopping counter: 8 out of 100
149 tarainning loss : 0.0077696327827407015 validation loss : 0.014791192734264769 Real validation loss : 0.014791192734264769
EarlyStopping counter: 9 out of 100
150 tarainning loss : 0.007474266880022199 validation loss : 0.016788607890096802 Real validation loss : 0.016788607890096802
EarlyStopping counter: 10 out of 100
151 tarainning loss : 0.007535451317027817 validation loss : 0.031309995839061834 Real validation loss : 0.031309995839061834
EarlyStopping counter: 11 out of 100
152 tarainning loss : 0.0078079910981828935 validation loss : 0.03147460941302901 Real validation loss : 0.03147460941302901
EarlyStopping counter: 12 out of 100
153 tarainning loss : 0.007150515354315348 validation loss : 0.020175178719606873 Real validation loss : 0.020175178719606873
EarlyStopping counter: 13 out of 100
154 tarainning loss : 0.007613459882737769 validation loss : 0.013334542115141327 Real validation loss : 0.013334542115141327
EarlyStopping counter: 14 out of 100
155 tarainning loss : 0.007357452817866639 validation loss : 0.01346157576093295 Real validation loss : 0.01346157576093295
EarlyStopping counter: 15 out of 100
156 tarainning loss : 0.007017021546223314 validation loss : 0.017126552780003596 Real validation loss : 0.017126552780003596
EarlyStopping counter: 16 out of 100
157 tarainning loss : 0.007345778244788006 validation loss : 0.02080157933717904 Real validation loss : 0.02080157933717904
EarlyStopping counter: 17 out of 100
158 tarainning loss : 0.007204577098216075 validation loss : 0.014902689305017702 Real validation loss : 0.014902689305017702
EarlyStopping counter: 18 out of 100
159 tarainning loss : 0.007396726969746704 validation loss : 0.020938511210260913 Real validation loss : 0.020938511210260913
EarlyStopping counter: 19 out of 100
160 tarainning loss : 0.0071651265968057185 validation loss : 0.013694920024136081 Real validation loss : 0.013694920024136081
EarlyStopping counter: 20 out of 100
161 tarainning loss : 0.007193853199813969 validation loss : 0.02342797862365842 Real validation loss : 0.02342797862365842
EarlyStopping counter: 21 out of 100
162 tarainning loss : 0.0070053462239975895 validation loss : 0.01754793358850293 Real validation loss : 0.01754793358850293
EarlyStopping counter: 22 out of 100
163 tarainning loss : 0.007079178138744687 validation loss : 0.018240209319628775 Real validation loss : 0.018240209319628775
EarlyStopping counter: 23 out of 100
164 tarainning loss : 0.007036020369897566 validation loss : 0.0161845941717426 Real validation loss : 0.0161845941717426
EarlyStopping counter: 24 out of 100
165 tarainning loss : 0.007074100390774824 validation loss : 0.021544104354688898 Real validation loss : 0.021544104354688898
EarlyStopping counter: 25 out of 100
166 tarainning loss : 0.006646117317547648 validation loss : 0.013371578776665652 Real validation loss : 0.013371578776665652
EarlyStopping counter: 26 out of 100
167 tarainning loss : 0.007083951864210915 validation loss : 0.01691709234728478 Real validation loss : 0.01691709234728478
EarlyStopping counter: 27 out of 100
168 tarainning loss : 0.006654773494912261 validation loss : 0.01847765458902965 Real validation loss : 0.01847765458902965
EarlyStopping counter: 28 out of 100
169 tarainning loss : 0.007058113340110192 validation loss : 0.014287631585223911 Real validation loss : 0.014287631585223911
EarlyStopping counter: 29 out of 100
170 tarainning loss : 0.006718793694420595 validation loss : 0.06143444237144043 Real validation loss : 0.06143444237144043
EarlyStopping counter: 30 out of 100
171 tarainning loss : 0.00670269896980585 validation loss : 0.023252825349724542 Real validation loss : 0.023252825349724542
EarlyStopping counter: 31 out of 100
172 tarainning loss : 0.006757386297300009 validation loss : 0.018811623788982008 Real validation loss : 0.018811623788982008
EarlyStopping counter: 32 out of 100
173 tarainning loss : 0.006746424847254395 validation loss : 0.021471475047292188 Real validation loss : 0.021471475047292188
EarlyStopping counter: 33 out of 100
174 tarainning loss : 0.006941362401302099 validation loss : 0.027526242406262707 Real validation loss : 0.027526242406262707
EarlyStopping counter: 34 out of 100
175 tarainning loss : 0.0066311618039777516 validation loss : 0.0160596036099984 Real validation loss : 0.0160596036099984
EarlyStopping counter: 35 out of 100
176 tarainning loss : 0.006457174915471267 validation loss : 0.05050950217992067 Real validation loss : 0.05050950217992067
EarlyStopping counter: 36 out of 100
177 tarainning loss : 0.006789426484082973 validation loss : 0.013283466881451508 Real validation loss : 0.013283466881451508
EarlyStopping counter: 37 out of 100
178 tarainning loss : 0.006747380753449344 validation loss : 0.013932971080066636 Real validation loss : 0.013932971080066636
EarlyStopping counter: 38 out of 100
179 tarainning loss : 0.00610361555084674 validation loss : 0.013620869402075186 Real validation loss : 0.013620869402075186
EarlyStopping counter: 39 out of 100
180 tarainning loss : 0.006702864817545053 validation loss : 0.015252940288822478 Real validation loss : 0.015252940288822478
EarlyStopping counter: 40 out of 100
181 tarainning loss : 0.006578184322479668 validation loss : 0.018276857862171408 Real validation loss : 0.018276857862171408
EarlyStopping counter: 41 out of 100
182 tarainning loss : 0.006269206126314511 validation loss : 0.014599053848845264 Real validation loss : 0.014599053848845264
EarlyStopping counter: 42 out of 100
183 tarainning loss : 0.006366019843019262 validation loss : 0.014051060347507397 Real validation loss : 0.014051060347507397
EarlyStopping counter: 43 out of 100
184 tarainning loss : 0.006454186506391177 validation loss : 0.013298057863721624 Real validation loss : 0.013298057863721624
EarlyStopping counter: 44 out of 100
185 tarainning loss : 0.0066648184451205 validation loss : 0.061985338029141225 Real validation loss : 0.061985338029141225
EarlyStopping counter: 45 out of 100
186 tarainning loss : 0.006296428799602358 validation loss : 0.023638727909807738 Real validation loss : 0.023638727909807738
EarlyStopping counter: 46 out of 100
187 tarainning loss : 0.00613862480986546 validation loss : 0.016595375636825338 Real validation loss : 0.016595375636825338
EarlyStopping counter: 47 out of 100
188 tarainning loss : 0.0062258320596303455 validation loss : 0.023133242396094527 Real validation loss : 0.023133242396094527
EarlyStopping counter: 48 out of 100
189 tarainning loss : 0.006131472712050669 validation loss : 0.013605192420072854 Real validation loss : 0.013605192420072854
EarlyStopping counter: 49 out of 100
190 tarainning loss : 0.006318118687789902 validation loss : 0.015034501882231174 Real validation loss : 0.015034501882231174
EarlyStopping counter: 50 out of 100
191 tarainning loss : 0.0060557621759441856 validation loss : 0.015700673509854823 Real validation loss : 0.015700673509854823
EarlyStopping counter: 51 out of 100
192 tarainning loss : 0.006140727511342239 validation loss : 0.01783632708247751 Real validation loss : 0.01783632708247751
EarlyStopping counter: 52 out of 100
193 tarainning loss : 0.006217182715219564 validation loss : 0.01315515092088996 Real validation loss : 0.01315515092088996
Validation loss decreased (0.013229 --> 0.013155).  Saving model ...
194 tarainning loss : 0.006237222006249084 validation loss : 0.013654505038478723 Real validation loss : 0.013654505038478723
EarlyStopping counter: 1 out of 100
195 tarainning loss : 0.0058940272451150156 validation loss : 0.19324754752839604 Real validation loss : 0.19324754752839604
EarlyStopping counter: 2 out of 100
196 tarainning loss : 0.006630539851077633 validation loss : 0.027914442548838753 Real validation loss : 0.027914442548838753
EarlyStopping counter: 3 out of 100
197 tarainning loss : 0.005821096155179731 validation loss : 0.019060902355704457 Real validation loss : 0.019060902355704457
EarlyStopping counter: 4 out of 100
198 tarainning loss : 0.0059580300714293325 validation loss : 0.0208373554632999 Real validation loss : 0.0208373554632999
EarlyStopping counter: 5 out of 100
199 tarainning loss : 0.0060757371266818025 validation loss : 0.01686384082616617 Real validation loss : 0.01686384082616617
EarlyStopping counter: 6 out of 100
200 tarainning loss : 0.005896468203744288 validation loss : 0.014340220547940893 Real validation loss : 0.014340220547940893
EarlyStopping counter: 7 out of 100
201 tarainning loss : 0.005932787888552774 validation loss : 0.013335527085776752 Real validation loss : 0.013335527085776752
EarlyStopping counter: 8 out of 100
202 tarainning loss : 0.005686638561879355 validation loss : 0.020119044308861096 Real validation loss : 0.020119044308861096
EarlyStopping counter: 9 out of 100
203 tarainning loss : 0.005969565375164874 validation loss : 0.02217962625824536 Real validation loss : 0.02217962625824536
EarlyStopping counter: 10 out of 100
204 tarainning loss : 0.0057741475320844705 validation loss : 0.013259470976966744 Real validation loss : 0.013259470976966744
EarlyStopping counter: 11 out of 100
205 tarainning loss : 0.005764897363773043 validation loss : 0.013456584560723664 Real validation loss : 0.013456584560723664
EarlyStopping counter: 12 out of 100
206 tarainning loss : 0.0057372649634796465 validation loss : 0.01367829748778604 Real validation loss : 0.01367829748778604
EarlyStopping counter: 13 out of 100
207 tarainning loss : 0.005772755235045426 validation loss : 0.01293223525378077 Real validation loss : 0.01293223525378077
Validation loss decreased (0.013155 --> 0.012932).  Saving model ...
208 tarainning loss : 0.005863042507713677 validation loss : 0.019598884993077565 Real validation loss : 0.019598884993077565
EarlyStopping counter: 1 out of 100
209 tarainning loss : 0.0056394091224466324 validation loss : 0.014231960551114753 Real validation loss : 0.014231960551114753
EarlyStopping counter: 2 out of 100
210 tarainning loss : 0.005611163473091189 validation loss : 0.013921586442544745 Real validation loss : 0.013921586442544745
EarlyStopping counter: 3 out of 100
211 tarainning loss : 0.005529751375910788 validation loss : 0.02686511471013849 Real validation loss : 0.02686511471013849
EarlyStopping counter: 4 out of 100
212 tarainning loss : 0.005525980369330702 validation loss : 0.05368738734008124 Real validation loss : 0.05368738734008124
EarlyStopping counter: 5 out of 100
213 tarainning loss : 0.005873333442428907 validation loss : 0.01394386388225636 Real validation loss : 0.01394386388225636
EarlyStopping counter: 6 out of 100
214 tarainning loss : 0.005367583882669048 validation loss : 0.02054581033492771 Real validation loss : 0.02054581033492771
EarlyStopping counter: 7 out of 100
215 tarainning loss : 0.0054739293011288655 validation loss : 0.047154033983436726 Real validation loss : 0.047154033983436726
EarlyStopping counter: 8 out of 100
216 tarainning loss : 0.005550099543489877 validation loss : 0.04826171092766648 Real validation loss : 0.04826171092766648
EarlyStopping counter: 9 out of 100
217 tarainning loss : 0.005427668256829169 validation loss : 0.026257566486795742 Real validation loss : 0.026257566486795742
EarlyStopping counter: 10 out of 100
218 tarainning loss : 0.005542194879055999 validation loss : 0.01631905215617735 Real validation loss : 0.01631905215617735
EarlyStopping counter: 11 out of 100
219 tarainning loss : 0.005422074623286314 validation loss : 0.021225390722975135 Real validation loss : 0.021225390722975135
EarlyStopping counter: 12 out of 100
220 tarainning loss : 0.005337749731447425 validation loss : 0.018313059360176947 Real validation loss : 0.018313059360176947
EarlyStopping counter: 13 out of 100
221 tarainning loss : 0.005489086664219534 validation loss : 0.021515735774300992 Real validation loss : 0.021515735774300992
EarlyStopping counter: 14 out of 100
222 tarainning loss : 0.005412113362420375 validation loss : 0.017353409270678338 Real validation loss : 0.017353409270678338
EarlyStopping counter: 15 out of 100
223 tarainning loss : 0.005242218062962707 validation loss : 0.023755282900917035 Real validation loss : 0.023755282900917035
EarlyStopping counter: 16 out of 100
224 tarainning loss : 0.005468654633056602 validation loss : 0.013950542585613826 Real validation loss : 0.013950542585613826
EarlyStopping counter: 17 out of 100
225 tarainning loss : 0.0052366079176687005 validation loss : 0.02561209670966491 Real validation loss : 0.02561209670966491
EarlyStopping counter: 18 out of 100
226 tarainning loss : 0.005245129848790122 validation loss : 0.020973244652850553 Real validation loss : 0.020973244652850553
EarlyStopping counter: 19 out of 100
227 tarainning loss : 0.00529158822301077 validation loss : 0.09006258573693533 Real validation loss : 0.09006258573693533
EarlyStopping counter: 20 out of 100
228 tarainning loss : 0.005233271588811829 validation loss : 0.01680631761943611 Real validation loss : 0.01680631761943611
EarlyStopping counter: 21 out of 100
229 tarainning loss : 0.00541527681681297 validation loss : 0.014488544155028649 Real validation loss : 0.014488544155028649
EarlyStopping counter: 22 out of 100
230 tarainning loss : 0.00509916127446995 validation loss : 0.01360182477219496 Real validation loss : 0.01360182477219496
EarlyStopping counter: 23 out of 100
231 tarainning loss : 0.005236639738263536 validation loss : 0.014874404165311716 Real validation loss : 0.014874404165311716
EarlyStopping counter: 24 out of 100
232 tarainning loss : 0.005057197639371999 validation loss : 0.022120810094444703 Real validation loss : 0.022120810094444703
EarlyStopping counter: 25 out of 100
233 tarainning loss : 0.005182050082156359 validation loss : 0.01370157895629139 Real validation loss : 0.01370157895629139
EarlyStopping counter: 26 out of 100
234 tarainning loss : 0.005157713705385751 validation loss : 0.013002128359706452 Real validation loss : 0.013002128359706452
EarlyStopping counter: 27 out of 100
235 tarainning loss : 0.005102773668454425 validation loss : 0.016500706726219505 Real validation loss : 0.016500706726219505
EarlyStopping counter: 28 out of 100
236 tarainning loss : 0.005018501021614882 validation loss : 0.03426174212169523 Real validation loss : 0.03426174212169523
EarlyStopping counter: 29 out of 100
237 tarainning loss : 0.004996310428839523 validation loss : 0.01796789514871004 Real validation loss : 0.01796789514871004
EarlyStopping counter: 30 out of 100
238 tarainning loss : 0.00515969694033021 validation loss : 0.014766374127551293 Real validation loss : 0.014766374127551293
EarlyStopping counter: 31 out of 100
239 tarainning loss : 0.00502996200019418 validation loss : 0.021543026339107502 Real validation loss : 0.021543026339107502
EarlyStopping counter: 32 out of 100
240 tarainning loss : 0.005141942433800504 validation loss : 0.017916074488312006 Real validation loss : 0.017916074488312006
EarlyStopping counter: 33 out of 100
241 tarainning loss : 0.005224433323846908 validation loss : 0.40403631919374067 Real validation loss : 0.40403631919374067
EarlyStopping counter: 34 out of 100
242 tarainning loss : 0.008284040116418158 validation loss : 0.013156654492680294 Real validation loss : 0.013156654492680294
EarlyStopping counter: 35 out of 100
243 tarainning loss : 0.004227486970012966 validation loss : 0.013981033941187585 Real validation loss : 0.013981033941187585
EarlyStopping counter: 36 out of 100
244 tarainning loss : 0.0045635907762460555 validation loss : 0.014192265633028 Real validation loss : 0.014192265633028
EarlyStopping counter: 37 out of 100
245 tarainning loss : 0.004748552850280372 validation loss : 0.014182489544812901 Real validation loss : 0.014182489544812901
EarlyStopping counter: 38 out of 100
246 tarainning loss : 0.004907217720794451 validation loss : 0.015048286271242736 Real validation loss : 0.015048286271242736
EarlyStopping counter: 39 out of 100
247 tarainning loss : 0.004808924293028359 validation loss : 0.014332501203170978 Real validation loss : 0.014332501203170978
EarlyStopping counter: 40 out of 100
248 tarainning loss : 0.004778170107093641 validation loss : 0.014053213274261603 Real validation loss : 0.014053213274261603
EarlyStopping counter: 41 out of 100
249 tarainning loss : 0.0047688892911899915 validation loss : 0.015016405988717452 Real validation loss : 0.015016405988717452
EarlyStopping counter: 42 out of 100
250 tarainning loss : 0.004774497066676949 validation loss : 0.02080669750769933 Real validation loss : 0.02080669750769933
EarlyStopping counter: 43 out of 100
251 tarainning loss : 0.00480542936561285 validation loss : 0.014090287329357428 Real validation loss : 0.014090287329357428
EarlyStopping counter: 44 out of 100
252 tarainning loss : 0.004610108451790824 validation loss : 0.02020206008455716 Real validation loss : 0.02020206008455716
EarlyStopping counter: 45 out of 100
253 tarainning loss : 0.004800919060403698 validation loss : 0.022362121138333652 Real validation loss : 0.022362121138333652
EarlyStopping counter: 46 out of 100
254 tarainning loss : 0.005049687317117248 validation loss : 0.013859268893914608 Real validation loss : 0.013859268893914608
EarlyStopping counter: 47 out of 100
255 tarainning loss : 0.004645820769028516 validation loss : 0.021539869776461273 Real validation loss : 0.021539869776461273
EarlyStopping counter: 48 out of 100
256 tarainning loss : 0.004680494477589118 validation loss : 0.022373572991151985 Real validation loss : 0.022373572991151985
EarlyStopping counter: 49 out of 100
257 tarainning loss : 0.004729970996384051 validation loss : 0.014476205105893314 Real validation loss : 0.014476205105893314
EarlyStopping counter: 50 out of 100
258 tarainning loss : 0.004600734296431801 validation loss : 0.01551565258220459 Real validation loss : 0.01551565258220459
EarlyStopping counter: 51 out of 100
259 tarainning loss : 0.004598089842599368 validation loss : 0.024935078186293442 Real validation loss : 0.024935078186293442
EarlyStopping counter: 52 out of 100
260 tarainning loss : 0.0046159520218585805 validation loss : 0.013414974110977104 Real validation loss : 0.013414974110977104
EarlyStopping counter: 53 out of 100
261 tarainning loss : 0.00471665116996159 validation loss : 0.045298489703175925 Real validation loss : 0.045298489703175925
EarlyStopping counter: 54 out of 100
262 tarainning loss : 0.004815620665595931 validation loss : 0.5333875206609567 Real validation loss : 0.5333875206609567
EarlyStopping counter: 55 out of 100
263 tarainning loss : 0.00595019047507384 validation loss : 0.01361469185697691 Real validation loss : 0.01361469185697691
EarlyStopping counter: 56 out of 100
264 tarainning loss : 0.004053072240398916 validation loss : 0.021609889052342623 Real validation loss : 0.021609889052342623
EarlyStopping counter: 57 out of 100
265 tarainning loss : 0.004325921611242768 validation loss : 0.014275183610152453 Real validation loss : 0.014275183610152453
EarlyStopping counter: 58 out of 100
266 tarainning loss : 0.0046733749891859555 validation loss : 0.055918057061110936 Real validation loss : 0.055918057061110936
EarlyStopping counter: 59 out of 100
267 tarainning loss : 0.004450407653050998 validation loss : 0.017662769115607563 Real validation loss : 0.017662769115607563
EarlyStopping counter: 60 out of 100
268 tarainning loss : 0.004654451110735926 validation loss : 0.015159224907013899 Real validation loss : 0.015159224907013899
EarlyStopping counter: 61 out of 100
269 tarainning loss : 0.004359138408751468 validation loss : 0.05536266847047955 Real validation loss : 0.05536266847047955
EarlyStopping counter: 62 out of 100
270 tarainning loss : 0.004514108837349035 validation loss : 0.01777339115506038 Real validation loss : 0.01777339115506038
EarlyStopping counter: 63 out of 100
271 tarainning loss : 0.004581426244063076 validation loss : 0.018617581091045093 Real validation loss : 0.018617581091045093
EarlyStopping counter: 64 out of 100
272 tarainning loss : 0.0044863765444704195 validation loss : 0.04634487947138647 Real validation loss : 0.04634487947138647
EarlyStopping counter: 65 out of 100
273 tarainning loss : 0.004471665449369684 validation loss : 0.013748516023042612 Real validation loss : 0.013748516023042612
EarlyStopping counter: 66 out of 100
274 tarainning loss : 0.004243689449442987 validation loss : 0.019003266973110538 Real validation loss : 0.019003266973110538
EarlyStopping counter: 67 out of 100
275 tarainning loss : 0.0042643456858354545 validation loss : 0.05348907100657622 Real validation loss : 0.05348907100657622
EarlyStopping counter: 68 out of 100
276 tarainning loss : 0.0044879785337305945 validation loss : 0.016720443449836846 Real validation loss : 0.016720443449836846
EarlyStopping counter: 69 out of 100
277 tarainning loss : 0.00429480523572866 validation loss : 0.013401737625827082 Real validation loss : 0.013401737625827082
EarlyStopping counter: 70 out of 100
278 tarainning loss : 0.0042425736015647905 validation loss : 0.019445547009430204 Real validation loss : 0.019445547009430204
EarlyStopping counter: 71 out of 100
279 tarainning loss : 0.0042332569912300584 validation loss : 0.01592666654808757 Real validation loss : 0.01592666654808757
EarlyStopping counter: 72 out of 100
280 tarainning loss : 0.004275032806455562 validation loss : 0.0140171953777705 Real validation loss : 0.0140171953777705
EarlyStopping counter: 73 out of 100
281 tarainning loss : 0.00432741239594923 validation loss : 0.01507612863012279 Real validation loss : 0.01507612863012279
EarlyStopping counter: 74 out of 100
282 tarainning loss : 0.004294347314305633 validation loss : 0.0146929329445508 Real validation loss : 0.0146929329445508
EarlyStopping counter: 75 out of 100
283 tarainning loss : 0.004233970262261588 validation loss : 0.014189772846293636 Real validation loss : 0.014189772846293636
EarlyStopping counter: 76 out of 100
284 tarainning loss : 0.004245433694869768 validation loss : 0.017169884270212304 Real validation loss : 0.017169884270212304
EarlyStopping counter: 77 out of 100
285 tarainning loss : 0.004244316978682794 validation loss : 0.01626035392594834 Real validation loss : 0.01626035392594834
EarlyStopping counter: 78 out of 100
286 tarainning loss : 0.0041364923506782315 validation loss : 0.013173519779229537 Real validation loss : 0.013173519779229537
EarlyStopping counter: 79 out of 100
287 tarainning loss : 0.00422858226120345 validation loss : 0.019532306517551962 Real validation loss : 0.019532306517551962
EarlyStopping counter: 80 out of 100
288 tarainning loss : 0.004241282276889776 validation loss : 0.025862141968294356 Real validation loss : 0.025862141968294356
EarlyStopping counter: 81 out of 100
289 tarainning loss : 0.004150666322419969 validation loss : 0.01696975830903587 Real validation loss : 0.01696975830903587
EarlyStopping counter: 82 out of 100
290 tarainning loss : 0.0041799105878987716 validation loss : 0.020763961588575814 Real validation loss : 0.020763961588575814
EarlyStopping counter: 83 out of 100
291 tarainning loss : 0.004027671772659528 validation loss : 0.014079323901872462 Real validation loss : 0.014079323901872462
EarlyStopping counter: 84 out of 100
292 tarainning loss : 0.004218003414766582 validation loss : 0.014117231058965748 Real validation loss : 0.014117231058965748
EarlyStopping counter: 85 out of 100
293 tarainning loss : 0.004363387559148755 validation loss : 0.019375680072698742 Real validation loss : 0.019375680072698742
EarlyStopping counter: 86 out of 100
294 tarainning loss : 0.0038430181513192576 validation loss : 0.020357715412198257 Real validation loss : 0.020357715412198257
EarlyStopping counter: 87 out of 100
295 tarainning loss : 0.004083958489217381 validation loss : 0.016120761749334633 Real validation loss : 0.016120761749334633
EarlyStopping counter: 88 out of 100
296 tarainning loss : 0.00406817231616579 validation loss : 0.01359185615244011 Real validation loss : 0.01359185615244011
EarlyStopping counter: 89 out of 100
297 tarainning loss : 0.004022685648888096 validation loss : 0.01534245443084122 Real validation loss : 0.01534245443084122
EarlyStopping counter: 90 out of 100
298 tarainning loss : 0.004119095376962466 validation loss : 0.014447903343049498 Real validation loss : 0.014447903343049498
EarlyStopping counter: 91 out of 100
299 tarainning loss : 0.00394278714130602 validation loss : 0.015902628200516727 Real validation loss : 0.015902628200516727
EarlyStopping counter: 92 out of 100
300 tarainning loss : 0.004060555924753003 validation loss : 0.01703462593529063 Real validation loss : 0.01703462593529063
EarlyStopping counter: 93 out of 100
301 tarainning loss : 0.0039261630379264075 validation loss : 0.017129205332215253 Real validation loss : 0.017129205332215253
EarlyStopping counter: 94 out of 100
302 tarainning loss : 0.0039013752980501942 validation loss : 0.01705831931515907 Real validation loss : 0.01705831931515907
EarlyStopping counter: 95 out of 100
303 tarainning loss : 0.0041333402053551896 validation loss : 0.013317024587498357 Real validation loss : 0.013317024587498357
EarlyStopping counter: 96 out of 100
304 tarainning loss : 0.0038337829357396377 validation loss : 0.017126282056172688 Real validation loss : 0.017126282056172688
EarlyStopping counter: 97 out of 100
305 tarainning loss : 0.004084288895430427 validation loss : 0.021253454207908362 Real validation loss : 0.021253454207908362
EarlyStopping counter: 98 out of 100
306 tarainning loss : 0.00386569531680833 validation loss : 0.015386813053434404 Real validation loss : 0.015386813053434404
EarlyStopping counter: 99 out of 100
307 tarainning loss : 0.003875807231306776 validation loss : 0.02811806625686586 Real validation loss : 0.02811806625686586
EarlyStopping counter: 100 out of 100
Early stopping
0
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 1628.477272582398, 'Validation Loss': 35.76571957270304, 'Real Validation Loss': 35.76571957270304} 0
1
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 2.764149271928233, 'Validation Loss': 0.11777142148154478, 'Real Validation Loss': 0.11777142148154478} 1
2
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.5934007049905597, 'Validation Loss': 2.9672537073493004, 'Real Validation Loss': 2.9672537073493004} 2
3
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.5785217130383377, 'Validation Loss': 0.49878943897783756, 'Real Validation Loss': 0.49878943897783756} 3
4
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.531429106914005, 'Validation Loss': 2.7224184200167656, 'Real Validation Loss': 2.7224184200167656} 4
5
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.5057311199195341, 'Validation Loss': 3.618893419702848, 'Real Validation Loss': 3.618893419702848} 5
6
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.4301679224376402, 'Validation Loss': 1.0069246751566727, 'Real Validation Loss': 1.0069246751566727} 6
7
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 1.468917713584781, 'Validation Loss': 0.6249490957707167, 'Real Validation Loss': 0.6249490957707167} 7
8
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.5855886370607628, 'Validation Loss': 0.3111084469904502, 'Real Validation Loss': 0.3111084469904502} 8
9
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.5358212273641151, 'Validation Loss': 1.6669515781104565, 'Real Validation Loss': 1.6669515781104565} 9
10
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.4802252903219366, 'Validation Loss': 0.15956137795001268, 'Real Validation Loss': 0.15956137795001268} 10
11
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.44785701895076513, 'Validation Loss': 0.1395905182386438, 'Real Validation Loss': 0.1395905182386438} 11
12
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.3570674440260796, 'Validation Loss': 1.2602998601893585, 'Real Validation Loss': 1.2602998601893585} 12
13
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.33465414746209177, 'Validation Loss': 3.002189273635546, 'Real Validation Loss': 3.002189273635546} 13
14
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.2650256919263231, 'Validation Loss': 2.1178621475895247, 'Real Validation Loss': 2.1178621475895247} 14
15
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.21884473896589066, 'Validation Loss': 0.5512886010110378, 'Real Validation Loss': 0.5512886010110378} 15
16
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.14464137952672232, 'Validation Loss': 0.35330620718499023, 'Real Validation Loss': 0.35330620718499023} 16
17
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.08074092019842462, 'Validation Loss': 0.20732852288832268, 'Real Validation Loss': 0.20732852288832268} 17
18
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0769908927407892, 'Validation Loss': 0.12313878450853129, 'Real Validation Loss': 0.12313878450853129} 18
19
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.050558972769315556, 'Validation Loss': 1.562307274589936, 'Real Validation Loss': 1.562307274589936} 19
20
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.18571638982000896, 'Validation Loss': 0.43390077880273265, 'Real Validation Loss': 0.43390077880273265} 20
21
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.06437929613371703, 'Validation Loss': 0.0470614797474506, 'Real Validation Loss': 0.0470614797474506} 21
22
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.043232141342136134, 'Validation Loss': 0.035698918237661324, 'Real Validation Loss': 0.035698918237661324} 22
23
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.04216675444836893, 'Validation Loss': 0.057943784670593836, 'Real Validation Loss': 0.057943784670593836} 23
24
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.03655075595310131, 'Validation Loss': 0.03951491747284308, 'Real Validation Loss': 0.03951491747284308} 24
25
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.03316589426200441, 'Validation Loss': 0.10179404821246862, 'Real Validation Loss': 0.10179404821246862} 25
26
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.03951463996534032, 'Validation Loss': 0.020404895146687824, 'Real Validation Loss': 0.020404895146687824} 26
27
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.03248746517489067, 'Validation Loss': 0.28132608253508806, 'Real Validation Loss': 0.28132608253508806} 27
28
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.029988584289300412, 'Validation Loss': 0.17149607464671135, 'Real Validation Loss': 0.17149607464671135} 28
29
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.030861280367832977, 'Validation Loss': 0.069490156446894, 'Real Validation Loss': 0.069490156446894} 29
30
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.02678671983945846, 'Validation Loss': 0.13465397936912873, 'Real Validation Loss': 0.13465397936912873} 30
31
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.031170276048572473, 'Validation Loss': 0.04447717766743153, 'Real Validation Loss': 0.04447717766743153} 31
32
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.02362622529985981, 'Validation Loss': 0.02117668482242152, 'Real Validation Loss': 0.02117668482242152} 32
33
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.023291713155337353, 'Validation Loss': 0.28486179855341714, 'Real Validation Loss': 0.28486179855341714} 33
34
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.024156498772776924, 'Validation Loss': 0.03242222386567543, 'Real Validation Loss': 0.03242222386567543} 34
35
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.022338140981703957, 'Validation Loss': 0.028728587242464226, 'Real Validation Loss': 0.028728587242464226} 35
36
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.02280825895512401, 'Validation Loss': 0.019691964698722586, 'Real Validation Loss': 0.019691964698722586} 36
37
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.02111002214150418, 'Validation Loss': 0.09638444730080664, 'Real Validation Loss': 0.09638444730080664} 37
38
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.021381699615603662, 'Validation Loss': 0.03346135232519979, 'Real Validation Loss': 0.03346135232519979} 38
39
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.01906376912076695, 'Validation Loss': 0.031993727141525596, 'Real Validation Loss': 0.031993727141525596} 39
40
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.02068974817999264, 'Validation Loss': 0.019984290362723794, 'Real Validation Loss': 0.019984290362723794} 40
41
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.019994194829912167, 'Validation Loss': 0.022496006422443315, 'Real Validation Loss': 0.022496006422443315} 41
42
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.017931091528981532, 'Validation Loss': 0.018822126536785316, 'Real Validation Loss': 0.018822126536785316} 42
43
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.019480690635315986, 'Validation Loss': 0.07379500346723944, 'Real Validation Loss': 0.07379500346723944} 43
44
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.017261551109632064, 'Validation Loss': 0.18339537115146717, 'Real Validation Loss': 0.18339537115146717} 44
45
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.018255822293992554, 'Validation Loss': 0.19459371315315366, 'Real Validation Loss': 0.19459371315315366} 45
46
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.019206327217146463, 'Validation Loss': 0.020678437829095248, 'Real Validation Loss': 0.020678437829095248} 46
47
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.016680857501094024, 'Validation Loss': 0.016940658873257537, 'Real Validation Loss': 0.016940658873257537} 47
48
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.016478896058661322, 'Validation Loss': 0.056592801779819034, 'Real Validation Loss': 0.056592801779819034} 48
49
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.017494071031484856, 'Validation Loss': 0.12707058782689273, 'Real Validation Loss': 0.12707058782689273} 49
50
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.01633223759859976, 'Validation Loss': 0.15379197243601084, 'Real Validation Loss': 0.15379197243601084} 50
51
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.016057953529601834, 'Validation Loss': 0.0983843607828021, 'Real Validation Loss': 0.0983843607828021} 51
52
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.015739605827977194, 'Validation Loss': 0.023773258028086275, 'Real Validation Loss': 0.023773258028086275} 52
53
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.015500341243016611, 'Validation Loss': 0.019836930364059906, 'Real Validation Loss': 0.019836930364059906} 53
54
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.015484386883544227, 'Validation Loss': 0.11612473094525437, 'Real Validation Loss': 0.11612473094525437} 54
55
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.01597643454789842, 'Validation Loss': 0.01936007073769967, 'Real Validation Loss': 0.01936007073769967} 55
56
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.014843518265338704, 'Validation Loss': 0.0425733583397232, 'Real Validation Loss': 0.0425733583397232} 56
57
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.015276966944244125, 'Validation Loss': 0.028908272603681933, 'Real Validation Loss': 0.028908272603681933} 57
58
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.016545055730715102, 'Validation Loss': 0.017338535146942984, 'Real Validation Loss': 0.017338535146942984} 58
59
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.013704530723261138, 'Validation Loss': 0.0159145099799692, 'Real Validation Loss': 0.0159145099799692} 59
60
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.014483006771160765, 'Validation Loss': 0.03238231708140423, 'Real Validation Loss': 0.03238231708140423} 60
61
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.013516677284142098, 'Validation Loss': 0.035355696318826325, 'Real Validation Loss': 0.035355696318826325} 61
62
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.014720276779303544, 'Validation Loss': 0.16660696982095638, 'Real Validation Loss': 0.16660696982095638} 62
63
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.013590512409083653, 'Validation Loss': 0.014044850759091787, 'Real Validation Loss': 0.014044850759091787} 63
64
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.01373212909884995, 'Validation Loss': 0.05399157506568978, 'Real Validation Loss': 0.05399157506568978} 64
65
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.014199765558387513, 'Validation Loss': 0.10697824019007385, 'Real Validation Loss': 0.10697824019007385} 65
66
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.013045514677437621, 'Validation Loss': 0.09891527673850457, 'Real Validation Loss': 0.09891527673850457} 66
67
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.013014358756416825, 'Validation Loss': 0.02107151331923281, 'Real Validation Loss': 0.02107151331923281} 67
68
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.012740478337025893, 'Validation Loss': 0.017447120005575318, 'Real Validation Loss': 0.017447120005575318} 68
69
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.01325870089984815, 'Validation Loss': 0.031093922754128773, 'Real Validation Loss': 0.031093922754128773} 69
70
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.013142222410426774, 'Validation Loss': 0.017349414478909846, 'Real Validation Loss': 0.017349414478909846} 70
71
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.028281609648606723, 'Validation Loss': 0.023058166436385363, 'Real Validation Loss': 0.023058166436385363} 71
72
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.011098492105136262, 'Validation Loss': 0.016228062178318698, 'Real Validation Loss': 0.016228062178318698} 72
73
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.011308925649270826, 'Validation Loss': 0.015881359247335542, 'Real Validation Loss': 0.015881359247335542} 73
74
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.012375757991681717, 'Validation Loss': 0.05710920489703616, 'Real Validation Loss': 0.05710920489703616} 74
75
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.01249684662122382, 'Validation Loss': 0.015436396468430758, 'Real Validation Loss': 0.015436396468430758} 75
76
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.011865982230445113, 'Validation Loss': 0.026280065717097994, 'Real Validation Loss': 0.026280065717097994} 76
77
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.012341615115322885, 'Validation Loss': 0.014961335643117005, 'Real Validation Loss': 0.014961335643117005} 77
78
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.011474515660513353, 'Validation Loss': 0.018346750856532406, 'Real Validation Loss': 0.018346750856532406} 78
79
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.01211136220838401, 'Validation Loss': 0.03876380071354409, 'Real Validation Loss': 0.03876380071354409} 79
80
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.012277432859583538, 'Validation Loss': 0.05099359449620048, 'Real Validation Loss': 0.05099359449620048} 80
81
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.01142133590685958, 'Validation Loss': 0.01941135319066234, 'Real Validation Loss': 0.01941135319066234} 81
82
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.011403090531692436, 'Validation Loss': 0.024500341600893687, 'Real Validation Loss': 0.024500341600893687} 82
83
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.011622413862276906, 'Validation Loss': 0.07672627526335418, 'Real Validation Loss': 0.07672627526335418} 83
84
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.011033584190432476, 'Validation Loss': 0.014015374001852857, 'Real Validation Loss': 0.014015374001852857} 84
85
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.01181252758283544, 'Validation Loss': 0.017428528857029352, 'Real Validation Loss': 0.017428528857029352} 85
86
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.011069421819991007, 'Validation Loss': 0.015343057360344877, 'Real Validation Loss': 0.015343057360344877} 86
87
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.01115604019009778, 'Validation Loss': 0.026824181045716006, 'Real Validation Loss': 0.026824181045716006} 87
88
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.010896527636210344, 'Validation Loss': 0.015597005947104966, 'Real Validation Loss': 0.015597005947104966} 88
89
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.01097934406499719, 'Validation Loss': 0.08409653937754531, 'Real Validation Loss': 0.08409653937754531} 89
90
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.011023948611117908, 'Validation Loss': 0.05118197839086255, 'Real Validation Loss': 0.05118197839086255} 90
91
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.010751975537918576, 'Validation Loss': 0.015575724362861365, 'Real Validation Loss': 0.015575724362861365} 91
92
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.010886919606589317, 'Validation Loss': 0.014266059588408098, 'Real Validation Loss': 0.014266059588408098} 92
93
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.010232603330614331, 'Validation Loss': 0.014869487538817339, 'Real Validation Loss': 0.014869487538817339} 93
94
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.01107153368425381, 'Validation Loss': 0.04019301780499518, 'Real Validation Loss': 0.04019301780499518} 94
95
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.010195387899021217, 'Validation Loss': 0.042482486188722156, 'Real Validation Loss': 0.042482486188722156} 95
96
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.010471511176307619, 'Validation Loss': 0.01591592596863241, 'Real Validation Loss': 0.01591592596863241} 96
97
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.010639474641770945, 'Validation Loss': 0.01464411163275751, 'Real Validation Loss': 0.01464411163275751} 97
98
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.010213970912188331, 'Validation Loss': 0.015580529453776156, 'Real Validation Loss': 0.015580529453776156} 98
99
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.010224947575870339, 'Validation Loss': 0.015191069857489007, 'Real Validation Loss': 0.015191069857489007} 99
100
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.010480427474325442, 'Validation Loss': 0.014620530399649093, 'Real Validation Loss': 0.014620530399649093} 100
101
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.010095629844751068, 'Validation Loss': 0.0577756519196555, 'Real Validation Loss': 0.0577756519196555} 101
102
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.009929179238353222, 'Validation Loss': 0.015091236835966507, 'Real Validation Loss': 0.015091236835966507} 102
103
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.010016331054895218, 'Validation Loss': 0.023278688410452258, 'Real Validation Loss': 0.023278688410452258} 103
104
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.009585747022918995, 'Validation Loss': 0.022159416791206848, 'Real Validation Loss': 0.022159416791206848} 104
105
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.00943951655257381, 'Validation Loss': 0.015364782768301666, 'Real Validation Loss': 0.015364782768301666} 105
106
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.009621956959357034, 'Validation Loss': 0.01958348224676835, 'Real Validation Loss': 0.01958348224676835} 106
107
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.009621084867311376, 'Validation Loss': 0.01694936620575997, 'Real Validation Loss': 0.01694936620575997} 107
108
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.01018158020451665, 'Validation Loss': 0.01374716060430122, 'Real Validation Loss': 0.01374716060430122} 108
109
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.009266966522999626, 'Validation Loss': 0.019560587058852736, 'Real Validation Loss': 0.019560587058852736} 109
110
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.009531275278902069, 'Validation Loss': 0.03940994521447768, 'Real Validation Loss': 0.03940994521447768} 110
111
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.009641275194938615, 'Validation Loss': 0.02092265634564683, 'Real Validation Loss': 0.02092265634564683} 111
112
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.009159331324694589, 'Validation Loss': 0.01406990045021909, 'Real Validation Loss': 0.01406990045021909} 112
113
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.00910764944472327, 'Validation Loss': 0.07619421304358791, 'Real Validation Loss': 0.07619421304358791} 113
114
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.009436946779094041, 'Validation Loss': 0.016258498256017145, 'Real Validation Loss': 0.016258498256017145} 114
115
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.009262939396303337, 'Validation Loss': 0.01477089149314755, 'Real Validation Loss': 0.01477089149314755} 115
116
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.008879044362945607, 'Validation Loss': 0.031457904648656644, 'Real Validation Loss': 0.031457904648656644} 116
117
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.00916652975672292, 'Validation Loss': 0.084283892918999, 'Real Validation Loss': 0.084283892918999} 117
118
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.009172138434543054, 'Validation Loss': 0.06778734732264032, 'Real Validation Loss': 0.06778734732264032} 118
119
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.008586181856833427, 'Validation Loss': 0.0171214724444629, 'Real Validation Loss': 0.0171214724444629} 119
120
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.008934497737434361, 'Validation Loss': 0.021727924739631515, 'Real Validation Loss': 0.021727924739631515} 120
121
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.008806500010812462, 'Validation Loss': 0.013630306959385052, 'Real Validation Loss': 0.013630306959385052} 121
122
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.008804746703299672, 'Validation Loss': 0.019263216556282714, 'Real Validation Loss': 0.019263216556282714} 122
123
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.008658477488470656, 'Validation Loss': 0.016350860397020977, 'Real Validation Loss': 0.016350860397020977} 123
124
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0088652920180524, 'Validation Loss': 0.020087375276489183, 'Real Validation Loss': 0.020087375276489183} 124
125
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.008586076422085495, 'Validation Loss': 0.03411635533363248, 'Real Validation Loss': 0.03411635533363248} 125
126
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.008508540053399058, 'Validation Loss': 0.014561256311329393, 'Real Validation Loss': 0.014561256311329393} 126
127
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.008630565843065202, 'Validation Loss': 0.020339778071502224, 'Real Validation Loss': 0.020339778071502224} 127
128
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.00828847074685899, 'Validation Loss': 0.015993134496966377, 'Real Validation Loss': 0.015993134496966377} 128
129
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.008427377201270111, 'Validation Loss': 0.013511096161285726, 'Real Validation Loss': 0.013511096161285726} 129
130
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.008135812518188087, 'Validation Loss': 0.013877266324319256, 'Real Validation Loss': 0.013877266324319256} 130
131
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.008500449230032698, 'Validation Loss': 0.043611485802102834, 'Real Validation Loss': 0.043611485802102834} 131
132
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.00837615640988991, 'Validation Loss': 0.013436769382678904, 'Real Validation Loss': 0.013436769382678904} 132
133
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.008215191742639651, 'Validation Loss': 0.016463713051052764, 'Real Validation Loss': 0.016463713051052764} 133
134
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.008420480859220555, 'Validation Loss': 0.02530712242393444, 'Real Validation Loss': 0.02530712242393444} 134
135
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.00824996365568702, 'Validation Loss': 0.024508694468143705, 'Real Validation Loss': 0.024508694468143705} 135
136
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.00789229225899492, 'Validation Loss': 0.04537061433074996, 'Real Validation Loss': 0.04537061433074996} 136
137
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.008097778469919768, 'Validation Loss': 0.061012911571500204, 'Real Validation Loss': 0.061012911571500204} 137
138
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.008080113173229314, 'Validation Loss': 0.013565502100391313, 'Real Validation Loss': 0.013565502100391313} 138
139
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.008325180765680803, 'Validation Loss': 0.026880265038926154, 'Real Validation Loss': 0.026880265038926154} 139
140
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.007848844459453698, 'Validation Loss': 0.013228660997507783, 'Real Validation Loss': 0.013228660997507783} 140
141
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.008070714995423686, 'Validation Loss': 0.03210870630573481, 'Real Validation Loss': 0.03210870630573481} 141
142
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.007686898158069793, 'Validation Loss': 0.08026662084739655, 'Real Validation Loss': 0.08026662084739655} 142
143
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.00798756584188221, 'Validation Loss': 0.0161019790393766, 'Real Validation Loss': 0.0161019790393766} 143
144
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.007635877388352492, 'Validation Loss': 0.013580099616471367, 'Real Validation Loss': 0.013580099616471367} 144
145
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.007686328672624509, 'Validation Loss': 0.014934966568641054, 'Real Validation Loss': 0.014934966568641054} 145
146
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.007656056637757337, 'Validation Loss': 0.014026252528613744, 'Real Validation Loss': 0.014026252528613744} 146
147
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0078204693107928, 'Validation Loss': 0.026070538345569123, 'Real Validation Loss': 0.026070538345569123} 147
148
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.007586053747752118, 'Validation Loss': 0.04044052244474491, 'Real Validation Loss': 0.04044052244474491} 148
149
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0077696327827407015, 'Validation Loss': 0.014791192734264769, 'Real Validation Loss': 0.014791192734264769} 149
150
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.007474266880022199, 'Validation Loss': 0.016788607890096802, 'Real Validation Loss': 0.016788607890096802} 150
151
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.007535451317027817, 'Validation Loss': 0.031309995839061834, 'Real Validation Loss': 0.031309995839061834} 151
152
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0078079910981828935, 'Validation Loss': 0.03147460941302901, 'Real Validation Loss': 0.03147460941302901} 152
153
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.007150515354315348, 'Validation Loss': 0.020175178719606873, 'Real Validation Loss': 0.020175178719606873} 153
154
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.007613459882737769, 'Validation Loss': 0.013334542115141327, 'Real Validation Loss': 0.013334542115141327} 154
155
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.007357452817866639, 'Validation Loss': 0.01346157576093295, 'Real Validation Loss': 0.01346157576093295} 155
156
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.007017021546223314, 'Validation Loss': 0.017126552780003596, 'Real Validation Loss': 0.017126552780003596} 156
157
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.007345778244788006, 'Validation Loss': 0.02080157933717904, 'Real Validation Loss': 0.02080157933717904} 157
158
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.007204577098216075, 'Validation Loss': 0.014902689305017702, 'Real Validation Loss': 0.014902689305017702} 158
159
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.007396726969746704, 'Validation Loss': 0.020938511210260913, 'Real Validation Loss': 0.020938511210260913} 159
160
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0071651265968057185, 'Validation Loss': 0.013694920024136081, 'Real Validation Loss': 0.013694920024136081} 160
161
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.007193853199813969, 'Validation Loss': 0.02342797862365842, 'Real Validation Loss': 0.02342797862365842} 161
162
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0070053462239975895, 'Validation Loss': 0.01754793358850293, 'Real Validation Loss': 0.01754793358850293} 162
163
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.007079178138744687, 'Validation Loss': 0.018240209319628775, 'Real Validation Loss': 0.018240209319628775} 163
164
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.007036020369897566, 'Validation Loss': 0.0161845941717426, 'Real Validation Loss': 0.0161845941717426} 164
165
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.007074100390774824, 'Validation Loss': 0.021544104354688898, 'Real Validation Loss': 0.021544104354688898} 165
166
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.006646117317547648, 'Validation Loss': 0.013371578776665652, 'Real Validation Loss': 0.013371578776665652} 166
167
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.007083951864210915, 'Validation Loss': 0.01691709234728478, 'Real Validation Loss': 0.01691709234728478} 167
168
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.006654773494912261, 'Validation Loss': 0.01847765458902965, 'Real Validation Loss': 0.01847765458902965} 168
169
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.007058113340110192, 'Validation Loss': 0.014287631585223911, 'Real Validation Loss': 0.014287631585223911} 169
170
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.006718793694420595, 'Validation Loss': 0.06143444237144043, 'Real Validation Loss': 0.06143444237144043} 170
171
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.00670269896980585, 'Validation Loss': 0.023252825349724542, 'Real Validation Loss': 0.023252825349724542} 171
172
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.006757386297300009, 'Validation Loss': 0.018811623788982008, 'Real Validation Loss': 0.018811623788982008} 172
173
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.006746424847254395, 'Validation Loss': 0.021471475047292188, 'Real Validation Loss': 0.021471475047292188} 173
174
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.006941362401302099, 'Validation Loss': 0.027526242406262707, 'Real Validation Loss': 0.027526242406262707} 174
175
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0066311618039777516, 'Validation Loss': 0.0160596036099984, 'Real Validation Loss': 0.0160596036099984} 175
176
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.006457174915471267, 'Validation Loss': 0.05050950217992067, 'Real Validation Loss': 0.05050950217992067} 176
177
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.006789426484082973, 'Validation Loss': 0.013283466881451508, 'Real Validation Loss': 0.013283466881451508} 177
178
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.006747380753449344, 'Validation Loss': 0.013932971080066636, 'Real Validation Loss': 0.013932971080066636} 178
179
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.00610361555084674, 'Validation Loss': 0.013620869402075186, 'Real Validation Loss': 0.013620869402075186} 179
180
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.006702864817545053, 'Validation Loss': 0.015252940288822478, 'Real Validation Loss': 0.015252940288822478} 180
181
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.006578184322479668, 'Validation Loss': 0.018276857862171408, 'Real Validation Loss': 0.018276857862171408} 181
182
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.006269206126314511, 'Validation Loss': 0.014599053848845264, 'Real Validation Loss': 0.014599053848845264} 182
183
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.006366019843019262, 'Validation Loss': 0.014051060347507397, 'Real Validation Loss': 0.014051060347507397} 183
184
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.006454186506391177, 'Validation Loss': 0.013298057863721624, 'Real Validation Loss': 0.013298057863721624} 184
185
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0066648184451205, 'Validation Loss': 0.061985338029141225, 'Real Validation Loss': 0.061985338029141225} 185
186
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.006296428799602358, 'Validation Loss': 0.023638727909807738, 'Real Validation Loss': 0.023638727909807738} 186
187
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.00613862480986546, 'Validation Loss': 0.016595375636825338, 'Real Validation Loss': 0.016595375636825338} 187
188
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0062258320596303455, 'Validation Loss': 0.023133242396094527, 'Real Validation Loss': 0.023133242396094527} 188
189
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.006131472712050669, 'Validation Loss': 0.013605192420072854, 'Real Validation Loss': 0.013605192420072854} 189
190
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.006318118687789902, 'Validation Loss': 0.015034501882231174, 'Real Validation Loss': 0.015034501882231174} 190
191
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0060557621759441856, 'Validation Loss': 0.015700673509854823, 'Real Validation Loss': 0.015700673509854823} 191
192
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.006140727511342239, 'Validation Loss': 0.01783632708247751, 'Real Validation Loss': 0.01783632708247751} 192
193
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.006217182715219564, 'Validation Loss': 0.01315515092088996, 'Real Validation Loss': 0.01315515092088996} 193
194
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.006237222006249084, 'Validation Loss': 0.013654505038478723, 'Real Validation Loss': 0.013654505038478723} 194
195
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0058940272451150156, 'Validation Loss': 0.19324754752839604, 'Real Validation Loss': 0.19324754752839604} 195
196
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.006630539851077633, 'Validation Loss': 0.027914442548838753, 'Real Validation Loss': 0.027914442548838753} 196
197
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005821096155179731, 'Validation Loss': 0.019060902355704457, 'Real Validation Loss': 0.019060902355704457} 197
198
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0059580300714293325, 'Validation Loss': 0.0208373554632999, 'Real Validation Loss': 0.0208373554632999} 198
199
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0060757371266818025, 'Validation Loss': 0.01686384082616617, 'Real Validation Loss': 0.01686384082616617} 199
200
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005896468203744288, 'Validation Loss': 0.014340220547940893, 'Real Validation Loss': 0.014340220547940893} 200
201
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005932787888552774, 'Validation Loss': 0.013335527085776752, 'Real Validation Loss': 0.013335527085776752} 201
202
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005686638561879355, 'Validation Loss': 0.020119044308861096, 'Real Validation Loss': 0.020119044308861096} 202
203
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005969565375164874, 'Validation Loss': 0.02217962625824536, 'Real Validation Loss': 0.02217962625824536} 203
204
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0057741475320844705, 'Validation Loss': 0.013259470976966744, 'Real Validation Loss': 0.013259470976966744} 204
205
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005764897363773043, 'Validation Loss': 0.013456584560723664, 'Real Validation Loss': 0.013456584560723664} 205
206
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0057372649634796465, 'Validation Loss': 0.01367829748778604, 'Real Validation Loss': 0.01367829748778604} 206
207
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005772755235045426, 'Validation Loss': 0.01293223525378077, 'Real Validation Loss': 0.01293223525378077} 207
208
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005863042507713677, 'Validation Loss': 0.019598884993077565, 'Real Validation Loss': 0.019598884993077565} 208
209
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0056394091224466324, 'Validation Loss': 0.014231960551114753, 'Real Validation Loss': 0.014231960551114753} 209
210
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005611163473091189, 'Validation Loss': 0.013921586442544745, 'Real Validation Loss': 0.013921586442544745} 210
211
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005529751375910788, 'Validation Loss': 0.02686511471013849, 'Real Validation Loss': 0.02686511471013849} 211
212
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005525980369330702, 'Validation Loss': 0.05368738734008124, 'Real Validation Loss': 0.05368738734008124} 212
213
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005873333442428907, 'Validation Loss': 0.01394386388225636, 'Real Validation Loss': 0.01394386388225636} 213
214
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005367583882669048, 'Validation Loss': 0.02054581033492771, 'Real Validation Loss': 0.02054581033492771} 214
215
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0054739293011288655, 'Validation Loss': 0.047154033983436726, 'Real Validation Loss': 0.047154033983436726} 215
216
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005550099543489877, 'Validation Loss': 0.04826171092766648, 'Real Validation Loss': 0.04826171092766648} 216
217
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005427668256829169, 'Validation Loss': 0.026257566486795742, 'Real Validation Loss': 0.026257566486795742} 217
218
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005542194879055999, 'Validation Loss': 0.01631905215617735, 'Real Validation Loss': 0.01631905215617735} 218
219
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005422074623286314, 'Validation Loss': 0.021225390722975135, 'Real Validation Loss': 0.021225390722975135} 219
220
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005337749731447425, 'Validation Loss': 0.018313059360176947, 'Real Validation Loss': 0.018313059360176947} 220
221
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005489086664219534, 'Validation Loss': 0.021515735774300992, 'Real Validation Loss': 0.021515735774300992} 221
222
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005412113362420375, 'Validation Loss': 0.017353409270678338, 'Real Validation Loss': 0.017353409270678338} 222
223
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005242218062962707, 'Validation Loss': 0.023755282900917035, 'Real Validation Loss': 0.023755282900917035} 223
224
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005468654633056602, 'Validation Loss': 0.013950542585613826, 'Real Validation Loss': 0.013950542585613826} 224
225
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0052366079176687005, 'Validation Loss': 0.02561209670966491, 'Real Validation Loss': 0.02561209670966491} 225
226
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005245129848790122, 'Validation Loss': 0.020973244652850553, 'Real Validation Loss': 0.020973244652850553} 226
227
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.00529158822301077, 'Validation Loss': 0.09006258573693533, 'Real Validation Loss': 0.09006258573693533} 227
228
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005233271588811829, 'Validation Loss': 0.01680631761943611, 'Real Validation Loss': 0.01680631761943611} 228
229
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.00541527681681297, 'Validation Loss': 0.014488544155028649, 'Real Validation Loss': 0.014488544155028649} 229
230
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.00509916127446995, 'Validation Loss': 0.01360182477219496, 'Real Validation Loss': 0.01360182477219496} 230
231
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005236639738263536, 'Validation Loss': 0.014874404165311716, 'Real Validation Loss': 0.014874404165311716} 231
232
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005057197639371999, 'Validation Loss': 0.022120810094444703, 'Real Validation Loss': 0.022120810094444703} 232
233
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005182050082156359, 'Validation Loss': 0.01370157895629139, 'Real Validation Loss': 0.01370157895629139} 233
234
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005157713705385751, 'Validation Loss': 0.013002128359706452, 'Real Validation Loss': 0.013002128359706452} 234
235
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005102773668454425, 'Validation Loss': 0.016500706726219505, 'Real Validation Loss': 0.016500706726219505} 235
236
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005018501021614882, 'Validation Loss': 0.03426174212169523, 'Real Validation Loss': 0.03426174212169523} 236
237
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004996310428839523, 'Validation Loss': 0.01796789514871004, 'Real Validation Loss': 0.01796789514871004} 237
238
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.00515969694033021, 'Validation Loss': 0.014766374127551293, 'Real Validation Loss': 0.014766374127551293} 238
239
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.00502996200019418, 'Validation Loss': 0.021543026339107502, 'Real Validation Loss': 0.021543026339107502} 239
240
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005141942433800504, 'Validation Loss': 0.017916074488312006, 'Real Validation Loss': 0.017916074488312006} 240
241
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005224433323846908, 'Validation Loss': 0.40403631919374067, 'Real Validation Loss': 0.40403631919374067} 241
242
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.008284040116418158, 'Validation Loss': 0.013156654492680294, 'Real Validation Loss': 0.013156654492680294} 242
243
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004227486970012966, 'Validation Loss': 0.013981033941187585, 'Real Validation Loss': 0.013981033941187585} 243
244
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0045635907762460555, 'Validation Loss': 0.014192265633028, 'Real Validation Loss': 0.014192265633028} 244
245
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004748552850280372, 'Validation Loss': 0.014182489544812901, 'Real Validation Loss': 0.014182489544812901} 245
246
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004907217720794451, 'Validation Loss': 0.015048286271242736, 'Real Validation Loss': 0.015048286271242736} 246
247
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004808924293028359, 'Validation Loss': 0.014332501203170978, 'Real Validation Loss': 0.014332501203170978} 247
248
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004778170107093641, 'Validation Loss': 0.014053213274261603, 'Real Validation Loss': 0.014053213274261603} 248
249
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0047688892911899915, 'Validation Loss': 0.015016405988717452, 'Real Validation Loss': 0.015016405988717452} 249
250
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004774497066676949, 'Validation Loss': 0.02080669750769933, 'Real Validation Loss': 0.02080669750769933} 250
251
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.00480542936561285, 'Validation Loss': 0.014090287329357428, 'Real Validation Loss': 0.014090287329357428} 251
252
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004610108451790824, 'Validation Loss': 0.02020206008455716, 'Real Validation Loss': 0.02020206008455716} 252
253
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004800919060403698, 'Validation Loss': 0.022362121138333652, 'Real Validation Loss': 0.022362121138333652} 253
254
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.005049687317117248, 'Validation Loss': 0.013859268893914608, 'Real Validation Loss': 0.013859268893914608} 254
255
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004645820769028516, 'Validation Loss': 0.021539869776461273, 'Real Validation Loss': 0.021539869776461273} 255
256
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004680494477589118, 'Validation Loss': 0.022373572991151985, 'Real Validation Loss': 0.022373572991151985} 256
257
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004729970996384051, 'Validation Loss': 0.014476205105893314, 'Real Validation Loss': 0.014476205105893314} 257
258
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004600734296431801, 'Validation Loss': 0.01551565258220459, 'Real Validation Loss': 0.01551565258220459} 258
259
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004598089842599368, 'Validation Loss': 0.024935078186293442, 'Real Validation Loss': 0.024935078186293442} 259
260
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0046159520218585805, 'Validation Loss': 0.013414974110977104, 'Real Validation Loss': 0.013414974110977104} 260
261
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.00471665116996159, 'Validation Loss': 0.045298489703175925, 'Real Validation Loss': 0.045298489703175925} 261
262
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004815620665595931, 'Validation Loss': 0.5333875206609567, 'Real Validation Loss': 0.5333875206609567} 262
263
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.00595019047507384, 'Validation Loss': 0.01361469185697691, 'Real Validation Loss': 0.01361469185697691} 263
264
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004053072240398916, 'Validation Loss': 0.021609889052342623, 'Real Validation Loss': 0.021609889052342623} 264
265
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004325921611242768, 'Validation Loss': 0.014275183610152453, 'Real Validation Loss': 0.014275183610152453} 265
266
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0046733749891859555, 'Validation Loss': 0.055918057061110936, 'Real Validation Loss': 0.055918057061110936} 266
267
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004450407653050998, 'Validation Loss': 0.017662769115607563, 'Real Validation Loss': 0.017662769115607563} 267
268
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004654451110735926, 'Validation Loss': 0.015159224907013899, 'Real Validation Loss': 0.015159224907013899} 268
269
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004359138408751468, 'Validation Loss': 0.05536266847047955, 'Real Validation Loss': 0.05536266847047955} 269
270
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004514108837349035, 'Validation Loss': 0.01777339115506038, 'Real Validation Loss': 0.01777339115506038} 270
271
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004581426244063076, 'Validation Loss': 0.018617581091045093, 'Real Validation Loss': 0.018617581091045093} 271
272
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0044863765444704195, 'Validation Loss': 0.04634487947138647, 'Real Validation Loss': 0.04634487947138647} 272
273
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004471665449369684, 'Validation Loss': 0.013748516023042612, 'Real Validation Loss': 0.013748516023042612} 273
274
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004243689449442987, 'Validation Loss': 0.019003266973110538, 'Real Validation Loss': 0.019003266973110538} 274
275
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0042643456858354545, 'Validation Loss': 0.05348907100657622, 'Real Validation Loss': 0.05348907100657622} 275
276
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0044879785337305945, 'Validation Loss': 0.016720443449836846, 'Real Validation Loss': 0.016720443449836846} 276
277
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.00429480523572866, 'Validation Loss': 0.013401737625827082, 'Real Validation Loss': 0.013401737625827082} 277
278
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0042425736015647905, 'Validation Loss': 0.019445547009430204, 'Real Validation Loss': 0.019445547009430204} 278
279
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0042332569912300584, 'Validation Loss': 0.01592666654808757, 'Real Validation Loss': 0.01592666654808757} 279
280
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004275032806455562, 'Validation Loss': 0.0140171953777705, 'Real Validation Loss': 0.0140171953777705} 280
281
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.00432741239594923, 'Validation Loss': 0.01507612863012279, 'Real Validation Loss': 0.01507612863012279} 281
282
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004294347314305633, 'Validation Loss': 0.0146929329445508, 'Real Validation Loss': 0.0146929329445508} 282
283
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004233970262261588, 'Validation Loss': 0.014189772846293636, 'Real Validation Loss': 0.014189772846293636} 283
284
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004245433694869768, 'Validation Loss': 0.017169884270212304, 'Real Validation Loss': 0.017169884270212304} 284
285
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004244316978682794, 'Validation Loss': 0.01626035392594834, 'Real Validation Loss': 0.01626035392594834} 285
286
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0041364923506782315, 'Validation Loss': 0.013173519779229537, 'Real Validation Loss': 0.013173519779229537} 286
287
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.00422858226120345, 'Validation Loss': 0.019532306517551962, 'Real Validation Loss': 0.019532306517551962} 287
288
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004241282276889776, 'Validation Loss': 0.025862141968294356, 'Real Validation Loss': 0.025862141968294356} 288
289
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004150666322419969, 'Validation Loss': 0.01696975830903587, 'Real Validation Loss': 0.01696975830903587} 289
290
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0041799105878987716, 'Validation Loss': 0.020763961588575814, 'Real Validation Loss': 0.020763961588575814} 290
291
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004027671772659528, 'Validation Loss': 0.014079323901872462, 'Real Validation Loss': 0.014079323901872462} 291
292
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004218003414766582, 'Validation Loss': 0.014117231058965748, 'Real Validation Loss': 0.014117231058965748} 292
293
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004363387559148755, 'Validation Loss': 0.019375680072698742, 'Real Validation Loss': 0.019375680072698742} 293
294
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0038430181513192576, 'Validation Loss': 0.020357715412198257, 'Real Validation Loss': 0.020357715412198257} 294
295
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004083958489217381, 'Validation Loss': 0.016120761749334633, 'Real Validation Loss': 0.016120761749334633} 295
296
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.00406817231616579, 'Validation Loss': 0.01359185615244011, 'Real Validation Loss': 0.01359185615244011} 296
297
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004022685648888096, 'Validation Loss': 0.01534245443084122, 'Real Validation Loss': 0.01534245443084122} 297
298
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004119095376962466, 'Validation Loss': 0.014447903343049498, 'Real Validation Loss': 0.014447903343049498} 298
299
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.00394278714130602, 'Validation Loss': 0.015902628200516727, 'Real Validation Loss': 0.015902628200516727} 299
300
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004060555924753003, 'Validation Loss': 0.01703462593529063, 'Real Validation Loss': 0.01703462593529063} 300
301
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0039261630379264075, 'Validation Loss': 0.017129205332215253, 'Real Validation Loss': 0.017129205332215253} 301
302
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0039013752980501942, 'Validation Loss': 0.01705831931515907, 'Real Validation Loss': 0.01705831931515907} 302
303
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0041333402053551896, 'Validation Loss': 0.013317024587498357, 'Real Validation Loss': 0.013317024587498357} 303
304
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.0038337829357396377, 'Validation Loss': 0.017126282056172688, 'Real Validation Loss': 0.017126282056172688} 304
305
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.004084288895430427, 'Validation Loss': 0.021253454207908362, 'Real Validation Loss': 0.021253454207908362} 305
306
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.00386569531680833, 'Validation Loss': 0.015386813053434404, 'Real Validation Loss': 0.015386813053434404} 306
307
TL Mean Absolute Loss vs Epoch [Y: hr, Learning Rate: 0.0005] {'Training Loss': 0.003875807231306776, 'Validation Loss': 0.02811806625686586, 'Real Validation Loss': 0.02811806625686586} 307


